<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[微服务网关netflix-zuul]]></title>
    <url>%2F2017%2F11%2F13%2Fgateway%2F</url>
    <content type="text"><![CDATA[引言：前面一个系列文章介绍了认证鉴权与API权限控制在微服务架构中的设计与实现 ，好多同学询问有没有完整的demo项目，笔者回答肯定有的。由于之前系列文章侧重讲解了权限前置，所以近期补上完整的后置项目，但是这最好有一个完整的微服务调用。本文主要讲下API网关的设计与实现。netflix-zuul是由netflix开源的API网关，在微服务架构下，网关作为对外的门户，实现动态路由、监控、授权、安全、调度等功能。 1. 网关介绍当使用单体应用程序架构时，客户端（web和移动端）通过向后端应用程序发起一次REST调用来获取数据。负载均衡器将请求路由给N个相同的应用程序实例中的一个。然后应用程序会查询各种数据库表，并将响应返回给客户端。微服务架构下，单体应用被切割成多个微服务，如果将所有的微服务直接对外暴露，势必会出现安全方面的各种问题。客户端可以直接向每个微服务发送请求，其问题主要如下： 客户端需求和每个微服务暴露的细粒度API不匹配。 部分服务使用的协议不是Web友好协议。可能使用Thrift二进制RPC，也可能使用AMQP消息传递协议。 微服务难以重构。如果合并两个服务，或者将一个服务拆分成两个或更多服务，这类重构就非常困难了。 如上问题，解决的方法是使用API网关。API网关是一个服务，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API网关封装了系统内部架构，为每个客户端提供一个定制的API。它可能还具有其它职责，如身份验证、监控、负载均衡、限流、降级与应用检测。 2. zuul网关API Gateway，常见的选型有基于 Openresty 的 Kong和基于 JVM 的 Zuul，其他还有基于Go的Tyk。技术选型上，之前稍微调研了Kong，性能还可以。考虑到快速应用和二次开发，netflix-zuul也在Spring Cloud的全家桶中，和其他组件配合使用还挺方便，后期可能还会对网关的功能进行扩增，最后选了Zuul。 2.1 pom配置123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Spring Cloud的项目中，引入zuul的starter，consul-discovery是为了服务的动态路由，这边没有用eureka，是通过注册到consul上的服务实例进行路由。 2.2 入口类12345678@SpringBootApplication@EnableZuulProxypublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class, args); &#125;&#125; Spring boot的入口类需要加上@EnableZuulProxy，下面看下这个注解。 1234567@EnableCircuitBreaker@EnableDiscoveryClient@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Import(&#123;ZuulProxyConfiguration.class&#125;)public @interface EnableZuulProxy &#123;&#125; 可以看到该注解还包含了@EnableCircuitBreaker 和 @EnableDiscoveryClient。@EnableDiscoveryClient注解在服务启动的时候，可以触发服务注册的过程，向配置文件中指定的服务注册中心；@EnableCircuitBreaker则开启了Hystrix的断路器。 2.3 bootstrap.yml12345678910111213141516171819202122232425262728293031323334server: port: 10101 #spring configspring: application: name: gateway-server cloud: consul: discovery: preferIpAddress: true enabled: true register: true service-name: api-getway ip-address: localhost port: $&#123;server.port&#125; lifecycle: enabled: true scheme: http prefer-agent-address: false host: localhost port: 8500#zuul config and routeszuul: host: maxTotalConnections: 500 maxPerRouteConnections: 50 routes: user: path: /user/** ignoredPatterns: /consul serviceId: user sensitiveHeaders: Cookie,Set-Cookie 配置主要包括三块，服务端口，Spring Cloud服务注册，最后是zuul的路由配置。 默认情况下，Zuul在请求路由时，会过滤HTTP请求头信息中的一些敏感信息，默认的敏感头信息通过zuul.sensitiveHeaders定义，包括Cookie、Set-Cookie、Authorization。 zuul.host.maxTotalConnections配置了每个服务的http客户端连接池最大连接，默认值是200。maxPerRouteConnections每个route可用的最大连接数，默认值是20。 2.3 支持https上线的项目一般域名都会改为https协议，顺手写下https的配置。 首先申请https的数字证书在阿里云生成的针对tomcat服务器CA证书在申请成功后， 下载相应的tomcat证书文件。 包含如下：1): .pfx为keystore文件，服务器用的就是这个文件2): pfx-password.txt里包含有keystore所用到的密码3): .key里面包含的是私钥，暂时没用到此文件4): *.pem里面包含的是公钥，主要给客户端 bootstrap.yml增加如下配置 123456789# httpsserver: port: 5443 http: 10101 ssl: enabled: true key-store: classpath:214329585620980.pfx key-store-password: password keyStoreType: PKCS12 同时支持http和https 1234567891011121314151617181920212223242526272829@Bean public EmbeddedServletContainerFactory servletContainer() &#123; TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint constraint = new SecurityConstraint(); constraint.setUserConstraint("CONFIDENTIAL"); SecurityCollection collection = new SecurityCollection(); collection.addPattern(""); constraint.addCollection(collection); context.addConstraint(constraint); &#125; &#125;; tomcat.addAdditionalTomcatConnectors(httpConnector()); return tomcat; &#125; @Bean public Connector httpConnector() &#123; Connector connector = new Connector("org.apache.coyote.http11.Http11NioProtocol"); connector.setScheme("http"); //Connector监听的http的端口号 connector.setPort(httpPort); connector.setSecure(false); //监听到http的端口号后转向到的https的端口号 connector.setRedirectPort(securePort); return connector; &#125; servletContainer()把EmbeddedServletContainerFactory注入到web容器中，用postProcessContext拦截所有的/*请求，并把其关联到下面的httpConnector中。最后，在httpConnector()中，把http设为10101端口，并把http的请求跳转到5443的https端口，这边是读取的配置文件。 至此，至此同时支持https和http的API网关完成，将匹配到/user的请求，路由到user服务，是不是很简单？下面一起深入了解下Zuul。 3. 一些internalsinternals可以理解为内幕。 3.1 过滤器filter是Zuul的核心，用来实现对外服务的控制。filter的生命周期有4个，分别是pre、route、post、error，整个生命周期可以用下图来表示。 一个请求会先按顺序通过所有的前置过滤器，之后在路由过滤器中转发给后端应用，得到响应后又会通过所有的后置过滤器，最后响应给客户端。error可以在所有阶段捕获异常后执行。 一般来说，如果需要在请求到达后端应用前就进行处理的话，会选择前置过滤器，例如鉴权、请求转发、增加请求参数等行为。后面衔接auth系统部分给出具体实现，也是基于pre过滤。 在请求完成后需要处理的操作放在后置过滤器中完成，例如统计返回值和调用时间、记录日志、增加跨域头等行为。路由过滤器一般只需要选择 Zuul 中内置的即可。 错误过滤器一般只需要一个，这样可以在 Gateway 遇到错误逻辑时直接抛出异常中断流程，并直接统一处理返回结果。 3.2 配置管理后端服务 API可能根据情况，有些不需要登录校验了，这个配置信息怎么动态加载到网关配置当中？笔者认为有两种方式：一是配置信息存到库中，定期实现对网关服务的配置刷新；另一种就是基于配置中心服务，当配置提交到配置中心时，触发网关服务的热更新。 后端应用无关的配置，有些是自动化的，例如恶意请求拦截，Gateway 会将所有请求的信息通过消息队列发送给一些实时数据分析的应用，这些应用会对请求分析，发现恶意请求的特征，并通过 Gateway 提供的接口将这些特征上报给 Gateway，Gateway 就可以实时的对这些恶意请求进行拦截。 3.3 隔离机制在微服务的模式下，应用之间的联系变得没那么强烈，理想中任何一个应用超过负载或是挂掉了，都不应该去影响到其他应用。但是在 Gateway 这个层面，有没有可能出现一个应用负载过重，导致将整个 Gateway 都压垮了，已致所有应用的流量入口都被切断？ 这当然是有可能的，想象一个每秒会接受很多请求的应用，在正常情况下这些请求可能在 10 毫秒之内就能正常响应，但是如果有一天它出了问题，所有请求都会 Block 到 30 秒超时才会断开（例如频繁 Full GC 无法有效释放内存）。那么在这个时候，Gateway 中也会有大量的线程在等待请求的响应，最终会吃光所有线程，导致其他正常应用的请求也受到影响。 在 Zuul 中，每一个后端应用都称为一个 Route，为了避免一个 Route 抢占了太多资源影响到其他 Route 的情况出现，Zuul 使用 Hystrix 对每一个 Route 都做了隔离和限流。 Hystrix 的隔离策略有两种，基于线程或是基于信号量。Zuul 默认的是基于线程的隔离机制，之前章节的配置可以回顾下，这意味着每一个 Route 的请求都会在一个固定大小且独立的线程池中执行，这样即使其中一个 Route 出现了问题，也只会是某一个线程池发生了阻塞，其他 Route 不会受到影响。 一般使用 Hystrix 时，只有调用量巨大会受到线程开销影响时才会使用信号量进行隔离策略，对于 Zuul 这种网络请求的用途使用线程隔离更加稳妥。 3.4 重试机制一般来说，后端应用的健康状态是不稳定的，应用列表随时会有修改，所以 Gateway 必须有足够好的容错机制，能够减少后端应用变更时造成的影响。 简单介绍下 Ribbon 支持哪些容错配置。重试的场景分为三种： okToRetryOnConnectErrors：只重试网络错误 okToRetryOnAllErrors：重试所有错误 OkToRetryOnAllOperations：重试所有操作 重试的次数有两种： MaxAutoRetries：每个节点的最大重试次数 MaxAutoRetriesNextServer：更换节点重试的最大次数 一般来说我们希望只在网络连接失败时进行重试、或是对 5XX 的 GET 请求进行重试（不推荐对 POST 请求进行重试，无法保证幂等性会造成数据不一致）。单台的重试次数可以尽量小一些，重试的节点数尽量多一些，整体效果会更好。 如果有更加复杂的重试场景，例如需要对特定的某些 API、特定的返回值进行重试，那么也可以通过实现 RequestSpecificRetryHandler 定制逻辑（不建议直接使用 RetryHandler，因为这个子类可以使用很多已有的功能）。 4. 总结本文首先介绍了API网关的相关知识；其次介绍了zuul网关的配置实现，同时支持https；最后介绍了zuul网关的一些内幕原理，这边大部分参考了网上的文章。网关作为内网与外网之间的门户，所有访问内网的请求都会经过网关，网关处进行反向代理。在整个Spring Cloud微服务框架里，Zuul扮演着”智能网关“的角色。 github: https://github.com/keets2012/Spring-Boot-Samples/tree/master/api-gatewaygitee: https://gitee.com/keets/spring-boot-samples/tree/master/api-gateway 参考 聊聊 API Gateway 和 Netflix Zuul Spring Cloud技术分析（4）- spring cloud zuul netflix-zuul]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>zuul</tag>
        <tag>gateway</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几种分布式调用链监控组件的实践与比较（一）实践]]></title>
    <url>%2F2017%2F11%2F10%2Fapm1%2F</url>
    <content type="text"><![CDATA[引言：最近在调研与选型分布式调用链监控组件。选了主要的三种APM组件进行了实践与比较。本来打算一篇文章写完的，篇幅太长，打算分两篇。本文主要讲下链路traceing的基本概念和几种APM组件的实践，实践部分也没给出特别详细的步骤，因为本文重点不在具体的步骤。第二篇将会讲下几种APM选型的比较与性能测试。 1. 问题背景微服务架构下，服务按照不同的维度进行拆分，一次请求请求往往需要涉及到多个服务。互联网应用构建在不同的软件模块集上，这些软件模块，有可能是由不同的团队开发、可能使用不同的编程语言来实现、有可能布在了几千台服务器，横跨多个不同的数据中心。因此，就需要一些可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题。 分布式调用链监控组件在这样的环境下产生了。最出名的是谷歌公开的论文提到的Dapper。开发Dapper是为了收集更多的复杂分布式系统的行为信息，然后呈现给Google的开发者们。这样的分布式系统有一个特殊的好处，因为那些大规模的低端服务器，作为互联网服务的载体，是一个特殊的经济划算的平台。想要在这个上下文中理解分布式系统的行为，就需要监控那些横跨了不同的应用、不同的服务器之间的关联动作。 市面上的APM（Application Performance Management）理论模型大多都是借鉴（borrow）Google Dapper论文，本文重点关注以下几种APM组件： Zipkin 由Twitter公司开源，开放源代码分布式的跟踪系统，用于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。 PinpointPinpoint是一款对Java编写的大规模分布式系统的APM工具，由韩国人开源的分布式跟踪组件。 Skywalking国产的优秀APM组件，是一个对JAVA分布式应用程序集群的业务运行情况进行追踪、告警和分析的系统。 其他类似的组件还有美团点评的CAT，淘宝的鹰眼EgleEye。 如上所述，那么我们选择链路监控组件有哪些要求呢？Dapper中也提到了，笔者总结如下： 探针的性能消耗。APM组件服务的影响应该做到足够小。在一些高度优化过的服务，即使一点点损耗也会很容易察觉到，而且有可能迫使在线服务的部署团队不得不将跟踪系统关停。 代码的侵入性对于应用的程序员来说，是不需要知道有跟踪系统这回事的。如果一个跟踪系统想生效，就必须需要依赖应用的开发者主动配合，那么这个跟踪系统也太脆弱了，往往由于跟踪系统在应用中植入代码的bug或疏忽导致应用出问题，这样才是无法满足对跟踪系统“无所不在的部署”这个需求。 可扩展性能够支持的组件越多当然越好。或者提供便捷的插件开发API，对于一些没有监控到的组件，应用开发者也可以自行扩展。 数据的分析数据的分析要快 ，分析的维度尽可能多。跟踪系统能提供足够快的信息反馈，就可以对生产环境下的异常状况做出快速反应。分析的全面，能够避免二次开发。 2. 基础概念上面列出的几种组件，其中Zipkin是严格按照Google Dapper论文实现的，下面介绍下其中涉及的基本概念。 Span基本工作单元，一次链路调用(可以是RPC，DB等没有特定的限制)创建一个span，通过一个64位ID标识它，uuid较为方便，span中还有其他的数据，例如描述信息，时间戳，key-value对的(Annotation)tag信息，parent-id等,其中parent-id可以表示span调用链路来源。 Trace:类似于树结构的Span集合，表示一条调用链路，存在唯一标识。比如你运行的分布式大数据存储一次Trace就由你的一次请求组成。 Annotation: 注解,用来记录请求特定事件相关信息(例如时间)，通常包含四个注解信息： (1) cs：Client Start,表示客户端发起请求 (2) sr：Server Receive,表示服务端收到请求 (3) ss：Server Send,表示服务端完成处理，并将结果发送给客户端 (4) cr：Client Received,表示客户端获取到服务端返回信息 2.1 Trace下面看一下，在系统中Trace是什么样子。 每种颜色的note标注了一个span，一条链路通过TraceId唯一标识，Span标识发起的请求信息。树节点是整个架构的基本单元，而每一个节点又是对span的引用。节点之间的连线表示的span和它的父span直接的关系。虽然span在日志文件中只是简单的代表span的开始和结束时间，他们在整个树形结构中却是相对独立的。 2.2 Span 上图说明了span在一次大的跟踪过程中是什么样的。Dapper记录了span名称，以及每个span的ID和父ID，以重建在一次追踪过程中不同span之间的关系。如果一个span没有父ID被称为root span。所有span都挂在一个特定的跟踪上，也共用一个跟踪id。 2.3 Annotation自动的探针，不需要修改应用程序源代码，对应用开发者近乎零浸入的成本对分布式控制路径进行跟踪，几乎完全依赖于基于少量通用组件库的改造。Dapper还允许应用程序开发人员在Dapper跟踪的过程中添加额外的信息，以监控更高级别的系统行为，或帮助调试问题。 下面章节将会介绍下上述三种APM组件的使用与实践。 3. zipkinzipkin主要涉及几个组件：collector收集agent的数据，storage存储，web UI图形化界面，search查询Storage中存储的数据,提供简单的JSON API获取数据。 我们的项目基于微服务框架spring cloud构建微服务。spring cloud也提供了spring-cloud-sleuth来方便集成zipkin实现。所以笔者就在项目中试了下spring-cloud-sleuth-zipkin。 起了三个服务：zipkin-server、zipkin-client-backend、zipkin-client。其中server服务负责收集以及信息展示。client-backend调用client，产生调用链路信息。 3.1 zipkin-server实现zipkin-server实现主要有两点需要注意，其一是收集到数据的存储，方式包括内存、数据库、ES等；其二是通信方式，包括http通信和mq异步方式通信，http通信会对正常的访问造成影响，所以还是推荐基于mq异步方式通信。 本文使用mysql作为存储，使用MQ通信，MQ通信基于Spring-cloud-Stream。本文重点不在zipkin-server的具体几种实现方式，其他方式，读者可以自己去官网查看。 （1）pom需要添加的引用如下： 1234567891011121314151617181920212223242526272829&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--zipkin依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--保存到数据库需要如下依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; （2）启动类： 12345678// 使用Stream方式启动ZipkinServer@EnableZipkinStreamServer@SpringBootApplicationpublic class ZipkinStreamServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinStreamServerApplication.class,args); &#125;&#125; @EnableZipkinStreamServer注解引入了@EnableZipkinServer注解，同时还创建了一个rabbit-mq的SleuthSink消息队列监听器。 （3）配置文件 123456789101112131415161718192021222324252627server: port: 9411spring: datasource: username: root password: root123 schema[0]: classpath:/zipkin.sqlzipkin: storage: type: mysql---spring: application: name: microservice-zipkin-stream-server rabbitmq: host: $&#123;RABBIT_ADDR:localhost&#125; port: $&#123;RABBIT_PORT:5672&#125; username: guest password: guest sleuth: enabled: false profiles: default datasource: url: jdbc:mysql://localhost:3307/zipkin?autoReconnect=true&amp;useSSL=false zipkin.sql可以去官网获取，设置了zipkin-server的端口号为9411。 3.2 zipkin-client两个zipkin-client的配置一样，所以放在一起。 （1）pom依赖 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; (2) 配置文件 123456spring: rabbitmq: host: 127.0.0.1 port : 5672 username: guest password: guest 3.3 结果服务之间的调用关系如下： 可以看到客户端的请求经过gateway，调用内网中的各个服务，部分还涉及到调用notice服务。从图中可以清楚的看出客户端请求所经过的服务。下面看下demo2-default服务实例中的http path： 上图中demo2-default服务的几个http path按照时长排序，显示了trace调用时长和span数量。点进去可以看到： 图中列出了从父span开始，每一个span的耗时。本次trace中，涉及到两个服务demo1和demo2。demo2调用demo1，从597ms开始调用demo1，完成最终的请求总共耗时1265ms。 4. pinpoint对代码零侵入，运用JavaAgent字节码增强技术，只需要加启动参数即可。pinpoint的几个组件部分和zipkin差不多，架构图如下： Pinpoint-Collector收集各种性能数据、Pinpoint-Agent和自己运行的应用关联起来的探针、Pinpoint-Web将收集到的数据显示成WEB网页形式、HBase Storage收集到的数据存到HBase中。 4.1 pinpoint安装主要涉及以下软件的安装： jdk 1.8Java环境必须的，没啥好解释。 Hbasepinpoint收集来的测试数据，主要是存在Hbase数据库的。所以它可以收集大量的数据，可以进行更加详细的分析。Hbase安装完成后，需要初始化Hbase的pinpoint库，由pinpoint提供。Hbase内置了zookeeper。 pinpoint-collectorcollector收集agent的数据，将数据存到hbase集群，对外暴露collector的tcp和udp的监听端口9994，9995，9996。 pinpoint-web页面展示，配置文件中设置环境变量HBASE_HOST、HBASE_PORT等。 pinpoint-agent 到官网release页面下载pinpoint-agent-x-SNAPSHOT.tar.gz，配置pinpoint.config中相关collector的信息。 安装确实还比较麻烦，本文篇幅太长了，具体步骤后面再单独写文章讲解。 4.2 运行pinpoint-agent笔者使用的是spring-boot项目，所以只需要在启动jar包的命令中加入-javaagent参数，并指定pinpoint-bootstrap包的绝对路径。实例代码如下： 1java -javaagent:/aoho/auth_compose/pinpoint-bootstrap-1.6.0.jar -Dpinpoint.agentId=aoho-consumer -Dpinpoint.applicationName=aoho-consumer -jar id_generator/snowflake-id-generate-1.0-SNAPSHOT.jar 起的id生成器服务比较简单，没有用到数据库等存储介质。服务注册到consul上，本地客户端请求了id-server获取id。其调用链如下： pinpoint提供的功能比较丰富，下图是调用/api/id接口的详细信息。 可以看到，pinpoint记录了客户端的相应时间、IP地址等，调用树在下面也有详细列出，每个方法的耗时等。 serverMap中还展示了服务器的堆、永久代、CPU等信息，非常强大。 5. SkywalkingSkywalking是国内开源的APM监控组件，官网OpenSkywalking，根据官网介绍，其着力于性能和实时性两方面。网上找到的Skywalking的架构图。 可以看到Skywalking也是四部分组成，collector、agent、web、storage。支持集群部署，集群之间还引入了grpc通信。存储支持内置的h2和elasticsearch存储。 5.1 安装具体安装可见官网。 collector安装此处笔者使用单机版的collector，在release页面下载好压缩包，解压后，单机版的collector默认使用h2数据库，所以配置文件可以不需要修改，即可以运行bin/startup.sh。 目录结构如上，logs文件夹中，有启动的日志，可以查看启动情况。 web解压好skywalking-ui，设置server的config/collector_config.properties、log4j2以及监听端口等相关信息， agent拷贝skywalking-agent目录到所需位置，探针包含整个目录，设置/config/agent.config中的collector信息。 5.2 运行agentSpring boot的项目，启动和上面pinpoint agent启动方式相同。增加JVM启动参数，-javaagent:/path/to/skywalking-agent/skywalking-agent.jar。 这次起了user服务，涉及到mysql、redis、consul等组件。可以看到其调用链路图如下： 当访问/api/external/register-code和/api/external/validate-code接口时，形成了上图中的调用链。 上图TraceId为 2.59.15103021777910001的请求/api/external/register-code。这次trace中，每个涉及的span的耗时都有在图中统计。 上面这张图，是对userService中的Entry Service List接口进行了统计，包括调用数、成功率等信息。（因为内置的h2，这边在UI响应很久） 还有个对instance的统计，统计jvm的相关信息，API响应也很慢，可能与我用的存储有关吧，就不截图了。 6. 总结本文主要写了链路监控组件的实践。首先介绍了链路监控组件产生与应用的背景，以及选择的要求；其次介绍了opentracing中涉及的基本概念；最后大篇幅介绍了三种APM组件的安装与使用，并展示了每种APM的UI截图。本文比较简单，下一篇文章主要介绍几种APM选型的比较与性能测试。 zipkin-server-stream的源码github: https://github.com/keets2012/Spring-Boot-Samples/oschina: https://gitee.com/keets/spring-boot-samples 参考(疯狂找资料) OpenTracing官方标准-中文版 Skywalking Zipkin PinPoint Spring Cloud Sleuth Dapper pinpoint 安装部署 java开源APM概要 分布式系统监控系统zipkin入门 跟着小程学微服务-自己动手扩展分布式调用链]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>APM</tag>
        <tag>zipkin</tag>
        <tag>micro-service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务部署之Maven插件构建Docker镜像]]></title>
    <url>%2F2017%2F11%2F02%2Fdockermaven%2F</url>
    <content type="text"><![CDATA[1.背景微服务架构下，微服务在带来良好的设计和架构理念的同时，也带来了运维上的额外复杂性，尤其是在服务部署和服务监控上。单体应用是集中式的，就一个单体跑在一起，部署和管理的时候非常简单，而微服务是一个网状分布的，有很多服务需要维护和管理，对它进行部署和维护的时候则比较复杂。 下面从Dev的角度来看一下Ops的工作。从Dev提交代码，到完成集成测试的一系列步骤如下： 首先是开发人员把程序代码更新后上传到Git，然后其他的事情都将由Jenkins自动完成。 然后Git在接收到用户更新的代码后，会把消息和任务传递给Jenkins，然后Jenkins会自动构建一个任务，下载Maven相关的软件包。下载完成后，就开始利用Maven Build新的项目包，然后重建Maven容器，构建新的Image并Push到Docker私有库中。 最后删除正在运行的Docker容器，再基于新的镜像重新把Docker容器启动，自动完成集成测试。 整个过程都是自动的，这样就简化了原本复杂的集成工作，一天可以集成一次，甚至是多次。 本文主要关注的第二步，作为Dev使用Maven插件构建Docker镜像。 2. 过程步骤2.1 环境笔者的电脑系统是MacOS，在进行下面的步骤之前，先具备一下条件： Docker Registry Maven（3.5.0） JDK(1.8.0_131) Docker for Mac (17.09.0-ce-mac35) Maven 和JDK 就不用过多多了，必须具有的。Docker Registry是私有的hub，mac上装好docker之后，配置一下Docker Registry的地址，配置如下： 1234567&#123; "debug" : true, "experimental" : false, "insecure-registries" : [ "192.168.1.202" ]&#125; 配置好registry地址之后，本地pull镜像，还需要命令行login到registry： 1docker login 192.168.1.202 --username admin --password 123456 2.2 pom文件pom文件中需要引入相应的插件。docker-maven-plugin有三款：spotify、fabric8io和bibryam。其中第一款最为流行，资料也多，所以毫不犹豫选择第一款。插件有两种使用方式，一种是在直接在pom配置中指定baseImage和entryPoint。另一种适合于复杂的构建，使用dockerfile，只需要在配置中指定dockerfile的位置。前一种比较简单，此处略过，主要讲下第二种的配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.docker.version&#125;&lt;/version&gt; &lt;!--插件绑定到phase--&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!--配置变量，包括是否build、imageName、imageTag，非常灵活--&gt; &lt;skipDocker&gt;$&#123;docker.skip.build&#125;&lt;/skipDocker&gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;!--最后镜像产生了两个tag，版本和和最新的--&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;imageTag&gt;latest&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;env&gt; &lt;TZ&gt;Asia/Shanghai&lt;/TZ&gt; &lt;/env&gt; &lt;!--时区配置--&gt; &lt;runs&gt; &lt;run&gt;ln -snf /usr/share/zoneinfo/$TZ /etc/localtime&lt;/run&gt; &lt;run&gt;echo $TZ &gt; /etc/timezone&lt;/run&gt; &lt;/runs&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--push到私有的hub--&gt; &lt;serverId&gt;docker-registry&lt;/serverId&gt; &lt;/configuration&gt; &lt;/plugin&gt; ${maven.docker.version}、${docker.skip.build}、${docker.image.prefix}都是可配置的变量。${project.basedir}、${project.build.directory}、${project.build.finalName}、${project.version}分别对应项目根目录、构建目录、打包后生成的结果名称、项目版本号。上面的pom插件配置，指定了dockerfile的位置和镜像的命名规则。并将docker的build目标，绑定在install这个phase上。 2.3 dockerfile12345FROM 192.168.1.202/library/basejavaVOLUME /tmpADD ./target/cloud-api-gateway-1.2.0.RELEASE.jar app.jarRUN bash -c 'touch /app.jar'ENTRYPOINT ["java","-Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"] dockerfile 写的很简单，将jar包ADD进去，提供ENTRYPOINT。 2.4 setting.xml在pom插件中，还有一个serverId的配置。这个配置是必要的，对于需要将image上传到私有hub上，在如上配置之后，只需要加上-DpushImage即可实现。serverId是与maven的配置文件setting.xml相对应，setting.xml中增加的配置： 12345678&lt;server&gt; &lt;id&gt;docker-registry&lt;/id&gt; &lt;username&gt;用户名&lt;/username&gt; &lt;password&gt;密码&lt;/password&gt; &lt;configuration&gt; &lt;email&gt;邮箱&lt;/email&gt; &lt;/configuration&gt;&lt;/server&gt; 2.5 结果 上图是执行mvn clean install -DpushImage成功的结果。mvn首先是打包，将生产的文件拷贝到target下的docker目录，然后执行dockerfile中的步骤，将打成的镜像进行tag，最后上传到私有hub上。 上图是VMware Harbor中的截图，可以看到，我们已经成功将镜像上传，其tag有两个：1.2.0.RELEASE和latest。 3. 总结本文属于工程实践类文章，比较简单。开头由背景介绍了Dev到继承测试的一系列步骤，本文主要关注的是第二步，作为Dev使用Maven插件构建Docker镜像。正文部分主要讲了实践的环境，然后讲了docker-maven-plugin插件的使用方式，重点介绍了使用dockerfile的方式，对于涉及到的配置进行了解释。 本文的源码地址：GitHub：https://github.com/keets2012/snowflake-id-generator码云： https://gitee.com/keets/snowflake-id-generator 参考 从运维的角度看微服务和容器 Docker与微服务-使用Maven插件构建Docker镜像]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Docker</tag>
        <tag>Ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认证鉴权与API权限控制在微服务架构中的设计与实现（四）]]></title>
    <url>%2F2017%2F10%2F26%2Fsecurity4%2F</url>
    <content type="text"><![CDATA[引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的完结篇，前面三篇已经将认证鉴权与API权限控制的流程和主要细节讲解完。本文比较长，对这个系列进行收尾，主要内容包括对授权和鉴权流程之外的endpoint以及Spring Security过滤器部分踩坑的经历。欢迎阅读本系列文章。 1. 前文回顾首先还是照例对前文进行回顾。在第一篇 认证鉴权与API权限控制在微服务架构中的设计与实现（一）介绍了该项目的背景以及技术调研与最后选型。第二篇认证鉴权与API权限控制在微服务架构中的设计与实现（二）画出了简要的登录和校验的流程图，并重点讲解了用户身份的认证与token发放的具体实现。第三篇认证鉴权与API权限控制在微服务架构中的设计与实现（三）先介绍了资源服务器配置，以及其中涉及的配置类，后面重点讲解了token以及API级别的鉴权。 本文将会讲解剩余的两个内置端点：注销和刷新token。注销token端点的处理与Spring Security默认提供的有些’/logout’有些区别，不仅清空SpringSecurityContextHolder中的信息，还要增加对存储token的清空。另一个刷新token端点其实和之前的请求授权是一样的API，只是参数中的grant_type不一样。 除了以上两个内置端点，后面将会重点讲下几种Spring Security过滤器。API级别的操作权限校验本来设想是通过Spring Security的过滤器实现，特地把这边学习了一遍，踩了一遍坑。 最后是本系列的总结，并对于存在的不足和后续工作进行论述。 2. 其他端点2.1 注销端点在第一篇中提到了Auth系统内置的注销端点 /logout，如果还记得第三篇资源服务器的配置，下面的关于/logout配置一定不陌生。 123456//... .and().logout() .logoutUrl("/logout") .clearAuthentication(true) .logoutSuccessHandler(new HttpStatusReturningLogoutSuccessHandler()) .addLogoutHandler(customLogoutHandler()); 上面配置的主要作用是： 设置注销的URL 清空Authentication信息 设置注销成功的处理方式 设置自定义的注销处理方式 当然在LogoutConfigurer中还有更多的设置选项，笔者此处列出项目所需要的配置项。这些配置项围绕着LogoutFilter过滤器。顺带讲一下Spring Security的过滤器。其使用了springSecurityFillterChian作为了安全过滤的入口，各种过滤器按顺序具体如下： SecurityContextPersistenceFilter：与SecurityContext安全上下文信息有关 HeaderWriterFilter：给http响应添加一些Header CsrfFilter：防止csrf攻击，默认开启 LogoutFilter：处理注销的过滤器 UsernamePasswordAuthenticationFilter：表单认证过滤器 RequestCacheAwareFilter：缓存request请求 SecurityContextHolderAwareRequestFilter：此过滤器对ServletRequest进行了一次包装，使得request具有更加丰富的API AnonymousAuthenticationFilter：匿名身份过滤器 SessionManagementFilter：session相关的过滤器，常用来防止session-fixation protection attack，以及限制同一用户开启多个会话的数量 ExceptionTranslationFilter：异常处理过滤器 FilterSecurityInterceptor：web应用安全的关键Filter 各种过滤器简单标注了作用，在下一节重点讲其中的几个过滤器。注销过滤器排在靠前的位置，我们一起看下LogoutFilter的UML类图。 类图和我们之前配置时的思路是一致的，HttpSecurity创建了LogoutConfigurer，我们在这边配置了LogoutConfigurer的一些属性。同时LogoutConfigurer根据这些属性创建了LogoutFilter。 LogoutConfigurer的配置，第一和第二点就不用再详细解释了，一个是设置端点，另一个是清空认证信息。对于第三点，配置注销成功的处理方式。由于项目是前后端分离，客户端只需要知道执行成功该API接口的状态，并不用返回具体的页面或者继续向下传递请求。因此，这边配置了默认的HttpStatusReturningLogoutSuccessHandler，成功直接返回状态码200。对于第四点配置，自定义注销处理的方法。这边需要借助TokenStore，对token进行操作。TokenStore在之前文章的配置中已经讲过，使用的是JdbcTokenStore。首先校验请求的合法性，如果合法则对其进行操作，先后移除refreshToken和existingAccessToken。 12345678910111213141516171819202122232425262728293031323334public class CustomLogoutHandler implements LogoutHandler &#123; //... @Override public void logout(HttpServletRequest request, HttpServletResponse response, Authentication authentication) &#123; //确定注入了tokenStore Assert.notNull(tokenStore, "tokenStore must be set"); //获取头部的认证信息 String token = request.getHeader("Authorization"); Assert.hasText(token, "token must be set"); //校验token是否符合JwtBearer格式 if (isJwtBearerToken(token)) &#123; token = token.substring(6); OAuth2AccessToken existingAccessToken = tokenStore.readAccessToken(token); OAuth2RefreshToken refreshToken; if (existingAccessToken != null) &#123; if (existingAccessToken.getRefreshToken() != null) &#123; LOGGER.info("remove refreshToken!", existingAccessToken.getRefreshToken()); refreshToken = existingAccessToken.getRefreshToken(); tokenStore.removeRefreshToken(refreshToken); &#125; LOGGER.info("remove existingAccessToken!", existingAccessToken); tokenStore.removeAccessToken(existingAccessToken); &#125; return; &#125; else &#123; throw new BadClientCredentialsException(); &#125; &#125; //...&#125; 执行如下请求： 123456method: geturl: http://localhost:9000/logoutheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=&#125; 注销成功则会返回200，将token和SecurityContextHolder进行清空。 2.2 刷新端点在第一篇就已经讲过，由于token的时效一般不会很长，而refresh token一般周期会很长，为了不影响用户的体验，可以使用refresh token去动态的刷新token。刷新token主要与RefreshTokenGranter有关，CompositeTokenGranter管理一个List列表，每一种grantType对应一个具体的真正授权者，refresh_ token对应的granter就是RefreshTokenGranter，而granter内部则是通过grantType来区分是否是各自的授权类型。执行如下请求： 123456method: post url: http://localhost:12000/oauth/token?grant_type=refresh_token&amp;refresh_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeEheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=&#125; 在refresh_ token正确的情况下，其返回的response和/oauth/token得到正常的响应是一样的。具体的代码可以参阅第二篇的讲解。 3. Spring Security过滤器在上一节我们介绍了内置的两个端点的实现细节，还提到了HttpSecurity过滤器，因为注销端点的实现就是通过过滤器的作用。核心的过滤器主要有： FilterSecurityInterceptor UsernamePasswordAuthenticationFilter SecurityContextPersistenceFilter ExceptionTranslationFilter 这一节将重点介绍其中的UsernamePasswordAuthenticationFilter和FilterSecurityInterceptor。 3.1 UsernamePasswordAuthenticationFilter笔者在刚开始看关于过滤器的文章，对于UsernamePasswordAuthenticationFilter有不少的文章介绍。如果只是引入Spring-Security，必然会与/login端点熟悉。SpringSecurity强制要求我们的表单登录页面必须是以POST方式向/login URL提交请求，而且要求用户名和密码的参数名必须是username和password。如果不符合，则不能正常工作。原因在于，当我们调用了HttpSecurity对象的formLogin方法时，其最终会给我们注册一个过滤器UsernamePasswordAuthenticationFilter。看一下该过滤器的源码。 1234567891011121314151617181920212223242526272829303132333435public class UsernamePasswordAuthenticationFilter extends AbstractAuthenticationProcessingFilter &#123; //用户名、密码 public static final String SPRING_SECURITY_FORM_USERNAME_KEY = "username"; public static final String SPRING_SECURITY_FORM_PASSWORD_KEY = "password"; private String usernameParameter = SPRING_SECURITY_FORM_USERNAME_KEY; private String passwordParameter = SPRING_SECURITY_FORM_PASSWORD_KEY; private boolean postOnly = true; //post请求/login public UsernamePasswordAuthenticationFilter() &#123; super(new AntPathRequestMatcher("/login", "POST")); &#125; //实现抽象类AbstractAuthenticationProcessingFilter的抽象方法，尝试验证 public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if (postOnly &amp;&amp; !request.getMethod().equals("POST")) &#123; throw new AuthenticationServiceException( "Authentication method not supported: " + request.getMethod()); &#125; String username = obtainUsername(request); String password = obtainPassword(request); //··· username = username.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); //··· return this.getAuthenticationManager().authenticate(authRequest); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public abstract class AbstractAuthenticationProcessingFilter extends GenericFilterBean implements ApplicationEventPublisherAware, MessageSourceAware &#123; //... //调用requiresAuthentication，判断请求是否需要authentication，如果需要则调用attemptAuthentication //有三种结果可能返回： //1.Authentication对象 //2. AuthenticationException //3. Authentication对象为空 public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; //不需要校验，继续传递 if (!requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); return; &#125; Authentication authResult; try &#123; authResult = attemptAuthentication(request, response); if (authResult == null) &#123; // return immediately as subclass has indicated that it hasn't completed authentication return; &#125; sessionStrategy.onAuthentication(authResult, request, response); &#125; //... catch (AuthenticationException failed) &#123; // Authentication failed unsuccessfulAuthentication(request, response, failed); return; &#125; // Authentication success if (continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; successfulAuthentication(request, response, chain, authResult); &#125; //实际执行的authentication，继承类必须实现该抽象方法 public abstract Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException, IOException, ServletException; //成功authentication的默认行为 protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; //... &#125; //失败authentication的默认行为 protected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response, AuthenticationException failed) throws IOException, ServletException &#123; //... &#125; ... //设置AuthenticationManager public void setAuthenticationManager(AuthenticationManager authenticationManager) &#123; this.authenticationManager = authenticationManager; &#125; ...&#125; UsernamePasswordAuthenticationFilter因为继承了AbstractAuthenticationProcessingFilter才拥有过滤器的功能。AbstractAuthenticationProcessingFilter要求设置一个authenticationManager，authenticationManager的实现类将实际处理请求的认证。AbstractAuthenticationProcessingFilter将拦截符合过滤规则的request，并试图执行认证。子类必须实现 attemptAuthentication 方法，这个方法执行具体的认证。认证之后的处理和上注销的差不多。如果认证成功，将会把返回的Authentication对象存放在SecurityContext，并调用SuccessHandler，也可以设置指定的URL和指定自定义的处SuccessHandler。如果认证失败，默认会返回401代码给客户端，也可以设置URL，指定自定义的处理FailureHandler。 基于UsernamePasswordAuthenticationFilter自定义的AuthenticationFilte还是挺多案例的，这边推荐一篇博文Spring Security(五)–动手实现一个IP_Login，写得比较详细。 3.2 FilterSecurityInterceptorFilterSecurityInterceptor是filterchain中比较复杂，也是比较核心的过滤器，主要负责web应用安全授权的工作。首先看下对于自定义的FilterSecurityInterceptor配置。 12345678910111213@Override public void configure(HttpSecurity http) throws Exception &#123; ... //添加CustomSecurityFilter，过滤器的顺序放在FilterSecurityInterceptor http.antMatcher("/oauth/check_token").addFilterAt(customSecurityFilter(), FilterSecurityInterceptor.class); &#125; //提供实例化的自定义过滤器 @Bean public CustomSecurityFilter customSecurityFilter() &#123; return new CustomSecurityFilter(); &#125; 从上述配置可以看到，在FilterSecurityInterceptor的位置注册了CustomSecurityFilter，对于匹配到/oauth/check_token，则会调用该进入该过滤器。下图为FilterSecurityInterceptor的类图，在其中还添加了CustomSecurityFilter和相关实现的接口的类，方便读者对比着看。 CustomSecurityFilter是模仿FilterSecurityInterceptor实现，继承AbstractSecurityInterceptor和实现Filter接口。整个过程需要依赖AuthenticationManager、AccessDecisionManager和FilterInvocationSecurityMetadataSource。AuthenticationManager是认证管理器，实现用户认证的入口；AccessDecisionManager是访问决策器，决定某个用户具有的角色，是否有足够的权限去访问某个资源；FilterInvocationSecurityMetadataSource是资源源数据定义，即定义某一资源可以被哪些角色访问。从上面的类图中可以看到自定义的CustomSecurityFilter同时又实现了AccessDecisionManager和FilterInvocationSecurityMetadataSource。分别为SecureResourceFilterInvocationDefinitionSource和SecurityAccessDecisionManager。下面分析下主要的配置。 12345678910111213//通过一个实现的filter，对HTTP资源进行安全处理public class FilterSecurityInterceptor extends AbstractSecurityInterceptor implements Filter &#123; //被filter chain真实调用的方法，通过invoke代理 public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FilterInvocation fi = new FilterInvocation(request, response, chain); invoke(fi); &#125; //代理的方法 public void invoke(FilterInvocation fi) throws IOException, ServletException &#123; //...省略 &#125;&#125; 上述代码是FilterSecurityInterceptor中的实现，具体实现细节就没列出了，我们这边重点在于对自定义的实现进行讲解。 123456789101112131415161718192021222324252627282930313233343536373839404142public class CustomSecurityFilter extends AbstractSecurityInterceptor implements Filter &#123; @Autowired SecureResourceFilterInvocationDefinitionSource invocationSource; @Autowired private AuthenticationManager authenticationManager; @Autowired private SecurityAccessDecisionManager decisionManager; //设置父类中的属性 @PostConstruct public void init() &#123; super.setAccessDecisionManager(decisionManager); super.setAuthenticationManager(authenticationManager); &#125; //主要的过滤方法，与原来的一致 @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; //logger.info("doFilter in Security "); //构造一个FilterInvocation，封装request, response, chain FilterInvocation fi = new FilterInvocation(servletRequest, servletResponse, filterChain); //beforeInvocation会调用SecureResourceDataSource中的逻辑，类似于aop中的before InterceptorStatusToken token = super.beforeInvocation(fi); try &#123; //执行下一个拦截器 fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; finally &#123; //完成后续工作，类似于aop中的after super.afterInvocation(token, null); &#125; &#125; //... //资源源数据定义，设置为自定义的SecureResourceFilterInvocationDefinitionSource @Override public SecurityMetadataSource obtainSecurityMetadataSource() &#123; return invocationSource; &#125;&#125; 上面自定义的CustomSecurityFilter，与我们之前的讲解是一样的流程。主要依赖的三个接口都有在实现中实例化注入。看下父类的beforeInvocation方法，其中省略了一些不重要的代码片段。 12345678910111213141516171819protected InterceptorStatusToken beforeInvocation(Object object) &#123; //根据SecurityMetadataSource获取配置的权限属性 Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object); //... //判断是否需要对认证实体重新认证，默认为否 Authentication authenticated = authenticateIfRequired(); // Attempt authorization try &#123; //决策管理器开始决定是否授权，如果授权失败，直接抛出AccessDeniedException this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException accessDeniedException) &#123; publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, accessDeniedException)); throw accessDeniedException; &#125; &#125; 上面代码可以看出，第一步是根据SecurityMetadataSource获取配置的权限属性，accessDecisionManager会用到权限列表信息。然后判断是否需要对认证实体重新认证，默认为否。第二步是接着决策管理器开始决定是否授权，如果授权失败，直接抛出AccessDeniedException。 (1). 获取配置的权限属性 12345678910111213141516171819202122232425262728293031323334353637383940public class SecureResourceFilterInvocationDefinitionSource implements FilterInvocationSecurityMetadataSource, InitializingBean &#123; private PathMatcher matcher; //map保存配置的URL对应的权限集 private static Map&lt;String, Collection&lt;ConfigAttribute&gt;&gt; map = new HashMap&lt;&gt;(); //根据传入的对象URL进行循环 @Override public Collection&lt;ConfigAttribute&gt; getAttributes(Object o) throws IllegalArgumentException &#123; logger.info("getAttributes"); //应该做instanceof FilterInvocation filterInvocation = (FilterInvocation) o; //String method = filterInvocation.getHttpRequest().getMethod(); String requestURI = filterInvocation.getRequestUrl(); //循环资源路径，当访问的Url和资源路径url匹配时，返回该Url所需要的权限 for (Iterator&lt;Map.Entry&lt;String, Collection&lt;ConfigAttribute&gt;&gt;&gt; iterator = map.entrySet().iterator(); iter.hasNext(); ) &#123; Map.Entry&lt;String, Collection&lt;ConfigAttribute&gt;&gt; entry = iterator.next(); String url = entry.getKey(); if (matcher.match(url, requestURI)) &#123; return map.get(requestURI); &#125; &#125; return null; &#125; //... //设置权限集，即上述的map @Override public void afterPropertiesSet() throws Exception &#123; logger.info("afterPropertiesSet"); //用来匹配访问资源路径 this.matcher = new AntPathMatcher(); //可以有多个权限 Collection&lt;ConfigAttribute&gt; atts = new ArrayList&lt;&gt;(); ConfigAttribute c1 = new SecurityConfig("ROLE_ADMIN"); atts.add(c1); map.put("/oauth/check_token", atts); &#125;&#125; 上面是getAttributes()实现的具体细节，将请求的URL取出进行匹配事先设定的受限资源，最后返回需要的权限、角色。系统在启动的时候就会读取到配置的map集合，对于拦截到请求进行匹配。代码中注释比较详细，这边不多说。 (2). 决策管理器 1234567891011121314151617181920212223242526272829public class SecurityAccessDecisionManager implements AccessDecisionManager &#123; //... @Override public void decide(Authentication authentication, Object o, Collection&lt;ConfigAttribute&gt; collection) throws AccessDeniedException, InsufficientAuthenticationException &#123; logger.info("decide url and permission"); //集合为空 if (collection == null) &#123; return; &#125; Iterator&lt;ConfigAttribute&gt; ite = collection.iterator(); //判断用户所拥有的权限，是否符合对应的Url权限，如果实现了UserDetailsService，则用户权限是loadUserByUsername返回用户所对应的权限 while (ite.hasNext()) &#123; ConfigAttribute ca = ite.next(); String needRole = ca.getAttribute(); for (GrantedAuthority ga : authentication.getAuthorities()) &#123; logger.info("GrantedAuthority: &#123;&#125;", ga); if (needRole.equals(ga.getAuthority())) &#123; return; &#125; &#125; &#125; logger.error("AccessDecisionManager: no right!"); throw new AccessDeniedException("no right!"); &#125; //...&#125; 上面的代码是决策管理器的实现，其逻辑也比较简单，将请求所具有的权限与设定的受限资源所需的进行匹配，如果具有则返回，否则抛出没有正确的权限异常。默认提供的决策管理器有三种，分别为AffirmativeBased、ConsensusBased、UnanimousBased，篇幅有限，我们这边不再扩展了。 补充一下，所具有的权限是通过之前配置的认证方式，有password认证和client认证两种。我们之前在授权服务器中配置了withClientDetails，所以用frontend身份验证获得的权限是我们预先配置在数据库中的authorities。 4. 总结Auth系统主要功能是授权认证和鉴权。项目微服务化后，原有的单体应用基于HttpSession认证鉴权不能满足微服务架构下的需求。每个微服务都需要对访问进行鉴权，每个微应用都需要明确当前访问用户以及其权限，尤其当有多个客户端，包括web端、移动端等等，单体应用架构下的鉴权方式就不是特别合适了。权限服务作为基础的公共服务，也需要微服务化。 笔者的设计中，Auth服务一方面进行授权认证，另一方面是基于token进行身份合法性和API级别的权限校验。对于某个服务的请求，经过网关会调用Auth服务，对token合法性进行验证。同时笔者根据当前项目的整体情况，存在部分遗留服务，这些遗留服务又没有足够的时间和人力立马进行微服务改造，而且还需要继续运行。为了适配当前新的架构，采取的方案就是对这些遗留服务的操作API，在Auth服务进行API级别的操作权限鉴定。API级别的操作权限校验需要的上下文信息需要结合业务，与客户端进行商定，应该在token能取到相应信息，传递给Auth服务，不过应尽量减少在header取上下文校验的信息。 笔者将本次开发Auth系统所涉及的大部分代码及源码进行了解析，至于没有讲到的一些内容和细节，读者可以自行扩展。 5. 不足与后续工作5.1 存在的不足 API级别操作权限校验的通用性 (1). 对于API级别操作权限校验，需要在网关处调用时构造相应的上下文信息。上下文信息基本依赖于 token中的payload，如果信息太多引起token太长，导致每次客户端的请求头部长度变长。 (2). 并不是所有的操作接口都能覆盖到，这个问题是比较严重的，根据上下文集合很可能出现好多接口 的权限没法鉴定，最后的结果就是API级别操作权限校验失败的是绝对没有权限访问该接口，而通过不一定能访问，因为该接口涉及到的上下文根本没法完全得到。我们的项目在现阶段，定义的最小上下文集合能勉强覆盖到，但是对于后面扩增的服务接口真的是不乐观。 (3). 每个服务的每个接口都在Auth服务注册其所需要的权限，太过麻烦，Auth服务需要额外维护这样的信息。 网关处调用Auth服务带来的系统吞吐量瓶颈 (1). 这个其实很容易理解，Auth服务作为公共的基础服务，大多数服务接口都会需要鉴权，Auth服务需要经过复杂。 (2). 网关调用Auth服务，阻塞调用，只有等Auth服务返回校验结果，才会做进一步处理。虽说Auth服务可以多实例部署，但是并发量大了之后，其瓶颈明显可见，严重可能会造成整个系统的不可用。 5.2 后续工作 从整个系统设计角度来讲，API级别操作权限后期将会分散在各个服务的接口上，由各个接口负责其所需要的权限、身份等。Spring Security对于接口级别的权限校验也是支持的，之所以采用这样的做法，也是为了兼容新服务和遗留的服务，主要是针对遗留服务，新的服务采用的是分散在各个接口之上。 将API级别操作权限分散到各个服务接口之后，相应的能提升Auth服务的响应。网关能够及时的对请求进行转发或者拒绝。 API级别操作权限所需要的上下文信息对各个接口真的设计的很复杂，这边我们确实花了时间，同时管理移动服务的好几百操作接口所对应的权限，非常烦。！ 本文的源码地址：GitHub：https://github.com/keets2012/Auth-service码云： https://gitee.com/keets/Auth-Service 参考 配置表单登录 Spring Security3源码分析-FilterSecurityInterceptor分析 Core Security Filters Spring Security(四)–核心过滤器源码分析 相关阅读认证鉴权与API权限控制在微服务架构中的设计与实现（一）认证鉴权与API权限控制在微服务架构中的设计与实现（二）认证鉴权与API权限控制在微服务架构中的设计与实现（三）]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Spring Security</tag>
        <tag>OAuth2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认证鉴权与API权限控制在微服务架构中的设计与实现（三）]]></title>
    <url>%2F2017%2F10%2F24%2Fsecurity3%2F</url>
    <content type="text"><![CDATA[引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第三篇，本文重点讲解token以及API级别的鉴权。本文对涉及到的大部分代码进行了分析，欢迎订阅本系列文章。 1. 前文回顾在开始讲解这一篇文章之前，先对之前两篇文章进行回忆下。在第一篇 认证鉴权与API权限控制在微服务架构中的设计与实现（一）介绍了该项目的背景以及技术调研与最后选型。第二篇认证鉴权与API权限控制在微服务架构中的设计与实现（二）画出了简要的登录和校验的流程图，并重点讲解了用户身份的认证与token发放的具体实现。 本文重点讲解鉴权，包括两个方面：token合法性以及API级别的操作权限。首先token合法性很容易理解，第二篇文章讲解了获取授权token的一系列流程，token是否是认证服务器颁发的，必然是需要验证的。其次对于API级别的操作权限，将上下文信息不具备操作权限的请求直接拒绝，当然此处是设计token合法性校验在先，其次再对操作权限进行验证，如果前一个验证直接拒绝，通过则进入操作权限验证。 2.资源服务器配置ResourceServer配置在第一篇就列出了，在进入鉴权之前，把这边的配置搞清，即使有些配置在本项目中没有用到，大家在自己的项目有可能用到。 1234567891011121314151617181920212223242526272829303132333435@Configuration@EnableResourceServerpublic class ResourceServerConfig extends ResourceServerConfigurerAdapter &#123; //http安全配置 @Override public void configure(HttpSecurity http) throws Exception &#123; //禁掉csrf，设置session策略 http.csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and()//默认允许访问 .requestMatchers().antMatchers("/**") .and().authorizeRequests() .antMatchers("/**").permitAll() .anyRequest().authenticated() .and().logout() //logout注销端点配置 .logoutUrl("/logout") .clearAuthentication(true) .logoutSuccessHandler(new HttpStatusReturningLogoutSuccessHandler()) .addLogoutHandler(customLogoutHandler()); &#125; //添加自定义的CustomLogoutHandler @Bean public CustomLogoutHandler customLogoutHandler() &#123; return new CustomLogoutHandler(); &#125; //资源安全配置相关 @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &#123; super.configure(resources); &#125;&#125; (1). @EnableResourceServer这个注解很重要，OAuth2资源服务器的简便注解。其使得Spring Security filter通过请求中的OAuth2 token来验证请求。通常与EnableWebSecurity配合使用，该注解还创建了硬编码的@Order(3) WebSecurityConfigurerAdapter，由于当前spring的技术，order的顺序不易修改，所以在项目中避免还有其他order=3的配置。 (2). 关联的HttpSecurity，与之前的 Spring Security XML中的 “http”元素配置类似，它允许配置基于web安全以针对特定http请求。默认是应用到所有的请求，通过requestMatcher可以限定具体URL范围。HttpSecurity类图如下。 总的来说：HttpSecurity是SecurityBuilder接口的一个实现类，从名字上我们就可以看出这是一个HTTP安全相关的构建器。当然我们在构建的时候可能需要一些配置，当我们调用HttpSecurity对象的方法时，实际上就是在进行配置。 authorizeRequests()，formLogin()、httpBasic()这三个方法返回的分别是ExpressionUrlAuthorizationConfigurer、FormLoginConfigurer、HttpBasicConfigurer，他们都是SecurityConfigurer接口的实现类，分别代表的是不同类型的安全配置器。因此，从总的流程上来说，当我们在进行配置的时候，需要一个安全构建器SecurityBuilder(例如我们这里的HttpSecurity)，SecurityBuilder实例的创建需要有若干安全配置器SecurityConfigurer实例的配合。 (3).关联的ResourceServerSecurityConfigurer，为资源服务器添加特殊的配置，默认的适用于很多应用，但是这边的修改至少以resourceId为单位。类图如下。 ResourceServerSecurityConfigurer创建了OAuth2核心过滤器OAuth2AuthenticationProcessingFilter，并为其提供固定了OAuth2AuthenticationManager。只有被OAuth2AuthenticationProcessingFilter拦截到的oauth2相关请求才被特殊的身份认证器处理。同时设置了TokenExtractor、异常处理实现。 OAuth2AuthenticationProcessingFilter是OAuth2保护资源的预先认证过滤器。配合OAuth2AuthenticationManager使用，根据请求获取到OAuth2 token，之后就会使用OAuth2Authentication来填充Spring Security上下文。OAuth2AuthenticationManager在前面的文章给出的AuthenticationManager类图就出现了，与token认证相关。这边略过贴出源码进行讲解，读者可以自行阅读。 3. 鉴权endpoint鉴权主要是使用内置的endpoint /oauth/check_token，笔者将对端点的分析放在前面，因为这是鉴权的唯一入口。下面我们来看下该API接口中的主要代码。 123456789101112131415161718192021222324252627282930@RequestMapping(value = "/oauth/check_token") @ResponseBody public Map&lt;String, ?&gt; checkToken(CheckTokenEntity checkTokenEntity) &#123; //CheckTokenEntity为自定义的dto Assert.notNull(checkTokenEntity, "invalid token entity!"); //识别token OAuth2AccessToken token = resourceServerTokenServices.readAccessToken(checkTokenEntity.getToken()); //判断token是否为空 if (token == null) &#123; throw new InvalidTokenException("Token was not recognised"); &#125; //未过期 if (token.isExpired()) &#123; throw new InvalidTokenException("Token has expired"); &#125; //加载OAuth2Authentication OAuth2Authentication authentication = resourceServerTokenServices.loadAuthentication(token.getValue()); //获取response，token合法性验证完毕 Map&lt;String, Object&gt; response = (Map&lt;String, Object&gt;) accessTokenConverter.convertAccessToken(token, authentication); //check for api permission if (response.containsKey("jti")) &#123; //上下文操作权限校验 Assert.isTrue(checkPermissions.checkPermission(checkTokenEntity)); &#125; response.put("active", true); // Always true if token exists and not expired return response; &#125; 看过security-oauth源码的同学可能立马就看出上述代码与源码不同，熟悉/oauth/check_token校验流程的也会看出来，这边笔者对security-oauth jar进行了重新编译，修改了部分源码用于该项目需求的场景。主要是加入了前置的API级别的权限校验。 4. token 合法性验证从上面的CheckTokenEndpoint中可以看出，对于token合法性验证首先是识别请求体中的token。用到的主要方法是ResourceServerTokenServices提供的readAccessToken()方法。该接口的实现类为DefaultTokenServices，在之前的配置中有讲过这边配置了jdbc的TokenStore。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class JdbcTokenStore implements TokenStore &#123; ... public OAuth2AccessToken readAccessToken(String tokenValue) &#123; OAuth2AccessToken accessToken = null; try &#123; //使用selectAccessTokenSql语句，调用了私有的extractTokenKey()方法 accessToken = jdbcTemplate.queryForObject(selectAccessTokenSql, new RowMapper&lt;OAuth2AccessToken&gt;() &#123; public OAuth2AccessToken mapRow(ResultSet rs, int rowNum) throws SQLException &#123; return deserializeAccessToken(rs.getBytes(2)); &#125; &#125;, extractTokenKey(tokenValue)); &#125; //异常情况 catch (EmptyResultDataAccessException e) &#123; if (LOG.isInfoEnabled()) &#123; LOG.info("Failed to find access token for token " + tokenValue); &#125; &#125; catch (IllegalArgumentException e) &#123; LOG.warn("Failed to deserialize access token for " + tokenValue, e); //不合法则移除 removeAccessToken(tokenValue); &#125; return accessToken; &#125; ... //提取TokenKey方法 protected String extractTokenKey(String value) &#123; if (value == null) &#123; return null; &#125; MessageDigest digest; try &#123; //MD5 digest = MessageDigest.getInstance("MD5"); &#125; catch (NoSuchAlgorithmException e) &#123; throw new IllegalStateException("MD5 algorithm not available. Fatal (should be in the JDK)."); &#125; try &#123; byte[] bytes = digest.digest(value.getBytes("UTF-8")); return String.format("%032x", new BigInteger(1, bytes)); &#125; catch (UnsupportedEncodingException e) &#123; throw new IllegalStateException("UTF-8 encoding not available. Fatal (should be in the JDK)."); &#125; &#125;&#125; readAccessToken()检索出该token值的完整信息。上述代码比较简单，涉及到的逻辑也不复杂，此处简单讲解。下图为debug token校验的变量信息，读者可以自己动手操作下，截图仅供参考。 至于后面的步骤，loadAuthentication()为特定的access token 加载credentials。得到的credentials 与token作为convertAccessToken()参数，得到校验token的response。 5. API级别权限校验笔者项目目前都是基于Web的权限验证，之前遗留的一个巨大的单体应用系统正在逐渐拆分，然而当前又不能完全拆分完善。为了同时兼容新旧服务，尽量减少对业务系统的入侵，实现微服务的统一性和独立性。笔者根据业务业务场景，尝试在Auth处做操作权限校验。首先想到的是资源服务器配置ResourceServer，如： 12http.authorizeRequests().antMatchers(&quot;/order/**&quot;).access(&quot;#oauth2.hasScope(&apos;select&apos;) and hasRole(&apos;ROLE_USER&apos;)&quot;) 这样做需要将每个操作接口的API权限控制放在各个不同的业务服务，每个服务在接收到请求后，需要先从Auth服务取出该token 对应的role和scope等权限信息。这个方法肯定是可行的，但是由于项目鉴权的粒度更细，而且暂时不想大动原有系统，在加上之前网关设计，网关调用Auth服务校验token合法性，所以最后决定在Auth系统调用中，把这些校验一起解决完。 文章开头资源服务器的配置代码可以看出，对于所有的资源并没有做拦截，因为网关处是调用Auth系统的相关endpoint，并不是所有的请求url都会经过一遍Auth系统，所以对于所有的资源，在Auth系统中，定义需要鉴权接口所需要的API权限，然后根据上下文进行匹配。这是采用的第二种方式，也是笔者目前采用的方法。当然这种方式的弊端也很明显，一旦并发量大，网关还要耗时在调用Auth系统的鉴权上，TPS势必要下降很多，对于一些不需要鉴权的服务接口也会引起不可用。另外一点是，对于某些特殊权限的接口，需要的上下文信息很多，可能并不能完全覆盖，对于此，笔者的解决是分两方面：一是尽量将这些特殊情况进行分类，某一类的情况统一解决；二是将严苛的校验降低，对于上下文校验失败的直接拒绝，而通过的，对于某些接口，在接口内进行操作之前，对特殊的地方还要再次进行校验。 上面在讲endpoint有提到这边对源码进行了改写。CheckTokenEntity是自定义的DTO，这这个类中定义了鉴权需要的上下文，这里是指能校验操作权限的最小集合，如URI、roleId、affairId等等。另外定义了CheckPermissions接口，其方法checkPermission(CheckTokenEntity checkTokenEntity)返回了check的结果。而其具体实现类则定义在Auth系统中。笔者项目中调用的实例如下： 12345678910111213141516171819@Componentpublic class CustomCheckPermission implements CheckPermissions &#123; @Autowired private PermissionService permissionService; @Override public boolean checkPermission(CheckTokenEntity checkTokenEntity) &#123; String url = checkTokenEntity.getUri(); Long affairId = checkTokenEntity.getAffairId(); Long roleId = checkTokenEntity.getRoleId(); //校验 if (StringUtils.isEmpty(url) || affairId &lt;= 0 || roleId &lt;= 0) &#123; return true; &#125; else &#123; return permissionService.checkPermission(url, affairId, roleId); &#125; &#125;&#125; 关于jar包spring-cloud-starter-oauth2中的具体修改内容，大家可以看下文末笔者的GitHub项目。通过自定义CustomCheckPermission，覆写checkPermission()方法，大家也可以对自己业务的操作权限进行校验，非常灵活。这边涉及到具体业务，笔者在项目中只提供接口，具体的实现需要读者自行完成。 6. 总结本文相对来说比较简单，主要讲解了token以及API级别的鉴权。token的合法性认证很常规，Auth系统对于API级别的鉴权是结合自身业务需要和现状进行的设计。这两块的校验都前置到Auth系统中，优缺点在上面的小节也有讲述。最后，架构设计根据自己的需求和现状，笔者的解决思路仅供参考。 本文的源码地址：GitHub：https://github.com/keets2012/Auth-service码云： https://gitee.com/keets/Auth-Service 参考 微服务API级权限的技术架构 spring-security-oauth Spring-Security Docs 相关阅读认证鉴权与API权限控制在微服务架构中的设计与实现（一）认证鉴权与API权限控制在微服务架构中的设计与实现（二）]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Spring Security</tag>
        <tag>OAuth2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认证鉴权与API权限控制在微服务架构中的设计与实现（二）]]></title>
    <url>%2F2017%2F10%2F22%2Fsecurity2%2F</url>
    <content type="text"><![CDATA[引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第二篇，本文重点讲解用户身份的认证与token发放的具体实现。本文篇幅较长，对涉及到的大部分代码进行了分析，可收藏于闲暇时间阅读，欢迎订阅本系列文章。 1. 系统概览在上一篇 认证鉴权与API权限控制在微服务架构中的设计与实现（一）介绍了该项目的背景以及技术调研与最后选型，并且对于最终实现的endpoint执行结果进行展示。对系统架构虽然有提到，但是并未列出详细流程图。在笔者的应用场景中，Auth系统与网关进行结合。在网关出配置相应的端点信息，如登录系统申请token授权，校验check_token等端点。 下图为网关与Auth系统结合的流程图，网关系统的具体实现细节在后面另写文章介绍。（此处流程图的绘制中，笔者使用极简的语言描述，各位同学轻喷😆！） 上图展示了系统登录的简单流程，其中的细节有省略，用户信息的合法性校验实际是调用用户系统。大体流程是这样，客户端请求到达网关之后，根据网关识别的请求登录端点，转发到Auth系统，将用户的信息进行校验。 另一方面是对于一般请求的校验。一些不需要权限的公开接口，在网关处配置好，请求到达网关后，匹配了路径将会直接放行。如果需要对该请求进行校验，会将该请求的相关验证信息截取，以及API权限校验所需的上下文信息（笔者项目对于一些操作进行权限前置验证，下一篇章会讲到），调用Auth系统，校验成功后进行路由转发。 这篇文章就重点讲解我们在第一篇文章中提到的用户身份的认证与token发放。这个也主要包含两个方面： 用户合法性的认证 获取到授权的token 2. 配置与类图2.1 AuthorizationServer主要配置关于AuthorizationServer和ResourceServer的配置在上一篇文章已经列出。AuthorizationServer主要是继承了AuthorizationServerConfigurerAdapter，覆写了其实现接口的三个方法： 1234567891011121314//对应于配置AuthorizationServer安全认证的相关信息，创建ClientCredentialsTokenEndpointFilter核心过滤器@Overridepublic void configure(AuthorizationServerSecurityConfigurer security) throws Exception &#123; &#125;//配置OAuth2的客户端相关信息@Overridepublic void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123;&#125;//配置身份认证器，配置认证方式，TokenStore，TokenGranter，OAuth2RequestFactory@Overridepublic void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123;&#125; 2.2 主要Authentication类的类图 主要的验证方法authenticate(Authentication authentication)在接口AuthenticationManager中，其实现类有ProviderManager，有上图可以看出ProviderManager又依赖于AuthenticationProvider接口，其定义了一个List&lt;AuthenticationProvider&gt;全局变量。笔者这边实现了该接口的实现类CustomAuthenticationProvider。自定义一个provider，并在GlobalAuthenticationConfigurerAdapter中配置好改自定义的校验provider，覆写configure()方法。 123456789101112@Configurationpublic class AuthenticationManagerConfig extends GlobalAuthenticationConfigurerAdapter &#123; @Autowired CustomAuthenticationProvider customAuthenticationProvider; @Override public void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.authenticationProvider(customAuthenticationProvider);//使用自定义的AuthenticationProvider &#125;&#125; AuthenticationManagerBuilder是用来创建AuthenticationManager，允许自定义提供多种方式的AuthenticationProvider，比如LDAP、基于JDBC等等。 3. 认证与授权token下面讲解认证与授权token主要的类与接口。 3.1 内置端点TokenEndpointSpring-Security-Oauth2的提供的jar包中内置了与token相关的基础端点。本文认证与授权token与/oauth/token有关，其处理的接口类为TokenEndpoint。下面我们来看一下对于认证与授权token流程的具体处理过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@FrameworkEndpointpublic class TokenEndpoint extends AbstractEndpoint &#123; ... @RequestMapping(value = "/oauth/token", method=RequestMethod.POST) public ResponseEntity&lt;OAuth2AccessToken&gt; postAccessToken(Principal principal, @RequestParam Map&lt;String, String&gt; parameters) throws HttpRequestMethodNotSupportedException &#123; //首先对client信息进行校验 if (!(principal instanceof Authentication)) &#123; throw new InsufficientAuthenticationException( "There is no client authentication. Try adding an appropriate authentication filter."); &#125; String clientId = getClientId(principal); //根据请求中的clientId，加载client的具体信息 ClientDetails authenticatedClient = getClientDetailsService().loadClientByClientId(clientId); TokenRequest tokenRequest = getOAuth2RequestFactory().createTokenRequest(parameters, authenticatedClient); ... //验证scope域范围 if (authenticatedClient != null) &#123; oAuth2RequestValidator.validateScope(tokenRequest, authenticatedClient); &#125; //授权方式不能为空 if (!StringUtils.hasText(tokenRequest.getGrantType())) &#123; throw new InvalidRequestException("Missing grant type"); &#125; //token endpoint不支持Implicit模式 if (tokenRequest.getGrantType().equals("implicit")) &#123; throw new InvalidGrantException("Implicit grant type not supported from token endpoint"); &#125; ... //进入CompositeTokenGranter，匹配授权模式，然后进行password模式的身份验证和token的发放 OAuth2AccessToken token = getTokenGranter().grant(tokenRequest.getGrantType(), tokenRequest); if (token == null) &#123; throw new UnsupportedGrantTypeException("Unsupported grant type: " + tokenRequest.getGrantType()); &#125; return getResponse(token); &#125; ...&#125; 上面给代码进行了注释，读者感兴趣可以看看。接口处理的主要流程就是对authentication信息进行检查是否合法，不合法直接抛出异常，然后对请求的GrantType进行处理，根据GrantType，进行password模式的身份验证和token的发放。下面我们来看下TokenGranter的类图。 可以看出TokenGranter的实现类CompositeTokenGranter中有一个List&lt;TokenGranter&gt;，对应五种GrantType的实际授权实现。这边涉及到的getTokenGranter()，代码也列下： 123456789101112131415161718192021public class CompositeTokenGranter implements TokenGranter &#123; //GrantType的集合，有五种，之前有讲 private final List&lt;TokenGranter&gt; tokenGranters; public CompositeTokenGranter(List&lt;TokenGranter&gt; tokenGranters) &#123; this.tokenGranters = new ArrayList&lt;TokenGranter&gt;(tokenGranters); &#125; //遍历list，匹配到相应的grantType就进行处理 public OAuth2AccessToken grant(String grantType, TokenRequest tokenRequest) &#123; for (TokenGranter granter : tokenGranters) &#123; OAuth2AccessToken grant = granter.grant(grantType, tokenRequest); if (grant!=null) &#123; return grant; &#125; &#125; return null; &#125; ...&#125; 本次请求是使用的password模式，随后进入其GrantType具体的处理流程，下面是grant()方法。 1234567891011121314151617181920212223242526public OAuth2AccessToken grant(String grantType, TokenRequest tokenRequest) &#123; if (!this.grantType.equals(grantType)) &#123; return null; &#125; String clientId = tokenRequest.getClientId(); //加载clientId对应的ClientDetails，为了下一步的验证 ClientDetails client = clientDetailsService.loadClientByClientId(clientId); //再次验证clientId是否拥有该grantType模式，安全 validateGrantType(grantType, client); //获取token return getAccessToken(client, tokenRequest);&#125;protected OAuth2AccessToken getAccessToken(ClientDetails client, TokenRequest tokenRequest) &#123;//进入创建token之前，进行身份验证 return tokenServices.createAccessToken(getOAuth2Authentication(client, tokenRequest));&#125;protected OAuth2Authentication getOAuth2Authentication(ClientDetails client, TokenRequest tokenRequest) &#123;//身份验证 OAuth2Request storedOAuth2Request = requestFactory.createOAuth2Request(client, tokenRequest); return new OAuth2Authentication(storedOAuth2Request, null);&#125; 上面一段代码是grant()方法具体的实现细节。GrantType匹配到其对应的grant()后，先进行基本的验证确保安全，然后进入主流程，就是下面小节要讲的验证身份和发放token。 3.2 自定义的验证类CustomAuthenticationProviderCustomAuthenticationProvider中定义了验证方法的具体实现。其具体实现如下所示。 1234567891011121314151617181920212223242526//主要的自定义验证方法@Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; String username = authentication.getName(); String password = (String) authentication.getCredentials(); Map data = (Map) authentication.getDetails(); String clientId = (String) data.get("client"); Assert.hasText(clientId,"clientId must have value" ); String type = (String) data.get("type"); //通过调用user服务，校验用户信息 Map map = userClient.checkUsernameAndPassword(getUserServicePostObject(username, password, type)); //校验返回的信息，不正确则抛出异常，授权失败 String userId = (String) map.get("userId"); if (StringUtils.isBlank(userId)) &#123; String errorCode = (String) map.get("code"); throw new BadCredentialsException(errorCode); &#125; CustomUserDetails customUserDetails = buildCustomUserDetails(username, password, userId, clientId); return new CustomAuthenticationToken(customUserDetails); &#125; //构造一个CustomUserDetails，简单，略去 private CustomUserDetails buildCustomUserDetails(String username, String password, String userId, String clientId) &#123; &#125;//构造一个请求userService的map，内容略 private Map&lt;String, String&gt; getUserServicePostObject(String username, String password, String type) &#123; &#125; authenticate()最后返回构造的自定义CustomAuthenticationToken，在CustomAuthenticationToken中，将boolean authenticated设为true，user信息验证成功。这边传入的参数CustomUserDetails与token生成有关，作为payload中的信息，下面会讲到。 12345678910//继承抽象类AbstractAuthenticationTokenpublic class CustomAuthenticationToken extends AbstractAuthenticationToken &#123; private CustomUserDetails userDetails; public CustomAuthenticationToken(CustomUserDetails userDetails) &#123; super(null); this.userDetails = userDetails; super.setAuthenticated(true); &#125; ...&#125; 而AbstractAuthenticationToken实现了接口Authentication和CredentialsContainer，里面的具体信息读者可以自己看下源码。 3.3 关于JWT用户信息校验完成之后，下一步则是要对该用户进行授权。在讲具体的授权之前，先补充下关于JWT Token的相关知识点。 Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准(RFC 7519)。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 从上面的描述可知JWT的定义，这边读者可以对比下token的认证和传统的session认证的区别。推荐一篇文章什么是 JWT – JSON WEB TOKEN，笔者这边就不详细扩展讲了，只是简单介绍下其构成。 JWT包含三部分：header头部、payload信息、signature签名。下面以上一篇生成好的access_token为例介绍。 headerjwt的头部承载两部分信息，一是声明类型，这里是jwt；二是声明加密的算法 通常直接使用 HMAC SHA256。第一部分一般固定为： 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 playload存放的有效信息，这些有效信息包含三个部分、标准中注册的声明、公共的声明、私有的声明。这边笔者额外添加的信息为X-KEETS-UserId和X-KEETS-ClientId。读者可根据实际项目需要进行定制。最后playload经过base64编码后的结果为： 1eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ signaturejwt的第三部分是一个签证信息，这个签证信息由三部分组成：header (base64后的)、payload (base64后的)、secret。关于secret，细心的读者可能会发现之前的配置里面有具体设置。前两部分连接组成的字符串，通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。第三部分结果为： 15ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo 至于具体应用方法，可以参见第一篇文章中构建的/logout端点。 3.3 自定义的AuthorizationTokenServices现在到了为用户创建token，这边主要与自定义的接口AuthorizationServerTokenServices有关。AuthorizationServerTokenServices主要有如下三个方法： 1234567//创建tokenOAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException;//刷新tokenOAuth2AccessToken refreshAccessToken(String refreshToken, TokenRequest tokenRequest) throws AuthenticationException;//获取tokenOAuth2AccessToken getAccessToken(OAuth2Authentication authentication); 由于篇幅限制，笔者这边仅对createAccessToken()的实现方法进行分析，其他的方法实现，读者可以下关注笔者的GitHub项目。 1234567891011121314151617181920212223242526272829303132public class CustomAuthorizationTokenServices implements AuthorizationServerTokenServices, ConsumerTokenServices &#123; ... public OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException &#123; //通过TokenStore，获取现存的AccessToken OAuth2AccessToken existingAccessToken = tokenStore.getAccessToken(authentication); OAuth2RefreshToken refreshToken; //移除已有的AccessToken和refreshToken if (existingAccessToken != null) &#123; if (existingAccessToken.getRefreshToken() != null) &#123; refreshToken = existingAccessToken.getRefreshToken(); // The token store could remove the refresh token when the // access token is removed, but we want to be sure tokenStore.removeRefreshToken(refreshToken); &#125; tokenStore.removeAccessToken(existingAccessToken); &#125; //recreate a refreshToken refreshToken = createRefreshToken(authentication); OAuth2AccessToken accessToken = createAccessToken(authentication, refreshToken); if (accessToken != null) &#123; tokenStore.storeAccessToken(accessToken, authentication); &#125; refreshToken = accessToken.getRefreshToken(); if (refreshToken != null) &#123; tokenStore.storeRefreshToken(refreshToken, authentication); &#125; return accessToken; &#125; ...&#125; 这边具体的实现在上面有注释，基本没有改写多少，读者此处可以参阅源码。createAccessToken()还调用了两个私有方法，分别创建accessToken和refreshToken。创建accessToken，需要基于refreshToken。此处可以自定义设置token的时效长度，accessToken创建实现如下： 1234567891011121314151617private int refreshTokenValiditySeconds = 60 * 60 * 24 * 30; // default 30 days. private int accessTokenValiditySeconds = 60 * 60 * 12; // default 12 hours. private OAuth2AccessToken createAccessToken(OAuth2Authentication authentication, OAuth2RefreshToken refreshToken) &#123; //对应tokenId，存储的标识 DefaultOAuth2AccessToken token = new DefaultOAuth2AccessToken(UUID.randomUUID().toString()); int validitySeconds = getAccessTokenValiditySeconds(authentication.getOAuth2Request()); if (validitySeconds &gt; 0) &#123; token.setExpiration(new Date(System.currentTimeMillis() + (validitySeconds * 1000L))); &#125; token.setRefreshToken(refreshToken); //scope对应作用范围 token.setScope(authentication.getOAuth2Request().getScope());//上一节介绍的自定义TokenEnhancer，这边使用 return accessTokenEnhancer != null ? accessTokenEnhancer.enhance(token, authentication) : token; &#125; 既然提到TokenEnhancer，这边简单贴一下代码。 12345678910111213141516171819202122232425public class CustomTokenEnhancer extends JwtAccessTokenConverter &#123; private static final String TOKEN_SEG_USER_ID = "X-KEETS-UserId"; private static final String TOKEN_SEG_CLIENT = "X-KEETS-ClientId"; @Override public OAuth2AccessToken enhance(OAuth2AccessToken accessToken, OAuth2Authentication authentication) &#123; CustomUserDetails userDetails = (CustomUserDetails) authentication.getPrincipal(); Map&lt;String, Object&gt; info = new HashMap&lt;&gt;(); //从自定义的userDetails中取出UserId info.put(TOKEN_SEG_USER_ID, userDetails.getUserId()); DefaultOAuth2AccessToken customAccessToken = new DefaultOAuth2AccessToken(accessToken); customAccessToken.setAdditionalInformation(info); OAuth2AccessToken enhancedToken = super.enhance(customAccessToken, authentication); //设置ClientId enhancedToken.getAdditionalInformation().put(TOKEN_SEG_CLIENT, userDetails.getClientId()); return enhancedToken; &#125;&#125; 自此，用户身份校验与发放授权token结束。最终成功返回的结果为: 12345678910&#123; &quot;access_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ.5ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeE&quot;, &quot;expires_in&quot;: 43195, &quot;scope&quot;: &quot;all&quot;, &quot;X-KEETS-UserId&quot;: &quot;d6448c24-3c4c-4b80-8372-c2d61868f8c6&quot;, &quot;jti&quot;: &quot;bad72b19-d9f3-4902-affa-0430e7db79ed&quot;, &quot;X-KEETS-ClientId&quot;: &quot;frontend&quot;&#125; 4. 总结本文开头给出了Auth系统概述，画出了简要的登录和校验的流程图，方便读者能对系统的实现有个大概的了解。然后主要讲解了用户身份的认证与token发放的具体实现。对于其中主要的类和接口进行了分析与讲解。下一篇文章主要讲解token的鉴定和API级别的上下文权限校验。 本文的源码地址：GitHub：https://github.com/keets2012/Auth-service码云： https://gitee.com/keets/Auth-Service 参考 什么是 JWT – JSON WEB TOKEN Re：从零开始的Spring Security OAuth2（二） spring-security-oauth 相关阅读认证鉴权与API权限控制在微服务架构中的设计与实现（一）]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Spring Security</tag>
        <tag>OAuth2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认证鉴权与API权限控制在微服务架构中的设计与实现（一）]]></title>
    <url>%2F2017%2F10%2F19%2Fsecurity1%2F</url>
    <content type="text"><![CDATA[引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第一篇，本系列预计四篇文章讲解微服务下的认证鉴权与API权限控制的实现。 1. 背景最近在做权限相关服务的开发，在系统微服务化后，原有的单体应用是基于session的安全权限方式，不能满足现有的微服务架构的认证与鉴权需求。微服务架构下，一个应用会被拆分成若干个微应用，每个微应用都需要对访问进行鉴权，每个微应用都需要明确当前访问用户以及其权限。尤其当访问来源不只是浏览器，还包括其他服务的调用时，单体应用架构下的鉴权方式就不是特别合适了。在微服务架构下，要考虑外部应用接入的场景、用户–服务的鉴权、服务–服务的鉴权等多种鉴权场景。比如用户A访问User Service，A如果未登录，则首先需要登录，请求获取授权token。获取token之后，A将携带着token去请求访问某个文件，这样就需要对A的身份进行校验，并且A可以访问该文件。为了适应架构的变化、需求的变化，auth权限模块被单独出来作为一个基础的微服务系统，为其他业务service提供服务。 2. 系统架构的变更单体应用架构到分布式架构，简化的权限部分变化如下面两图所示。（1）单体应用简化版架构图：（2）分布式应用简化版架构图： 分布式架构，特别是微服务架构的优点是可以清晰的划分出业务逻辑来，让每个微服务承担职责单一的功能，毕竟越简单的东西越稳定。 但是，微服务也带来了很多的问题。比如完成一个业务操作，需要跨很多个微服务的调用，那么如何用权限系统去控制用户对不同微服务的调用，对我们来说是个挑战。当业务微服务的调用接入权限系统后，不能拖累它们的吞吐量，当权限系统出现问题后，不能阻塞它们的业务调用进度，当然更不能改变业务逻辑。新的业务微服务快速接入权限系统相对容易把控，那么对于公司已有的微服务，如何能不改动它们的架构方式的前提下，快速接入，对我们来说，也是一大挑战。 3. 技术方案这主要包括两方面需求：其一是认证与鉴权，对于请求的用户身份的授权以及合法性鉴权；其二是API级别的操作权限控制，这个在第一点之后，当鉴定完用户身份合法之后，对于该用户的某个具体请求是否具有该操作执行权限进行校验。 3.1 认证与鉴权对于第一个需求，笔者调查了一些实现方案： 分布式Session方案分布式会话方案原理主要是将关于用户认证的信息存储在共享存储中，且通常由用户会话作为 key 来实现的简单分布式哈希映射。当用户访问微服务时，用户数据可以从共享存储中获取。在某些场景下，这种方案很不错，用户登录状态是不透明的。同时也是一个高可用且可扩展的解决方案。这种方案的缺点在于共享存储需要一定保护机制，因此需要通过安全链接来访问，这时解决方案的实现就通常具有相当高的复杂性了。 基于OAuth2 Token方案随着 Restful API、微服务的兴起，基于Token的认证现在已经越来越普遍。Token和Session ID 不同，并非只是一个 key。Token 一般会包含用户的相关信息，通过验证 Token 就可以完成身份校验。用户输入登录信息，发送到身份认证服务进行认证。AuthorizationServer验证登录信息是否正确，返回用户基础信息、权限范围、有效时间等信息，客户端存储接口。用户将 Token 放在 HTTP 请求头中，发起相关 API 调用。被调用的微服务，验证Token。ResourceServer返回相关资源和数据。 这边选用了第二种方案，基于OAuth2 Token认证的好处如下： 服务端无状态：Token 机制在服务端不需要存储 session 信息，因为 Token 自身包含了所有用户的相关信息。 性能较好，因为在验证 Token 时不用再去访问数据库或者远程服务进行权限校验，自然可以提升不少性能。 现在很多应用都是同时面向移动端和web端，OAuth2 Token机制可以支持移动设备。 OAuth2与Spring Security结合使用，有提供很多开箱即用的功能，大多特性都可以通过配置灵活的变更。 最后一点，也很重要，Spring Security OAuth2的文档写得较为详细。 oauth2根据使用场景不同，分成了4种模式： 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 对于上述oauth2四种模式不熟的同学，可以自行百度oauth2，阮一峰的文章有解释。常使用的是password模式和client模式。 3.2 操作权限控制对于第二个需求，笔者主要看了Spring Security和Shiro。 ShiroShiro是一个强大而灵活的开源安全框架，能够非常清晰的处理认证、授权、管理会话以及密码加密。Shiro很容易入手，上手快控制粒度可糙可细。自由度高，Shiro既能配合Spring使用也可以单独使用。 Spring SecuritySpring社区生态很强大。除了不能脱离Spring，Spring Security具有Shiro所有的功能。而且Spring Security对Oauth、OpenID也有支持,Shiro则需要自己手动实现。Spring Security的权限细粒度更高。但是Spring Security太过复杂。 看了下网上的评论，貌似一边倒向Shiro。大部分人提出的Spring Security问题就是比较复杂难懂，文档太长。不管是Shiro还是Spring Security，其实现都是基于过滤器，对于自定义实现过滤器，我想对于很多开发者并不是很难，但是这需要团队花费时间与封装可用的jar包出来，对于后期维护和升级，以及功能的扩展。很多中小型公司并不一定具有这样的时间和人力投入这件事。笔者综合评估了下复杂性与所要实现的权限需求，以及上一个需求调研的结果，既然Spring Security功能足够强大且稳定，最终选择了Spring Security。 4. 系统架构4.1 组件Auth系统的最终使用组件如下： 123OAuth2.0 JWT TokenSpring SecuritySpring boot 4.2 步骤主要步骤为： 配置资源服务器和认证服务器 配置Spring Security 上述步骤比较笼统，对于前面小节提到的需求，属于Auth系统的主要内容，笔者后面会另写文章对应讲解。 4.3 endpoint提供的endpoint： 1234567/oauth/token?grant_type=password #请求授权token/oauth/token?grant_type=refresh_token #刷新token/oauth/check_token #校验token/logout #注销token及权限相关信息 4.4 maven依赖主要的jar包，pom.xml文件如下： 12345678910111213141516171819202122232425262728293031323334&lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt; &lt;version&gt;1.2.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;version&gt;1.2.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; 4.5 AuthorizationServer配置文件AuthorizationServer配置主要是覆写如下的三个方法，分别针对endpoints、clients、security配置。 1234567891011121314151617181920@Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &#123; security.tokenKeyAccess("permitAll()").checkTokenAccess("isAuthenticated()"); &#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; //配置客户端认证 clients.withClientDetails(clientDetailsService(dataSource)); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; //配置token的数据源、自定义的tokenServices等信息 endpoints.authenticationManager(authenticationManager) .tokenStore(tokenStore(dataSource)) .tokenServices(authorizationServerTokenServices()) .accessTokenConverter(accessTokenConverter()) .exceptionTranslator(webResponseExceptionTranslator); &#125; 4.6 ResourceServer配置资源服务器的配置，覆写了默认的配置。为了支持logout，这边自定义了一个CustomLogoutHandler并且将logoutSuccessHandler指定为返回http状态的HttpStatusReturningLogoutSuccessHandler。 1234567891011121314@Override public void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .requestMatchers().antMatchers("/**") .and().authorizeRequests() .antMatchers("/**").permitAll() .anyRequest().authenticated() .and().logout() .logoutUrl("/logout") .clearAuthentication(true) .logoutSuccessHandler(new HttpStatusReturningLogoutSuccessHandler()) .addLogoutHandler(customLogoutHandler()); 4.7 执行endpoint 首先执行获取授权的endpoint。 123456789101112method: post url: http://localhost:12000/oauth/token?grant_type=passwordheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=, Content-Type: application/x-www-form-urlencoded&#125;body:&#123; username: keets, password: ***&#125; 上述构造了一个post请求，具体请求写得很详细。username和password是客户端提供给服务器进行校验用户身份信息。header里面的Authorization是存放的clientId和clientSecret经过编码的字符串。返回结果如下： 12345678910&#123; &quot;access_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ.5ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeE&quot;, &quot;expires_in&quot;: 43195, &quot;scope&quot;: &quot;all&quot;, &quot;X-KEETS-UserId&quot;: &quot;d6448c24-3c4c-4b80-8372-c2d61868f8c6&quot;, &quot;jti&quot;: &quot;bad72b19-d9f3-4902-affa-0430e7db79ed&quot;, &quot;X-KEETS-ClientId&quot;: &quot;frontend&quot;&#125; 可以看到在用户名密码通过校验后，客户端收到了授权服务器的response，主要包括access token、refresh token。并且表明token的类型为bearer，过期时间expires_in。笔者在jwt token中加入了自定义的info为UserId和ClientId。 2.鉴权的endpoint 1234567891011method: post url: http://localhost:12000/oauth/check_tokenheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=, Content-Type: application/x-www-form-urlencoded&#125;body:&#123; token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ.5ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo&#125; 上面即为check_token请求的详细信息。需要注意的是，笔者将刚刚授权的token放在了body里面，这边可以有多种方法，此处不扩展。 123456789101112&#123; &quot;X-KEETS-UserId&quot;: &quot;d6448c24-3c4c-4b80-8372-c2d61868f8c6&quot;, &quot;user_name&quot;: &quot;keets&quot;, &quot;scope&quot;: [ &quot;all&quot; ], &quot;active&quot;: true, &quot;exp&quot;: 1508447756, &quot;X-KEETS-ClientId&quot;: &quot;frontend&quot;, &quot;jti&quot;: &quot;bad72b19-d9f3-4902-affa-0430e7db79ed&quot;, &quot;client_id&quot;: &quot;frontend&quot;&#125; 校验token合法后，返回的response如上所示。在response中也是展示了相应的token中的基本信息。 3.刷新token由于token的时效一般不会很长，而refresh token一般周期会很长，为了不影响用户的体验，可以使用refresh token去动态的刷新token。 123456method: post url: http://localhost:12000/oauth/token?grant_type=refresh_token&amp;refresh_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeEheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=&#125; 其response和/oauth/token得到正常的相应是一样的，此处不再列出。 4.注销token 123456method: geturl: http://localhost:9000/logoutheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=&#125; 注销成功则会返回200，注销端点主要是将token和SecurityContextHolder进行清空。 5. 总结本文是《认证鉴权与API权限控制在微服务架构中的设计与实现》系列文章的总述，从遇到的问题着手，介绍了项目的背景。通过调研现有的技术，并结合当前项目的实际，确定了技术选型。最后对于系统的最终的实现进行展示。后面将从实现的细节，讲解本系统的实现。敬请期待后续文章。 参考 理解OAuth 2.0 微服务API级权限的技术架构 微服务架构下的安全认证与鉴权]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Spring Security</tag>
        <tag>OAuth2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件NSQ深入与实践]]></title>
    <url>%2F2017%2F10%2F08%2Fnsq%2F</url>
    <content type="text"><![CDATA[1. 介绍最近在研究一些消息中间件，常用的MQ如RabbitMQ,ActiveMQ,Kafka等。NSQ是一个基于Go语言的分布式实时消息平台，它基于MIT开源协议发布，由bitly公司开源出来的一款简单易用的消息中间件。官方和第三方还为NSQ开发了众多客户端功能库，如官方提供的基于HTTP的nsqd、Go客户端go-nsq、Python客户端pynsq、基于Node.js的JavaScript客户端nsqjs、异步C客户端libnsq、Java客户端nsq-java以及基于各种语言的众多第三方客户端功能库。 1.1 Features1). DistributedNSQ提供了分布式的，去中心化，且没有单点故障的拓扑结构，稳定的消息传输发布保障，能够具有高容错和HA（高可用）特性。2). Scalable易于扩展NSQ支持水平扩展，没有中心化的brokers。内置的发现服务简化了在集群中增加节点。同时支持pub-sub和load-balanced 的消息分发。3). Ops FriendlyNSQ非常容易配置和部署，生来就绑定了一个管理界面。二进制包没有运行时依赖。官方有Docker image。4.Integrated高度集成官方的 Go 和 Python库都有提供。而且为大多数语言提供了库。 1.2 组件 Topic ：一个topic就是程序发布消息的一个逻辑键，当程序第一次发布消息时就会创建topic。 Channels ：channel与消费者相关，是消费者之间的负载均衡，channel在某种意义上来说是一个“队列”。每当一个发布者发送一条消息到一个topic，消息会被复制到所有消费者连接的channel上，消费者通过这个特殊的channel读取消息，实际上，在消费者第一次订阅时就会创建channel。Channel会将消息进行排列，如果没有消费者读取消息，消息首先会在内存中排队，当量太大时就会被保存到磁盘中。 Messages：消息构成了我们数据流的中坚力量，消费者可以选择结束消息，表明它们正在被正常处理，或者重新将他们排队待到后面再进行处理。每个消息包含传递尝试的次数，当消息传递超过一定的阀值次数时，我们应该放弃这些消息，或者作为额外消息进行处理。 nsqd：nsqd 是一个守护进程，负责接收，排队，投递消息给客户端。它可以独立运行，不过通常它是由 nsqlookupd 实例所在集群配置的（它在这能声明 topics 和 channels，以便大家能找到）。 nsqlookupd：nsqlookupd 是守护进程负责管理拓扑信息。客户端通过查询 nsqlookupd 来发现指定话题（topic）的生产者，并且 nsqd 节点广播话题（topic）和通道（channel）信息。有两个接口：TCP 接口，nsqd 用它来广播。HTTP 接口，客户端用它来发现和管理。 nsqadmin：nsqadmin 是一套 WEB UI，用来汇集集群的实时统计，并执行不同的管理任务。 常用工具类： nsq_to _file：消费指定的话题（topic）/通道（channel），并写到文件中，有选择的滚动和/或压缩文件。 nsq_to _http：消费指定的话题（topic）/通道（channel）和执行 HTTP requests (GET/POST) 到指定的端点。 nsq_to _nsq：消费者指定的话题/通道和重发布消息到目的地 nsqd 通过 TCP。 1.3 拓扑结构NSQ推荐通过他们相应的nsqd实例使用协同定位发布者，这意味着即使面对网络分区，消息也会被保存在本地，直到它们被一个消费者读取。更重要的是，发布者不必去发现其他的nsqd节点，他们总是可以向本地实例发布消息。 首先，一个发布者向它的本地nsqd发送消息，要做到这点，首先要先打开一个连接，然后发送一个包含topic和消息主体的发布命令，在这种情况下，我们将消息发布到事件topic上以分散到我们不同的worker中。事件topic会复制这些消息并且在每一个连接topic的channel上进行排队，在我们的案例中，有三个channel，它们其中之一作为档案channel。消费者会获取这些消息并且上传到S3。 每个channel的消息都会进行排队，直到一个worker把他们消费，如果此队列超出了内存限制，消息将会被写入到磁盘中。Nsqd节点首先会向nsqlookup广播他们的位置信息，一旦它们注册成功，worker将会从nsqlookup服务器节点上发现所有包含事件topic的nsqd节点。 然后每个worker向每个nsqd主机进行订阅操作，用于表明worker已经准备好接受消息了。这里我们不需要一个完整的连通图，但我们必须要保证每个单独的nsqd实例拥有足够的消费者去消费它们的消息，否则channel会被队列堆着。 2. Internals2.1 消息传递担保NSQ 保证消息将交付至少一次，虽然消息可能是重复的。消费者应该关注到这一点，删除重复数据或执行idempotent等操作。这个担保是作为协议和工作流的一部分，工作原理如下（假设客户端成功连接并订阅一个话题）：1）客户表示已经准备好接收消息2）NSQ 发送一条消息，并暂时将数据存储在本地（在 re-queue 或 timeout）3）客户端回复 FIN（结束）或 REQ（重新排队）分别指示成功或失败。如果客户端没有回复, NSQ 会在设定的时间超时，自动重新排队消息这确保了消息丢失唯一可能的情况是不正常结束 nsqd 进程。在这种情况下，这是在内存中的任何信息（或任何缓冲未刷新到磁盘）都将丢失。如何防止消息丢失是最重要的，即使是这个意外情况可以得到缓解。一种解决方案是构成冗余 nsqd对（在不同的主机上）接收消息的相同部分的副本。因为你实现的消费者是幂等的，以两倍时间处理这些消息不会对下游造成影响，并使得系统能够承受任何单一节点故障而不会丢失信息。 2.2 简化配置和管理单个 nsqd 实例被设计成可以同时处理多个数据流。流被称为“话题”和话题有 1 个或多个“通道”。每个通道都接收到一个话题中所有消息的拷贝。在实践中，一个通道映射到下行服务消费一个话题。话题和通道都没有预先配置。话题由第一次发布消息到命名的话题或第一次通过订阅一个命名话题来创建。通道被第一次订阅到指定的通道创建。话题和通道的所有缓冲的数据相互独立，防止缓慢消费者造成对其他通道的积压（同样适用于话题级别）。一个通道一般会有多个客户端连接。假设所有已连接的客户端处于准备接收消息的状态，每个消息将被传递到一个随机的客户端。nsqlookupd，它提供了一个目录服务，消费者可以查找到提供他们感兴趣订阅话题的 nsqd 地址 。在配置方面，把消费者与生产者解耦开（它们都分别只需要知道哪里去连接 nsqlookupd 的共同实例，而不是对方），降低复杂性和维护。在更底的层面，每个 nsqd 有一个与 nsqlookupd 的长期 TCP 连接，定期推动其状态。这个数据被 nsqlookupd 用于给消费者通知 nsqd 地址。对于消费者来说，一个暴露的 HTTP /lookup 接口用于轮询。为话题引入一个新的消费者，只需启动一个配置了 nsqlookup 实例地址的 NSQ 客户端。无需为添加任何新的消费者或生产者更改配置，大大降低了开销和复杂性。 2.3 消除单点故障NSQ被设计以分布的方式被使用。nsqd 客户端（通过 TCP ）连接到指定话题的所有生产者实例。没有中间人，没有消息代理，也没有单点故障。这种拓扑结构消除单链，聚合，反馈。相反，你的消费者直接访问所有生产者。从技术上讲，哪个客户端连接到哪个 NSQ 不重要，只要有足够的消费者连接到所有生产者，以满足大量的消息，保证所有东西最终将被处理。对于 nsqlookupd，高可用性是通过运行多个实例来实现。他们不直接相互通信和数据被认为是最终一致。消费者轮询所有的配置的 nsqlookupd 实例和合并 response。失败的，无法访问的，或以其他方式故障的节点不会让系统陷于停顿。 2.4 效率对于数据的协议，通过推送数据到客户端最大限度地提高性能和吞吐量的，而不是等待客户端拉数据。这个概念，称之为 RDY 状态，基本上是客户端流量控制的一种形式。当客户端连接到 nsqd 和并订阅到一个通道时，它被放置在一个 RDY 为 0 状态。这意味着，还没有信息被发送到客户端。当客户端已准备好接收消息发送，更新它的命令 RDY 状态到它准备处理的数量，比如 100。无需任何额外的指令，当 100 条消息可用时，将被传递到客户端（服务器端为那个客户端每次递减 RDY 计数）。客户端库的被设计成在 RDY 数达到配置 max-in-flight 的 25% 发送一个命令来更新 RDY 计数（并适当考虑连接到多个 nsqd 情况下，适当地分配）。 2.5 心跳和超时NSQ 的 TCP 协议是面向 push 的。在建立连接，握手，和订阅后，消费者被放置在一个为 0 的 RDY 状态。当消费者准备好接收消息，它更新的 RDY 状态到准备接收消息的数量。NSQ 客户端库不断在幕后管理，消息控制流的结果。每隔一段时间，nsqd 将发送一个心跳线连接。客户端可以配置心跳之间的间隔，但 nsqd 会期待一个回应在它发送下一个心掉之前。组合应用级别的心跳和 RDY 状态，避免头阻塞现象，也可能使心跳无用（即，如果消费者是在后面的处理消息流的接收缓冲区中，操作系统将被填满，堵心跳）为了保证进度，所有的网络 IO 时间上限势必与配置的心跳间隔相关联。这意味着，你可以从字面上拔掉之间的网络连接 nsqd 和消费者，它会检测并正确处理错误。当检测到一个致命错误，客户端连接被强制关闭。在传输中的消息会超时而重新排队等待传递到另一个消费者。最后，错误会被记录并累计到各种内部指标。 2.6 分布式因为NSQ没有在守护程序之间共享信息，所以它从一开始就是为了分布式操作而生。个别的机器可以随便宕机随便启动而不会影响到系统的其余部分，消息发布者可以在本地发布，即使面对网络分区。这种“分布式优先”的设计理念意味着NSQ基本上可以永远不断地扩展，需要更高的吞吐量？那就添加更多的nsqd吧。唯一的共享状态就是保存在lookup节点上，甚至它们不需要全局视图，配置某些nsqd注册到某些lookup节点上这是很简单的配置，唯一关键的地方就是消费者可以通过lookup节点获取所有完整的节点集。清晰的故障事件——NSQ在组件内建立了一套明确关于可能导致故障的的故障权衡机制，这对消息传递和恢复都有意义。虽然它们可能不像Kafka系统那样提供严格的保证级别，但NSQ简单的操作使故障情况非常明显。 2.7 no replication不像其他的队列组件，NSQ并没有提供任何形式的复制和集群，也正是这点让它能够如此简单地运行，但它确实对于一些高保证性高可靠性的消息发布没有足够的保证。我们可以通过降低文件同步的时间来部分避免，只需通过一个标志配置，通过EBS支持我们的队列。但是这样仍然存在一个消息被发布后马上死亡，丢失了有效的写入的情况。 2.8 没有严格的顺序虽然Kafka由一个有序的日志构成，但NSQ不是。消息可以在任何时间以任何顺序进入队列。在我们使用的案例中，这通常没有关系，因为所有的数据都被加上了时间戳，但它并不适合需要严格顺序的情况。 2.9 无数据重复删除功能NSQ对于超时系统，它使用了心跳检测机制去测试消费者是否存活还是死亡。很多原因会导致我们的consumer无法完成心跳检测，所以在consumer中必须有一个单独的步骤确保幂等性。 3. 实践安装过程本文将nsq集群具体的安装过程略去，大家可以自行参考官网，比较简单。这部分介绍下笔者实验的拓扑，以及nsqadmin的相关信息。 3.1 拓扑结构 实验采用3台NSQD服务，2台LOOKUPD服务。采用官方推荐的拓扑，消息发布的服务和NSQD在一台主机。一共5台机器。NSQ基本没有配置文件，配置通过命令行指定参数。主要命令如下:LOOKUPD命令 1bin/nsqlookupd NSQD命令 1bin/nsqd --lookupd-tcp-address=172.16.30.254:4160 -broadcast-address=172.16.30.254 1bin/nsqadmin --lookupd-http-address=172.16.30.254:4161 工具类，消费后存储到本地文件。 1bin/nsq_to_file --topic=newtest --channel=test --output-dir=/tmp --lookupd-http-address=172.16.30.254:4161 发布一条消息1curl -d 'hello world 5' 'http://172.16.30.254:4151/put?topic=test' 3.2 nsqadmin对Streams的详细信息进行查看，包括NSQD节点，具体的channel，队列中的消息数，连接数等信息。 列出所有的NSQD节点: 消息的统计: lookup主机的列表: 4. 总结NSQ基本核心就是简单性，是一个简单的队列，这意味着它很容易进行故障推理和很容易发现bug。消费者可以自行处理故障事件而不会影响系统剩下的其余部分。 事实上，简单性是我们决定使用NSQ的首要因素，这方便与我们的许多其他软件一起维护，通过引入队列使我们得到了堪称完美的表现，通过队列甚至让我们增加了几个数量级的吞吐量。越来越多的consumer需要一套严格可靠性和顺序性保障，这已经超过了NSQ提供的简单功能。 结合我们的业务系统来看，对于我们所需要传输的发票消息，相对比较敏感，无法容忍某个nsqd宕机，或者磁盘无法使用的情况，该节点堆积的消息无法找回。这是我们没有选择该消息中间件的主要原因。简单性和可靠性似乎并不能完全满足。相比Kafka，ops肩负起更多负责的运营。另一方面，它拥有一个可复制的、有序的日志可以提供给我们更好的服务。但对于其他适合NSQ的consumer，它为我们服务的相当好，我们期待着继续巩固它的坚实的基础。 ps: 本文首发于笔者的csdn博客，此处将其加入个人的博客。 参考 NSQ：分布式的实时消息平台 NSQ - NYC Golang Meetup NSQ Docs]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>Cluster</tag>
        <tag>mq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok使用与原理]]></title>
    <url>%2F2017%2F10%2F06%2Flombok%2F</url>
    <content type="text"><![CDATA[1. Lombok简介首先Lombok是一款Java IDE的应用工具插件，一个可以通过简单的注解形式来帮助我们简化消除一些必须有但显得很臃肿的Java代码的工具，比如属性的构造器、getter、setter、equals、hashcode、toString方法。结合IDE，通过使用对应的注解，可以在编译源码的时候生成对应的方法。官方地址：https://projectlombok.org/。 虽然上述的那些常用方法IDE都能生成，但是lombok更加简洁与方便，能够达到的效果就是在源码中不需要写一些通用的方法，但是在编译生成的字节码文件中会帮我们生成这些方法，这就是lombok的神奇作用。 2. 安装2.1 插件安装笔者主要使用的IDE是Intellij idea，编译器需要在 1preference-&gt;plugins-&gt;Browse repositories 搜索lombok，然后安装plugins，需要稍等片刻。笔者截图已经安装好。 2.2 添加jar包在项目中添加lombok的jar包，笔者用的是maven，所以在pom文件中添加了如下的依赖。gradle使用见官网。 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.16&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3. 使用lombok主要通过注解起作用，详细的注解见Lombok features。 With Lombok: 12345678910111213import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.io.Serializable;@Data@AllArgsConstructorpublic class UserEntity implements Serializable &#123; private long userId; private String userName; private String sex;&#125; 编译后： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import java.beans.ConstructorProperties;import java.io.Serializable;public class UserEntity implements Serializable &#123; private long userId; private String userName; private String sex; public long getUserId() &#123; return this.userId; &#125; public String getUserName() &#123; return this.userName; &#125; public String getSex() &#123; return this.sex; &#125; public void setUserId(long userId) &#123; this.userId = userId; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public boolean equals(Object o) &#123; if(o == this) &#123; return true; &#125; else if(!(o instanceof UserEntity)) &#123; return false; &#125; else &#123; UserEntity other = (UserEntity)o; if(!other.canEqual(this)) &#123; return false; &#125; else if(this.getUserId() != other.getUserId()) &#123; return false; &#125; else &#123; Object this$userName = this.getUserName(); Object other$userName = other.getUserName(); if(this$userName == null) &#123; if(other$userName != null) &#123; return false; &#125; &#125; else if(!this$userName.equals(other$userName)) &#123; return false; &#125; Object this$sex = this.getSex(); Object other$sex = other.getSex(); if(this$sex == null) &#123; if(other$sex != null) &#123; return false; &#125; &#125; else if(!this$sex.equals(other$sex)) &#123; return false; &#125; return true; &#125; &#125; &#125; protected boolean canEqual(Object other) &#123; return other instanceof UserEntity; &#125; public int hashCode() &#123; int PRIME = true; int result = 1; long $userId = this.getUserId(); int result = result * 59 + (int)($userId &gt;&gt;&gt; 32 ^ $userId); Object $userName = this.getUserName(); result = result * 59 + ($userName == null?43:$userName.hashCode()); Object $sex = this.getSex(); result = result * 59 + ($sex == null?43:$sex.hashCode()); return result; &#125; public String toString() &#123; return "UserEntity(userId=" + this.getUserId() + ", userName=" + this.getUserName() + ", sex=" + this.getSex() + ")"; &#125; @ConstructorProperties(&#123;"userId", "userName", "sex"&#125;) public UserEntity(long userId, String userName, String sex) &#123; this.userId = userId; this.userName = userName; this.sex = sex; &#125;&#125; 这边介绍笔者经常使用到的注解。 val，用在局部变量前面，相当于将变量声明为final @Value用在类上，是@Data的不可变形式，相当于为属性添加final声明，只提供getter方法，而不提供setter方法 @Data@ToString, @EqualsAndHashCode, 所有属性的@Getter, 所有non-final属性的@Setter和@RequiredArgsConstructor的组合，通常情况下，我们使用这个注解就足够了。 @NoArgsConstructor无参构造器 @AllArgsConstructor全参构造器 @ToString 生成toString方法，默认情况下，会输出类名、所有属性，属性会按照顺序输出，以逗号分割。 @EqualsAndHashCode默认情况下，会使用所有非瞬态(non-transient)和非静态(non-static)字段来生成equals和hascode方法，也可以指定具体使用哪些属性。 @Getter / @Setter上面已经说过，一般用@data就不用额外加这个注解了。可以作用在类上和属性上，放在类上，会对所有的非静态(non-static)属性生成Getter/Setter方法，放在属性上，会对该属性生成Getter/Setter方法。并可以指定Getter/Setter方法的访问级别。 @NonNull，给方法参数增加这个注解会自动在方法内对该参数进行是否为空的校验，如果为空，则抛出NPE（NullPointerException） @Cleanup自动管理资源，用在局部变量之前，在当前变量范围内即将执行完毕退出之前会自动清理资源，自动生成try-finally这样的代码来关闭流 @Log根据不同的注解生成不同类型的log对象，但是实例名称都是log，有7种可选实现类： 1). @Log4j 1private static final org.apache.log4j.Logger log = org.apache.log4j.Logger.getLogger(LogExample.class); 2). @Log4j2 1private static final org.apache.logging.log4j.Logger log = org.apache.logging.log4j.LogManager.getLogger(LogExample.class); 3). @Slf4j 1private static final org.slf4j.Logger log = org.slf4j.LoggerFactory.getLogger(LogExample.class); 4). @XSlf4j 1private static final org.slf4j.ext.XLogger log = org.slf4j.ext.XLoggerFactory.getXLogger(LogExample.class); 5). @CommonsLog 1private static final org.apache.commons.logging.Log log = org.apache.commons.logging.LogFactory.getLog(LogExample.class); 6). @JBossLog 1private static final org.jboss.logging.Logger log = org.jboss.logging.Logger.getLogger(LogExample.class); 7). @Log private static final java.util.logging.Logger log = java.util.logging.Logger.getLogger(LogExample.class.getName()); 默认情况下，logger的名字将会是被@Log注解的那个类的名字。当然这也可以被个性化命名，通过topic参数，如@XSlf4j(topic=&quot;reporting&quot;)。 4. 原理lombok 主要通过注解生效，自jdk5引入注解，由两种解析方式。第一种是运行时解析，@Retention(RetentionPolicy.RUNTIME), 定义注解的保留策略，这样可以通过反射拿到该注解。另一种是编译时解析，有两种机制。 Annotation Processing Tool，apt自JDK5产生，JDK7已标记为过期，不推荐使用，JDK8中已彻底删除，自JDK6开始，可以使用Pluggable Annotation Processing API来替换它，apt被替换主要有2点原因。api都在com.sun.mirror非标准包下，还有就是没有集成到javac中，需要额外运行。 Pluggable Annotation Processing APIlombok使用这种方式实现，基于JSR 269，自JDK6加入，作为apt的替代方案，它解决了apt的两个问题，javac在执行的时候会调用实现了该API的程序，这样我们就可以对编译器做一些增强，这时javac执行的过程如下： 5. 总结这篇文章主要讲解了lombok的入门与使用。介绍了一些常用的lombok注解，大大简化了我们的开发工作和代码的简洁性。当然，lombok不支持多种参数构造器的重载，工具毕竟是工具，我感觉并不会有非常完美适合每个人的工具。最后，我个人还是很推荐这款插件的，毕竟我很懒，😆。 参考 Lombok Docs Java奇淫巧技之Lombok]]></content>
      <categories>
        <category>Utils</category>
      </categories>
      <tags>
        <tag>Lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Cluster深入与实践]]></title>
    <url>%2F2017%2F09%2F29%2Frediscluster%2F</url>
    <content type="text"><![CDATA[1. redis介绍www.redis.ioredis是一个基于内存的K-V存储数据库。支持存储的类型有string,list,set,zset(sorted set),hash等。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。redis支持各种不同方式的排序。保证效率的情况下，数据缓存在内存中。同时redis提供了持久化策略，不同的策略触发同步到磁盘或者把修改操作写入追加的记录文件，在此基础上实现了master-slave。 它是一个高性能的存储系统，能支持超过 100K+ 每秒的读写频率。同时还支持消息的发布/订阅，从而让你在构建高性能消息队列系统时多了另一种选择。 Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。 2. 主从redis支持master-slave模式，一主多从，redis server可以设置另外多个redis server为slave，从机同步主机的数据。配置后，读写分离，主机负责读写服务，从机只负责读。减轻主机的压力。redis实现的是最终会一致性，具体选择强一致性还是弱一致性，取决于业务场景。redis 主从同步有两种方式（或者所两个阶段）：全同步和部分同步。 主从刚刚连接的时候，进行全同步；全同步结束后，进行部分同步。当然，如果有需要，slave 在任何时候都可以发起全同步。redis 策略是，无论如何，首先会尝试进行部分同步，如不成功，要求从机进行全同步，并启动 BGSAVE……BGSAVE 结束后，传输 RDB 文件；如果成功，允许从机进行部分同步，并传输积压空间中的数据。简单来说，主从同步就是 RDB 文件的上传下载；主机有小部分的数据修改，就把修改记录传播给每个从机。 3. redis集群主从模式存在的问题是，master宕机之后，从机只能读，不可写，不能保证高可用。redis集群技术是构建高性能网站架构的重要手段，试想在网站承受高并发访问压力的同时，还需要从海量数据中查询出满足条件的数据，并快速响应，我们必然想到的是将数据进行切片，把数据根据某种规则放入多个不同的服务器节点，来降低单节点服务器的压力。 Redis Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。节点之间使用gossip协议传播信息以及发现新节点。 Redis 集群是一个分布式（distributed）、容错（fault-tolerant）的 Redis 实现，集群可以使用的功能是普通单机 Redis 所能使用的功能的一个子集（subset）。 Redis 集群中不存在中心（central）节点或者代理（proxy）节点，集群的其中一个主要设计目标是达到线性可扩展性（linear scalability）。 Redis 集群为了保证一致性（consistency）而牺牲了一部分容错性：系统会在保证对网络断线（net split）和节点失效（node failure）具有有限（limited）抵抗力的前提下，尽可能地保持数据的一致性。 4. 安装部署redis安装较为简单，官网下载压缩包解压。集群模式需要ruby的编译环境，集群最小的配置为3台master，小于3则启动集群报错。redis版本：3.2.4 4.1 主从模式拓扑图 主从模式采用一主三从，主从都配置auth认证，读写分离。主要实验的动作：1）多个app 同时写，测定写速率；2）多个app 同时写，同时有读的进程，测定读写速率；3）master主机宕机，app依然进行读写。 4.2 cluster拓扑图如下 集群模式采用四主四从，也是采用读写分离。主要实验的动作：1）有一个master宕机，观察日志，新的slave成为master；2）master宕机后，重新启动，master成为slave；3）集群全部宕机，redis主机重启，数据未丢失。 5. 原理5.1 一致性filesnapshot:默认redis是会以快照的形式将数据持久化到磁盘,在配置文件中的格式是：save N M表示在N秒之内，redis至少发生M次修改则redis抓快照到磁盘。 工作原理：当redis需要做持久化时，redis会fork一个子进程；子进程将数据写到磁盘上一个临时RDB文件中；当子进程完成写临时文件后，将原来的RDB替换掉，这样的好处就是可以copy-on-write。 Append-only：filesnapshotting方法在redis异常死掉时， 最近的数据会丢失（丢失数据的多少视你save策略的配置），所以这是它最大的缺点，当业务量很大时，丢失的数据是很多的。Append-only方法可 以做到全部数据不丢失，但redis的性能就要差些。AOF就可以做到全程持久化，只需要在配置文件中开启（默认是no），appendonly yes开启AOF之后，redis每执行一个修改数据的命令，都会把它添加到aof文件中，当redis重启时，将会读取AOF文件进行“重放”以恢复到 redis关闭前的最后时刻。 AOF文件刷新的方式，有三种，参考配置参数appendfsync ： appendfsync always每提交一个修改命令都调用fsync刷新到AOF文件，非常非常慢，但也非常安全； appendfsync everysec每秒钟都调用fsync刷新到AOF文件，很快，但可能会丢失一秒以内的数据； appendfsync no依靠OS进行刷新，redis不主动刷新AOF，这样最快，但安全性就差。默认并推荐每秒刷新，这样在速度和安全上都做到了兼顾。 Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力。因此我们可以将Redis的Replication架构视为图结构。 Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求。 Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据。 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成。即便如此，系统的伸缩性还是得到了很大的提高。 Master可以将数据保存操作交给Slaves完成，从而避免了在Master中要有独立的进程来完成此操作。Redis在master是非阻塞模式，也就是说在slave执行数据同步的时候，master是可以接受客户端的请求的，并不影响同步数据的一致性，然而在slave端是阻塞模式的，slave在同步master数据时，并不能够响应客户端的查询。 5.2 Replication的工作原理(1)Slave服务器连接到Master服务器。(2)Slave服务器发送SYCN命令。(3)Master服务器备份数据库到.rdb文件。(4)Master服务器把.rdb文件传输给Slave服务器。(5)Slave服务器把.rdb文件数据导入到数据库中。 在Slave启动并连接到Master之后，它将主动发送一个SYNC命令。此后Master将启动后台存盘进程，同时收集所有接收到的用于修改数据集 的命令，在后台进程执行完毕后，Master将传送整个数据库文件到Slave，以完成一次完全同步。而Slave服务器在接收到数据库文件数据之后将其 存盘并加载到内存中。此后，Master继续将所有已经收集到的修改命令，和新的修改命令依次传送给Slaves，Slave将在本次执行这些数据修改命令，从而达到最终的数据同步。如果Master和Slave之间的链接出现断连现象，Slave可以自动重连Master，但是在连接成功之后，一次完全同步将被自动执行。 5.3 一致性哈希集群要实现的目的是要将不同的 key 分散放置到不同的 redis 节点，这里我们需要一个规则或者算法，通常的做法是获取 key 的哈希值，然后根据节点数来求模，但这种做法有其明显的弊端，当我们需要增加或减少一个节点时，会造成大量的 key 无法命中，这种比例是相当高的，所以就有人提出了一致性哈希的概念。一致性哈希有四个重要特征： 均衡性：也有人把它定义为平衡性，是指哈希的结果能够尽可能分布到所有的节点中去，这样可以有效的利用每个节点上的资源。 单调性：对于单调性有很多翻译让我非常的不解，而我想要的是当节点数量变化时哈希的结果应尽可能的保护已分配的内容不会被重新分派到新的节点。 分散性和负载：这两个其实是差不多的意思，就是要求一致性哈希算法对 key 哈希应尽可能的避免重复。 Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。 使用哈希槽的好处就在于可以方便的添加或移除节点。 当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了； 当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了； 当设置了主从关系后，slave 在第一次连接或者重新连接 master 时，slave 都会发送一条同步指令给 master； master 接到指令后，开始启动后台保存进程保存数据，接着收集所有的数据修改指令。后台保存完了，master 就把这份数据发送给 slave，slave 先把数据保存到磁盘，然后把它加载到内存中，master 接着就把收集的数据修改指令一行一行的发给 slave，slave 接收到之后重新执行该指令，这样就实现了数据同步。 slave 在与 master 失去联系后，自动的重新连接。如果 master 收到了多个 slave 的同步请求，它会执行单个后台保存来为所有的 slave 服务。 5.4 节点失效检测以下是节点失效检查的实现方法： 当一个节点向另一个节点发送 PING 命令，但是目标节点未能在给定的时限内返回 PING 命令的回复时，那么发送命令的节点会将目标节点标记为PFAIL （possible failure，可能已失效）。 等待 PING 命令回复的时限称为“节点超时时限（node timeout）”，是一个节点选项（node-wise setting）。 每次当节点对其他节点发送 PING 命令的时候，它都会随机地广播三个它所知道的节点的信息，这些信息里面的其中一项就是说明节点是否已经被标记为 PFAIL 或者 FAIL 。 当节点接收到其他节点发来的信息时，它会记下那些被其他节点标记为失效的节点。这称为失效报告（failure report）。 如果节点已经将某个节点标记为 PFAIL ，并且根据节点所收到的失效报告显式，集群中的大部分其他主节点也认为那个节点进入了失效状态，那么节点会将那个失效节点的状态标记为 FAIL 。 一旦某个节点被标记为 FAIL ，关于这个节点已失效的信息就会被广播到整个集群，所有接收到这条信息的节点都会将失效节点标记为 FAIL 。 简单来说，一个节点要将另一个节点标记为失效，必须先询问其他节点的意见，并且得到大部分主节点的同意才行。因为过期的失效报告会被移除，所以主节点要将某个节点标记为 FAIL 的话，必须以最近接收到的失效报告作为根据。在以下两种情况中，节点的 FAIL 状态会被移除： 如果被标记为 FAIL 的是从节点，那么当这个节点重新上线时， FAIL 标记就会被移除。保持（retaning）从节点的 FAIL 状态是没有意义的，因为它不处理任何槽，一个从节点是否处于 FAIL 状态，决定了这个从节点在有需要时能否被提升为主节点。 如果一个主节点被打上 FAIL 标记之后，经过了节点超时时限的四倍时间，再加上十秒钟之后，针对这个主节点的槽的故障转移操作仍未完成，并且这个主节点已经重新上线的话，那么移除对这个节点的 FAIL 标记。 在第二种情况中，如果故障转移未能顺利完成，并且主节点重新上线，那么集群就继续使用原来的主节点，从而免去管理员介入的必要。 5.5 从节点选举一旦某个主节点进入 FAIL 状态，如果这个主节点有一个或多个从节点存在，那么其中一个从节点会被升级为新的主节点，而其他从节点则会开始对这个新的主节点进行复制。新的主节点由已下线主节点属下的所有从节点中自行选举产生，以下是选举的条件： 这个节点是已下线主节点的从节点。 已下线主节点负责处理的槽数量非空。 从节点的数据被认为是可靠的，也即是，主从节点之间的复制连接（replication link）的断线时长不能超过节点超时时限（node timeout）乘以REDIS_CLUSTER_SLAVE_VALIDITY_MULT 常量得出的积。 如果一个从节点满足了以上的所有条件，那么这个从节点将向集群中的其他主节点发送授权请求，询问它们，是否允许自己（从节点）升级为新的主节点。如果发送授权请求的从节点满足以下属性，那么主节点将向从节点返回 FAILOVER_AUTH_GRANTED 授权，同意从节点的升级要求： 发送授权请求的是一个从节点，并且它所属的主节点处于 FAIL 状态。 在已下线主节点的所有从节点中，这个从节点的节点 ID 在排序中是最小的。 从节点处于正常的运行状态：它没有被标记为 FAIL 状态，也没有被标记为 PFAIL 状态。 一旦某个从节点在给定的时限内得到大部分主节点的授权，它就会开始执行以下故障转移操作： 通过 PONG 数据包（packet）告知其他节点，这个节点现在是主节点了。 通过 PONG 数据包告知其他节点，这个节点是一个已升级的从节点（promoted slave）。 接管（claiming）所有由已下线主节点负责处理的哈希槽。 显式地向所有节点广播一个 PONG 数据包，加速其他节点识别这个节点的进度，而不是等待定时的 PING / PONG 数据包。 所有其他节点都会根据新的主节点对配置进行相应的更新，特别地： a. 所有被新的主节点接管的槽会被更新。 b. 已下线主节点的所有从节点会察觉到 PROMOTED 标志，并开始对新的主节点进行复制。 c.如果已下线的主节点重新回到上线状态，那么它会察觉到 PROMOTED 标志，并将自身调整为现任主节点的从节点。 在集群的生命周期中，如果一个带有 PROMOTED 标识的主节点因为某些原因转变成了从节点，那么该节点将丢失它所带有的 PROMOTED 标识。 6. 总结Redis集群具有高可用，易于迁移，存取速度快等特点。也可以作为消息队列使用，支持pub/sub模式，具体优缺点总结如下：首先优点: redis 在主节点下线后，从节点会自动提升为主节点，提供服务 redis 宕机节点恢复后，自动会添加到集群中，变成从节点 动态扩展和删除节点，rehash slot的分配，基于桶的数据分布方式大大降低了迁移成本，只需将数据桶从一个Redis Node迁移到另一个Redis Node即可完成迁移。 Redis Cluster使用异步复制。 其缺点为: 由于redis的复制使用异步机制，在自动故障转移的过程中，集群可能会丢失写命令。然而 redis 几乎是同时执行(将命令恢复发送给客户端，以及将命令复制到从节点)这两个操作，所以实际中，命令丢失的窗口非常小。 普通的主从模式支持auth加密认证，虽然比较弱，但写或者读都要通过密码验证，cluster对密码支持不太友好，如果对集群设置密码，那么requirepass和masterauth都需要设置，否则发生主从切换时，就会遇到授权问题，可以模拟并观察日志。 参考资料： www.redis.io redis-cluster研究和使用 Redis Cluster 3.0搭建与使用]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由Consul谈到Raft]]></title>
    <url>%2F2017%2F09%2F25%2Fraft%2F</url>
    <content type="text"><![CDATA[在前一篇文章consul配置与实战中，介绍了consul的一些内幕及consul配置相关，并对项目中的一些实际配置进行展示。这篇文章重点介绍consul中所涉及到的一致性算法raft。 1. 背景分布式系统的一致性是相当重要的，即为CAP理论中的C(Consistency)。一致性又可以分为强一致性和最终一致性。这篇文章重点讨论强一致性算法raft。 Lamport发表Paxos一致性算法从90年提出到现在已经有二十几年了，直到2006年Google的三篇论文初现“云”的端倪，其中的Chubby Lock服务使用Paxos作为Chubby Cell中的一致性算法，Paxos的人气从此一路狂飙。而Paxos流程太过于繁杂实现起来也比较复杂，虽然现在很广泛使用的Zookeeper也是基于Paxos算法来实现，但是Zookeeper使用的ZAB（Zookeeper Atomic Broadcast）协议对Paxos进行了很多的改进与优化，复杂性是制约他发展的一个重要原因。Raft的设计初衷就是易于理解性。 Raft是斯坦福的Diego Ongaro、John Ousterhout两个人以易懂（Understandability）为目标设计的一致性算法，在2013年发布了论文：《In Search of an Understandable Consensus Algorithm》 从2013年发布到现在不过只有两年，到现在已经有了十多种语言的Raft算法实现框架，较为出名的有etcd。 2. Raft详解强调的是易懂（Understandability），Raft和Paxos一样只要保证n/2+1节点正常就能够提供服务；众所周知但问题较为复杂时可以把问题分解为几个小问题来处理，Raft也使用了分而治之的思想把算法流程分为三个子问题：选举（Leader election）、日志复制（Log replication）、安全性（Safety）三个子问题。 2.1 raft基本概念 states 一个raft集群拥有多个server，通常会有5台，这样可以允许系统中两台server宕机。在任何情况下，所有的server只有如下三种状态之一： Leader，负责Client交互和log复制，同一时刻系统中最多存在1个 Follower，被动响应请求RPC，从不主动发起请求RPC Candidate，由Follower向Leader转换的中间状态 在正常的操作流程中，集群中有且只有一个server，其他所有的server都是follower。follower是被动的，他们只是被动地相应Candidate和leader的请求。。leader处理所有的客户端请求，follower自己不处理而是转发给leader。第三种状态是Candidate，用来选举一个新的leader。 Terms Raft将时间划分成任意的长度周期。Terms可以理解为逻辑周期，用连续的整数表示。在分布式环境中，时间同步很重要，同时是一个难题。在Raft中使用了一个可以理解为周期（任期）的概念，用Term作为一个周期，每个Term都是一个连续递增的编号，每一轮选举都是一个Term周期，在一个Term中只能产生一个Leader。 每个term伴随着一次election，一个或多个Candidate试图成为leader，如上图的状态转换。如果某个Candidate赢得了这次election，它将升级为剩余server的leader。在某些election的情形中，会产生耗票（Split Votes）的结果 ，即投票结果无效，随后一次新的term开始。raft确保在某个term至多有一个leader。 如上图所示，时间被划分成多个terms，每个term随着一次election。election完成后，一个leader节点管理整个集群，直至这个term结束。有些election失败了，未能产生一个leader。 2.2 Leader election所有节点都是以follower启动。一个最小的 Raft 集群需要三个参与者，这样才可能投出多数票。初始状态 都是 Follower，然后发起选举这时有三种可能情形发生。如果每方都投给了自己，结果没有任何一方获得多数票。之后每个参与方随机休息一阵（Election Timeout）重新发起投票直到一方获得多数票。这里的关键就是随机 timeout，最先从timeout中恢复发起投票的一方向还在 timeout 中的另外两方请求投票，这时它们就只能投给对方了，很快达成一致。Raft的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为Follower某个节点定时器触发选举后Term递增，状态由Follower转为Candidate，向其他节点发起RequestVote RPC请求，这时候有三种可能的情况发生： 1.该RequestVote请求接收到n/2+1（过半数）个节点的投票，从Candidate转为Leader，向其他节点发送heartBeat以保持Leader的正常运转。 2.在此期间如果收到其他节点发送过来的AppendEntries RPC请求，如该节点的Term大则当前节点转为Follower，否则保持Candidate拒绝该请求。 3.Election timeout发生则Term递增，重新发起选举。 在一个Term期间每个节点只能投票一次，所以当有多个Candidate存在时就会出现每个Candidate发起的选举都存在接收到的投票数都不过半的问题，这时每个Candidate都将Term递增、重启定时器并重新发起选举，由于每个节点中定时器的时间都是随机的，所以就不会多次存在有多个Candidate同时发起投票的问题。 引用一张网上的图片，比较形象，如下图。 2.3 Log replication日志复制主要是用于保证节点的一致性，这阶段所做的操作也是为了保证一致性与高可用性；当Leader选举出来后便开始负责客户端的请求，所有事务（更新操作）请求都必须先经过Leader处理，这些事务请求或说成命令也就是这里说的日志，我们都知道要保证节点的一致性就要保证每个节点都按顺序执行相同的操作序列，日志复制（Log Replication）就是为了保证执行相同的操作序列所做的工作；在Raft中当接收到客户端的日志（事务请求）后先把该日志追加到本地的Log中，然后通过heartbeat把该Entry同步给其他Follower，Follower接收到日志后记录日志然后向Leader发送ACK，当Leader收到大多数（n/2+1）Follower的ACK信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个heartbeat中Leader将通知所有的Follower将该日志存储在自己的本地磁盘中。 上图中，当leader选出来之后，follower的logs场景很可能出现在上图中。follower有可能丢失entries、有未提交的entries、有额外的entries等等场景。Raft中，leader通过强制followers复制自己的logs来处理不一致。这意味着，在follower中logs冲突的entries将会被leader logs中的覆写。 2.4 Safety安全性是用于保证每个节点都执行相同序列的安全机制，如当某个Follower在当前Leader commit Log时变得不可用了，稍后可能该Follower又会倍选举为Leader，这时新Leader可能会用新的Log覆盖先前已committed的Log，这就是导致节点执行不同序列；Safety就是用于保证选举出来的Leader一定包含先前 commited Log的机制； Election Safety每个Term只能选举出一个Leader，假设某个Term同时选举产生两个LeaderA和LeaderB，根据选举过程定义，A和B必须同时获得超过半数节点的投票，至少存在节点N同时给予A和B投票，因此矛盾。 Leader Completeness这里所说的完整性是指Leader日志的完整性，当Log在Term1被Commit后，那么以后Term2、Term3…等的Leader必须包含该Log；Raft在选举阶段就使用Term的判断用于保证完整性：当请求投票的该Candidate的Term较大或Term相同Index更大则投票，否则拒绝该请求； Leader Append-OnlyLeader从不“重写”或者“删除”本地Log，仅仅“追加”本地Log。Raft算法中Leader权威至高无上，当Follower和Leader产生分歧的时候，永远是Leader去覆盖修正Follower。 Log Matching如果两个节点上的日志项拥有相同的Index和Term，那么这两个节点[0, Index]范围内的Log完全一致。 State Machine Safety一旦某个server将某个日志项应用于本地状态机，以后所有server对于该偏移都将应用相同日志项。 3. 总结本文主要讲解了Raft算法的基本概念，以及算法中涉及到的leader选举，日志同步，安全性。Raft是以易理解性作为其设计的一个目标，对于一个学习的新手来说，确实比Paxos易于理解很多。虽然 Raft 的论文比 Paxos 简单版论文容易读，论文依然有很多地方需要深刻体会与理解，笔者也还是搞了好几天。 参考 Raft Animate Demo Raft Paper Raft Website Raft 为什么是更易理解的分布式一致性算法 Raft一致性算法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>consul</tag>
        <tag>Cluster</tag>
        <tag>Consensus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[consul配置与实战]]></title>
    <url>%2F2017%2F09%2F16%2Fconsul%2F</url>
    <content type="text"><![CDATA[上一篇提到，项目用的分布式服务发现与注册组件是consul，这篇文章主要来讲下consul组件在项目中的应用以及相关介绍。本文以官方文档为主要参考consul文档。 1. consul介绍consul是一个服务管理软件，主要功能如下： 支持多数据中心下，分布式高可用的，服务发现和配置共享。 consul支持健康检查，允许存储键值对。 一致性协议采用Raft算法,用来保证服务的高可用。 成员管理和消息广播采用GOSSIP协议，支持ACL访问控制。 1.1 服务注册与发现服务注册是一个服务将其位置信息在“中心注册节点”注册的过程。该服务一般会将它的主机IP地址以及端口号进行注册，有时也会有服务访问的认证信息，使用协议，版本号，以及关于环境的一些细节信息。而服务发现可以让一个应用或者组件发现其运行环境以及其它应用或组件的信息。用户配置一个服务发现工具就可以将实际容器跟运行配置分离开。常见配置信息包括：ip、端口号、名称等。 在传统情况下，当出现服务存在于多个主机节点上时，都会使用静态配置的方法来实现服务信息的注册。而当在一个复杂的系统里，需要较强的可扩展性时，服务被频繁替换时，为避免服务中断，动态的服务注册和发现就很重要。服务注册与发现的组件有很多，如Zookeeper、Etcd等。既可用于服务间的协调，同时又可用于服务的注册。 1.2 Consensus Protocol - Raft Consul使用Consensus协议Raft提供一致性（Consistency）。本文只是简单介绍在consul中的一致性，后面专门一篇写raft。 首先，Raft是一种基于Paxos的Consensus算法。相比于Paxos，Raft设计采用了较少的状态，并且是一种更简单、更易于理解的算法。只有Server节点参与Raft，且是peer set的一员。所有的Client节点只是转发请求到Server。这种设计的考虑是，当更多的成员加入到peer set中时，quorum的规模也会增加。可能会导致性能问题是等待quorum个节点log entry。 启动Consul时，单个consul节点需要以bootstrap模式运行，该模式运行自我选举为leader。一旦Leader被选出来，其他Server可以添加Peer set中，保持一致性和安全性。最终一些Server添加到集群，bootstrap模式需要禁用。 因为所有Server都是Peer set中的成员，它们都知道谁是Leader。当一个RPC请求到达某个非Leader Server节点，请求就会被转发到Leader。如果RPC是一种query类型，这意味着它是只读的，Leader会基于FSM当前生成相应的结果，如果RPC是一种transaction类型，即修改状态，Leader产生一个新的日志条目，并基于Raft算法进行管理。一旦日志条目应用于有限状态机，transaction完成。 由于Raft的replication性质，性能对网络延迟是非常敏感的。为此，每个数据中心选择独立的Leader和维护一个不关联的peer set。数据按照数据中心进行划分，所以每个Leader只负责在相应数据中心的数据。当接收到一个远程数据中心的请求时，请求会被转发到相应的Leader。这种设计在不牺牲一致性的情况实现较低延迟交易和更高的可用性。虽然所有日志副本的写入都是基于Raft，读取更灵活。但为了支持开发人员可能需要的各种权衡，Consul支持3种不同的一致性模式。 Default，Raft采用Leader租赁模式，提供了一个时间窗口，在该时间段内，Leader角色是稳定的。 consistent，无条件一致性 stale，这种模式允许在任何Server节点执行读取操作，无论它是不是Leader。 1.3 Group Membership Protocol - GossipConsul使用gossip协议管理成员关系、广播消息到整个集群。详情可参考Serf library。 Consul利用两个不同的gossip pool。局域网(LAN Pool)和广域网(WAN Pool)。 每个Consul数据中心都有一个包含所有成员（Server和Client）的LAN gossip pool。LAN Pool有如下几个目的： 首先，成员关系允许Client自动发现Server节点，减少所需的配置量。 其次，分布式故障检测允许的故障检测的工作在某几个Server几点执行，而不是集中整个集群所有节点上。 最后，gossip允许可靠和快速的事件广播，如Leader选举。 WAN Pool是全局唯一的，无论属于哪一个数据中心，所有Server应该加入到WAN Pool。由WAN Pool提供会员信息让Server可节电执行跨数据中心的请求。集成中故障检测允许Consul妥善处理整个数据中心失去连接，或在远程数据中心只是单个的Server节点。所有这些功能都是通过利用Serf提供。从用户角度来看，它是作为一个嵌入式库提供这些功能。但其被Consul屏蔽，用户无需关心。作为开发人员可以去了解这个库是如何利用。 1.4 Session会话上一篇文章snowflake升级版全局id生成中使用到了consul的KV存储。Consul提供session会话机制，可以用于构建分布式锁。session可以绑定到节点、健康检查、KV数据，目的是提供细粒度锁。KV存储和会话的集成是使用会话的主要场景。必须在使用之前创建一个会话，然后使用它的ID。KV API支持acquire和release操作，acquire操作类似CAS操作，只有当锁空闲时才会返回成功。当成功时，某个normal标识会更新，也会递增LockIndex，当然也会更新session的信息。如果在acquire操作时，与session相关的锁已经持有，那么LockIndex就不会递增，但是key值会更新，这就允许锁的当前持有者无需重新获得锁就可以更新key的内容。 一旦获得锁，所需要经release操作来释放（使用相同的session）。Release操作也类似于CAS操作。如果给定的session无效，那么请求会失败。需要特别注意的是，无需经过session的创建者，lock也是可以被释放的。这种设计是允许操作者干预来终止会话，在需要的时候。如上所述，会话无效也将导致所有被持有的锁被释放或删除。当锁被释放时，LockIndex不会变化，但是session会被清空，并且ModifyIndex递增。这些语义允许元组（Key，LockIndex，Session）作为一个独特的“序列”。这个序列可以被传递和用于验证请求是否属于当前的锁持有者。因为每次acquire 都会导致LockIndex递增，即使同一会话中重新获取锁，该序列能够检测到陈旧的请求。同样，如果会话失效，相应的LockIndex将为空。要清楚的是，这种锁系统是纯粹的咨询。并不是强制Client必须获取锁再能执行操作作。任何客户端都可以在未获得锁的情况下读取、写入和删除Key操作。它不是Consul用于保护系统的方法。 2. consul架构上面介绍了consul的技术内幕。现在来讲讲consul的架构。 拆解开这个体系，从每一个组件开始了解。首先，可以看到有两个数据中心，分别标记为“one”和“two”。Consul是支持多数据中心一流，并且是常用业务场景。 每个数据中心都是由Server和client组成。建议有3~5台Server，基于故障处理和性能的平衡之策。如果增加越多的机器，则Consensus会越来越慢。对client没有限制，可以很容易地扩展到成千上万或数万。同一个数据中心的所有节点都要加入Gossip协议。这意味着gossip pool包含给定数据中心的所有节点。有以下目的：首先，没有必要为client配置服务器地址参数；发现是自动完成的。第二，节点故障检测的工作不是放置在服务器上，而是分布式的。这使故障检测比心跳机制更可扩展性。第三，可用来作为消息层通知重要的事件，如leader选举。 每个数据中心的服务器都是属于一个Raft peer。这意味着，他们一起工作，选出一个的Leader，Leader server是有额外的职责。负责处理所有的查询和事务。事务也必须通过Consensus协议复制到所有的伙伴。由于这一要求，当非Leader Server接收到一个RPC请求，会转发到集群的leader。 Server节点也是作为WAN gossip pool的一部分。这个pool是与LAN gossip pool是不同的，它为具有更高延迟的网络响应做了优化，并且可能包括其他consul集群的server节点。设计WANpool的目的是让数据中心能够以low-touch的方式发现彼此。将一个新的数据中心加入现有的WAN Gossip是很容易的。因为池中的所有Server都是可控制的，这也使跨数据中心的要求。当一个Serfer接收到不同的数据中心的要求时，它把这个请求转发给相应数据中心的任一Server。然后，接收到请求的Server可能会转发给Leader。多个数据中心之间是低耦合，但由于故障检测、连接缓存复用、跨数据中心要求快速和可靠的响应。 3. consul部署3.1 docker安装docker安装很简单，笔者这边是基于docker-compose的配置文件，只需要本地安装好docker和docker-compose，docker-compose.yml如下： 12345678version: '3'services: consul: image: consul ports: - "8500:8500" - "8600:8600" - "8300:8300" 拉取consul得最新image，进行端口映射，暴露对外的端口8500，8300. 3.2 软件安装 从官网下载罪行的consul安装包，https://www.consul.io/downloads.html。 解压consul_0.6.4_darwin_amd64.zip。 将解压后的二进制文件consul拷贝到/usr/local/bin下。 写配置文件。服务注册的配置文件如下: 12345678910111213141516&#123; &quot;service&quot;: &#123; &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [&quot;master&quot;], &quot;address&quot;: &quot;1192.168.1.100&quot;, &quot;port&quot;: 8000, &quot;enableTagOverride&quot;: false, &quot;check&quot;: &#123; &quot;id&quot;: &quot;redis&quot;, &quot;name&quot;: &quot;redis on port 8000&quot;, &quot;tcp&quot;: &quot;localhost:8000&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125; &#125;&#125; 如上配置注册了Redis的8000端口，并带有tcp的health check。 节点的配置文件： 12345678910111213141516&#123; "datacenter": "east-cn", "data_dir": "/opt/consul", "log_level": "INFO", "node_name": "redis", "server": true, "addresses": &#123; "https": "192.168.1.100" &#125;, "ports": &#123; "https": 0 &#125;, "ui": true, "retry-join": []&#125; 当加载配置选项时，consul是按照词典顺序从所有配置文件或目录中加载。比如，a.json会先于e.json处理。后面设定的配置选项会合并到前面的配置集合中，如果存在重复的配置选项则会覆盖。当然，在某些情况下，比如事件处理程序，后面处理程序会追加到现有的配置选项中，形成事件处理程序列表。 3.3 启动具体启动文档见configuration。如: consul agent -server -config-dir /etc/consul.d -bind=192.168.1.100 -config-dir /etc/consul.d config-dir需要加载的配置文件目录，consul将加载目录下所有后缀为“.json”的文件，加载顺序为字母顺序，文件中配置选项合并方式如config-file。该参数可以多次配置。目录中的子目录是不会加载的。 data-dir此目录是为Agent存放state数据的。是所有Agent需要的，该目录应该存放在持久存储中（reboot不会丢失），对于server角色的Agent是很关键的,需要记录集群状态。并且该目录是支持文件锁。 server设置Agent是server模式还是client模式。Consul agent有两种运行模式：Server和Client。这里的Server和Client只是Consul集群层面的区分，与搭建在Cluster之上 的应用服务无关。Consule Server模式agent节点用于采用raft算法维护Consul集群的状态，官方建议每个Consul Cluster至少有3个或以上的运行在Server mode的Agent，Client节点不限。 其他常用的还有： client将绑定到client接口的地址，可以是HTTP、DNS、RPC服务器。默认为“127.0.0.1”，只允许回路连接。RPC地址会被其他的consul命令使用，比如consul members，查询agent列表 node节点在集群的名字，在集群中必须是唯一的。默认为节点的Hostname。 bootstrap设置服务是否为“bootstrap”模式。如果数据中心只有1个server agent，那么需要设置该参数。从技术上来讲，处于bootstrap模式的服务器是可以选择自己作为Raft Leader的。在consul集群中，只有一个节点可以配置该参数，如果有多个参数配置该参数，那么难以保证一致性。 bind用于集群内部通信的IP地址，与集群中其他节点互连可通。默认为“0.0.0.0”，consul将使用第一个有效的私有IPv4地址。如果指定“[::]”，consul将使用第一个有效的公共IPv6地址。使用TCP和UDP通信。注意防火墙，避免无法通信。 3.4 结果在开启了&quot;ui&quot;: trueserver主机上，如http://192.168.1.100:8500/ui查看注册中心的服务。demo ui如下： 4. 总结本文介绍了consul的一些内幕及consul配置相关，并对项目中的一些实际配置进行展示。希望能够帮助大家对consul相关的知识有所了解，并对于入门配置consul和实际应用有所知道。个人认为，consul原理还是简单易懂的，集群的配置也不复杂，安利大家使用。后面会再写一篇介绍Spring cloud中集成和使用consul组件作为注册与发现中心。 参考文献consul文档consul中文翻译]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>consul</tag>
        <tag>cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[snowflake升级版全局id生成]]></title>
    <url>%2F2017%2F09%2F09%2Fsnowflake%2F</url>
    <content type="text"><![CDATA[1. 背景分布式系统或者微服务架构基本都采用了分库分表的设计，全局唯一id生成的需求变得很迫切。传统的单体应用，使用单库，数据库中自增id可以很方便实现。分库之后，首先需要分库键，分库键必然不能重复，所以传统的做法并不能满足需求。概括下来，那业务系统对ID号的要求有哪些呢？ 1.全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。2.趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。3.单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。4.信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。 其中第3和第4点是互斥的。除了功能性需求，还有性能和可靠性的需求： 平均延迟和TP999延迟都要尽可能低； 可用性5个9； 高QPS。 2. 进阶历程自从项目从单体应用拆分成微服务架构后，对全局id部分做了些摸索。 2.1 uuid刚开始拆分业务，id主键都是使用uuid字符串。UUID(Universally Unique Identifier)的标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符。类似这样的字符串：dc5adf0a-d531-11e5-95aa-3c15c2d22392。128位，根本不用担心不够用。生成的方法也很简单： 1UUID userId = UUID.randomUUID(); uuid全球唯一，本地生成，没有网络消耗，产生的性能绝对可以满足。其缺点也是显而易见的，比较占地方，和INT类型相比，存储一个UUID要花费更多的空间。使用UUID后，URL显得冗长，不够友好。ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用： MySQL官方有明确的建议主键要尽量越短越好，36个字符长度的UUID不符合要求。 对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。 2.2 数据库生成以MySQL举例，利用给字段设置auto_increment_increment和auto_increment_offset来保证ID自增，每次业务使用下列SQL读写MySQL得到ID号。参考了Leaf的实现思想: id server每次批量从数据库取号段，本地缓存这个号段，并且设置阈值，当达到0.8（已用与号段容量的比值），自动去获取一个新的号段，更新本地缓存的号段。 id client，即具体的调用服务实例，在本地也做一个缓存，实现和id server的缓存差不多，这样做的目的是为了减轻id服务端的压力，同时减少了rpc调用的网络消耗。 以上方案，其缺点是： 号段存在浪费，无论哪个客户端还是服务端重启都会浪费号段。 号段是直接自增，不够随机，对外暴露信息过多。 DB宕机会造成整个系统不可用。虽然在DB宕机之后，利用缓存还能进行短暂供号，但是数据库的依赖还是很重。Leaf采用的一般做法是高可用容灾: 采用一主两从的方式，同时分机房部署，Master和Slave之间采用半同步方式同步数据。同时使用DBProxy做主从切换。当然这种方案在一些情况会退化成异步模式，甚至在非常极端情况下仍然会造成数据不一致的情况，但是出现的概率非常小。 3. snowflake方案3.1 介绍考虑到上述方案的缺陷，笔者调查了其他的生成方案，snowflake就是其中一种方案。趋势递增和不够随机的问题，在snowflake完全可以解决，Snowflake ID有64bits长，由以下三部分组成： 第一位为0，不用。 timestamp—41bits,精确到ms，那就意味着其可以表示长达(2^41-1)/(1000360024*365)=139.5年，另外使用者可以自己定义一个开始纪元（epoch)，然后用(当前时间-开始纪元）算出time，这表示在time这个部分在140年的时间里是不会重复的，官方文档在这里写成了41bits，应该是写错了。另外，这里用time还有一个很重要的原因，就是可以直接更具time进行排序，对于twitter这种更新频繁的应用，时间排序就显得尤为重要了。 machine id—10bits,该部分其实由datacenterId和workerId两部分组成，这两部分是在配置文件中指明的。 datacenterId，方便搭建多个生成uid的service，并保证uid不重复，比如在datacenter0将机器0，1，2组成了一个生成uid的service，而datacenter1此时也需要一个生成uid的service，从本中心获取uid显然是最快最方便的，那么它可以在自己中心搭建，只要保证datacenterId唯一。如果没有datacenterId，即用10bits，那么在搭建一个新的service前必须知道目前已经在用的id，否则不能保证生成的id唯一，比如搭建的两个uid service中都有machine id为100的机器，如果其server时间相同，那么产生相同id的情况不可避免。 workerId是实际server机器的代号，最大到32，同一个datacenter下的workerId是不能重复的。它会被注册到consul上，确保workerId未被其他机器占用，并将host:port值存入，注册成功后就可以对外提供服务了。 sequence id —12bits,该id可以表示4096个数字，它是在time相同的情况下，递增该值直到为0，即一个循环结束，此时便只能等到下一个ms到来，一般情况下4096/ms的请求是不太可能出现的，所以足够使用了。 3.2 实现思路snowflake方案，id服务端生成，不依赖DB，既能保证性能，且生成的id足够随机。每一毫秒，一台worker可以生成4096个id，如果超过，会阻塞到下一毫秒生成。对于那些并发量很大的系统来说,显然是不够的, 那么这个时候就是通过datacenterId和workerId来做区分,这两个ID,分别是5bit,共10bit,最大值是1024(0-1023)个, 在这种情况下,snowflake一毫秒理论上最大能够生成的ID数量是约42W个,这是一个非常大的基数了,理论上能够满足绝大多数系统的并发量。 该方案依赖于系统时钟，需要考虑时钟回拨的问题。本地缓存上一次请求的lastTimestamp，一个线程过来获取id时，首先校验当前时间是否小于上一次ID生成的时间戳。如果小于说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！如此可以解决运行中，系统时钟被修改的问题。 另一种情况是，server服务启动时，系统的时间被回拨（虽然比较极端，还是列在考虑中），这样有可能与之前生成的id冲突，全局不唯一。这边解决方法是利用项目的服务发现与注册组件consul，在consul集群存储最新的lastTimestamp，key为对应的machine-id。consul的一致性基于raft算法，并利用Gossip协议： Consul uses a gossip protocol to manage membership and broadcast messages to the cluster. All of this is provided through the use of the Serf library. 具体的协议算法，可以参考Gossip。每次server实例启动时，实例化id生成bean的时候，会首先校验当前时间与consul集群中该worker对应的lastTimestamp大小，如果当前时间偏小，则抛出异常，服务启动失败并报警。 笔者项目暂时未分data center，所以machine-id部分都是以服务实例的workid代替。workid可以从配置中心获取，也可以本地配置。简化的系统架构部署图如下： consul集群这边作为提供naming service和kv存储的组件，每个服务部署后注册到consul集群，至于consul集群相关的信息，以及consul成员的一致性相关，后面单独一篇文章详细介绍。 请求id生成流程图如下： 服务实例启动的流程图见上文，此处不画出了。这边需要强调的是，服务注册与发现组件consul。部署时每个服务实例都会注册到一个consul agent（一般是本机），consul agent连接到consul集群，通过gossip协议进行广播信息，所以如果连接的consul agent进程不幸挂掉（大多为系统宕机），在进程重启后，还是能迅速获取到集群中存储的该workid的lastTimestamp，针对该workid，如果系统时间回拨小于lastTimestamp，Generator启动时会报警。而对于大于lastTimestamp的情况，可能系统时钟还是相对回拨，我们姑且可以认为对全局id没有影响。 实例化时，进行校验： 123456789public IdServiceImpl(long workerId, ConsulClient consulClient) &#123; if (workerId &gt; idMeta.MAX_ID || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0", idMeta.MAX_ID)); &#125; this.workerId = workerId; this.consulClient = consulClient; validateStoredTimestamp(); log.info("worker starting. timestamp left shift &#123;&#125;, worker id bits &#123;&#125;, sequence bits &#123;&#125;, workerid &#123;&#125;", idMeta.TIMESTAMP_LEFT_SHIFT_BITS, idMeta.ID_BITS, idMeta.SEQUENCE_BITS, workerId);&#125; 校验函数： 123456789101112131415/** * checks for timestamp by workerId when server starts. * if server starts for the first time, just let it go and log warns. * if current timestamp is smaller than the value stored in consul server, throw exception. */private void validateStoredTimestamp() &#123; long current = timeGen(); Response&lt;GetValue&gt; keyValueResponse = consulClient.getKVValue(String.valueOf(workerId)); if (keyValueResponse.getValue() != null) &#123; lastTimestamp = Long.parseLong(keyValueResponse.getValue().getDecodedValue()); validateTimestamp(current, lastTimestamp, Periods.START); &#125; else &#123; log.warn(String.format("clock in consul is null. Generator works as for the 1st time.")); &#125;&#125; validateTimestamp: 123456789101112/** * 如果当前时间戳小于上一次ID生成的时间戳，说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！！！ * * @param lastTimestamp 上一次ID生成的时间戳 * @param timestamp 当前时间戳 */ private void validateTimestamp(long timestamp, long lastTimestamp, Periods period) &#123; if (timestamp &lt; lastTimestamp) &#123; log.error(String.format("clock is moving backwards. Rejecting requests until %d.", lastTimestamp)); throw new IllegalStateException(String.format("Clock moved backwards in %s. Refusing to generate id for %d milliseconds", period, lastTimestamp - timestamp)); &#125; &#125; 获取id方法： 123456789101112131415161718192021222324252627/** * 生成ID（线程安全） * * @return id */ public synchronized long genId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！！！ validateTimestamp(timestamp, lastTimestamp, Periods.RUNNING); //如果是同一时间生成的，则进行毫秒内sequence生成 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; IdMeta.SEQUENCE_MASK; //溢出处理 if (sequence == 0) &#123;//阻塞到下一毫秒,获得新时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123;//时间戳改变，毫秒内sequence重置 sequence = 0L; &#125; //上次生成ID时间截 lastTimestamp = timestamp; consulClient.setKVValue(String.valueOf(workerId), String.valueOf(lastTimestamp)); //移位并通过或运算组成64位ID return ((timestamp - idMeta.START_TIME) &lt;&lt; idMeta.TIMESTAMP_LEFT_SHIFT_BITS) | (workerId &lt;&lt; idMeta.ID_SHIFT_BITS) | sequence; &#125; 4. 总结这篇文章和大家分享了笔者项目中全局id生成服务的演进过程。当前的方案可以满足笔者当前项目的需求，至于分data-center（同一个机房优先调用），需要结合rpc调用进一步做处理，所以这块后续可以继续完善。欢迎大家提出建议。 本文的源码地址：GitHub：https://github.com/keets2012/snowflake-id-generator码云： https://gitee.com/keets/snowflake-id-generator 参考： www.consul.io leaf Twitter的分布式自增ID算法snowflake (Java版)]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>spring boot</tag>
        <tag>snowflake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入ThreadLocal]]></title>
    <url>%2F2017%2F09%2F04%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal主要是提供线程内部的局部变量，在每个线程内随时随地可取，隔离其他线程。 1. ThreadLocal接口1.1 ThreadLocal类接口很简单，只有4个方法，我们先来了解一下： void set(Object value)设置当前线程的线程局部变量的值。 public Object get()该方法返回当前线程所对应的线程局部变量。 public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。 protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。 1.2 使用ThreadLocal123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ThreadTest &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;()&#123; protected Long initialValue() &#123; return Thread.currentThread().getId(); &#125; &#125;; ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;()&#123;; protected String initialValue() &#123; return Thread.currentThread().getName(); &#125; &#125;; public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final ThreadTest test = new ThreadTest(); //test.set(); System.out.println("main.getLong: " + test.getLong()); System.out.println("main.getString: " + test.getString()); Thread thread1 = new Thread() &#123; public void run() &#123; //test.set(); System.out.println("Thread.getLong: " + test.getLong()); System.out.println("Thread.getString: " + test.getString()); &#125; &#125;; thread1.start(); thread1.join(); &#125;&#125; 以上demo覆写了initialValue()方法，或者调用set方法，否则会报空指针异常。在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。 2. ThreadLocalMapThreadLocalMap的Entry继承了WeakReference，并且使用ThreadLocal作为键值。 1. 实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的； 2. 为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal； 3. 在进行get之前，必须先set，否则会报空指针异常； 2.1 方法分析1). JDK8的ThreadLocal的get方法的源码 123456789101112131415161718192021/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local */public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 2). getMap 12345678910/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 3). setInitialValue 12345678910111213141516/** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; get方法的流程是这样的： 1.首先获取当前线程 2.根据当前线程获取一个Map 3.如果获取的Map不为空，则在Map中以ThreadLocal的引用作为key来在Map中获取对应的value e，否则转到5 4.如果e不为null，则返回e.value，否则转到5 5.Map为空或者e为空，则通过initialValue函数获取初始值value，然后用ThreadLocal的引用和value作为firstKey和firstValue创建一个新的Map 每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正需要存储的Object。 3. WeakReference关于内存泄露： ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：ThreadLocal Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 主要看下getEntryAfterMiss函数： 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null; &#125; ThreadLocalMap的getEntry函数的流程： 首先从ThreadLocal的直接索引位置(通过ThreadLocal.threadLocalHashCode &amp; (len-1)运算得到)获取Entry e，如果e不为null并且key相同则返回e； 如果e为null或者key不一致则向下一个位置查询，如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry，否则，如果key值为null，则擦除该位置的Entry，否则继续向下一个位置查询 在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。仔细研究代码可以发现，set操作也有类似的思想，将key为null的这些Entry都删除，防止内存泄露。 但是光这样还是不够的，上面的设计思路依赖一个前提条件：要调用ThreadLocalMap的genEntry函数或者set函数。这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的remove函数，手动删除不再需要的ThreadLocal，防止内存泄露。所以JDK建议将ThreadLocal变量定义成private static的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。 参考：ThreadLocal和synchronized的区别Java并发编程：深入剖析ThreadLocal]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Thread</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自制Jersey-Swagger的spring-boot-starter]]></title>
    <url>%2F2017%2F09%2F02%2Fspring-boot-starter-swaggerforjersey%2F</url>
    <content type="text"><![CDATA[Spring Boot的自动化配置特性来实现快速的将swagger2引入spring boot应用来生成jersey的API文档，简化原生使用swagger2的整合代码。 欢迎使用和Star支持，如使用过程中碰到问题，可以提出Issue，我会尽力完善该Starter 版本基础 Spring Boot：1.5.x swagger-jersey2-jaxrs：2.7.x Jersey 2 如何使用在该项目的帮助下，我们的Spring Boot可以轻松的引入swagger2，主需要做下面两个步骤： 在pom.xml中引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;club.hacloud&lt;/groupId&gt; &lt;artifactId&gt;jersey-starter-swagger&lt;/artifactId&gt; &lt;version&gt;1.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在应用主类中增加@EnableSwagger2Doc注解 123456789@EnableSwagger2Doc@SpringBootApplicationpublic class Bootstrap &#123; public static void main(String[] args) &#123; SpringApplication.run(Bootstrap.class, args); &#125;&#125; JerseyConfig 中增加1234@PostConstructpublic void init() &#123; this.register(ApiListingResource.class, SwaggerSerializers.class);&#125; 默认情况下就能产生所有当前jersey加载的请求映射文档。 参数配置更细致的配置内容参考如下： 配置示例1234567891011swagger: enabled: true title: spring-boot-starter-swagger config-id: demo-mvc version: v2 license: Apache License, Version 2.0 licenseUrl: https://www.apache.org/licenses/LICENSE-2.0.html termsOfServiceUrl: http://git.oschina.net/keets/jersey-starter-swagger contact: keets base-path: /** resource-package: cn.keets.demo 配置说明默认配置12345678910- swagger.enabled=是否开启 // todo 实现线上关闭功能- swagger.title=标题- swagger.description=描述- swagger.version=版本- swagger.license=许可证- swagger.licenseUrl=许可证URL- swagger.termsOfServiceUrl=服务条款URL- swagger.contact=维护人- swagger.resource-package=swagger扫描的基础包，默认：全扫描- swagger.base-path=需要处理的基础URL规则，默认：/** swagger ui未包含在项目中，大家可以自己部署静态文件，通过静态文件解析json 如下图所示： 项目git地址：http://git.oschina.net/keets/jersey-starter-swaggerdemo git地址：http://git.oschina.net/keets/spring-boot-samples/tree/master/demo-jersey-starter 参考：spring-boot-starter-swagger 1.3.0.RELEASE：新增对JSR-303的支持和host的配置]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>starter</tag>
        <tag>spring-boot</tag>
        <tag>swagger</tag>
        <tag>jersey</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Restful Layer of SpringMVC vs Jersey]]></title>
    <url>%2F2017%2F08%2F30%2FJerseyvsspringmvc%2F</url>
    <content type="text"><![CDATA[笔者项目实现前后端剥离，服务端对外提供restful接口。REST逐渐成为影响Web框架、Web协议与Web应用设计的重要概念。现在有越来越多的公司希望能以简单而又贴合Web架构本身的方式公开Web API，因此REST变得越来越重要也就不足为奇了。使用Ajax进行通信的富浏览器端也在朝这个目标不断迈进。这个架构原则提升了万维网的可伸缩性，无论何种应用都能从该原则中受益无穷。SpringMVC和Jersey都可以为你提供restful风格的接口。本文将介绍SpringMVC中的REST特性并与Jersey进行对比。 1. REST基础概念 在REST中的一切都被认为是一种资源。 每个资源由URI标识。 使用统一的接口。处理资源使用POST，GET，PUT，DELETE操作类似创建，读取，更新和删除（CRUD）操作。 无状态。每个请求是一个独立的请求。从客户端到服务器的每个请求都必须包含所有必要的信息，以便于理解。 通信都是通过展现。例如XML，JSON。 2. Jersey与SpringMVCJAX-RS（JSR 311）指的是Java API for RESTful Web Services，Roy Fielding也参与了JAX-RS的制订，他在自己的博士论文中定义了REST。对于那些想要构建RESTful Web Services的开发者来说，JAX-RS给出了不同于JAX-WS（JSR-224）的另一种解决方案。目前共有4种JAX-RS实现，所有这些实现都支持Spring，Jersey则是JAX-RS的参考实现。 有必要指出JAX-RS的目标是Web Services开发（这与HTML Web应用不同）而Spring MVC的目标则是Web应用开发。Spring 3为Web应用与Web Services增加了广泛的REST支持，但本文则关注于与Web Services开发相关的特性。我觉得这种方式更有助于在JAX-RS的上下文中讨论Spring MVC。 要说明的第二点是我们将要讨论的REST特性是Spring Framework的一部分，也是现有的Spring MVC编程模型的延续，因此，并没有所谓的“Spring REST framework”这种概念，有的只是Spring和Spring MVC。这意味着如果你有一个Spring应用的话，你既可以使用Spring MVC创建HTML Web层，也可以创建RESTful Web Services层。]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>REST</tag>
        <tag>Jersey</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac下快速进入当前目录iterm2]]></title>
    <url>%2F2017%2F08%2F28%2Fmac%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[win环境下，有直接在文件浏览的地址上，直接输入cmd，即可打开cmd命令框。笔者在macOS下，也想实现这样的功能，网上查了一下，可以成功实践。 1. 添加服务1git clone https://github.com/peterldowns/iterm2-finder-tools.git 进入 iterm2-finder-tools文件夹，运行iTerm.workflow。安装服务栏。 2. 使用服务在工作文件夹上右键，弹出窗口中找到服务一栏，将鼠标放置其上，在弹出窗口中找到 Open iTerm一栏，单击即可。 3. 添加快捷键服务-&gt;偏好设置-&gt;快捷键 笔者设置了control+command+L。大家可以根据自己的喜好进行设置快捷键。 参考： Mac在Finder中当前目录下打开iTerm2]]></content>
      <categories>
        <category>Utils</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 2实际应用]]></title>
    <url>%2F2017%2F08%2F27%2Fhttp2%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1. 背景介绍1.1 需要解决的问题本文来源于项目需要，项目所使用微服务框架为Spring Cloud，微服务之间的调用基于HTTP 1.X协议，上一篇文章 HTTPS vs HTTP 1.1 vs HTTP 2，介绍了http2 和http1.1的相关知识，也列出了http1.1局限性，链路不能复用、数据不加密、头信息过多等等。为此，笔者在想能不能将feign client的调用基于http2协议，做了如下调研。 HTTP/2 源自 SPDY/2。SPDY 系列协议由谷歌开发，于 2009 年公开。它的设计目标是降低 50% 的页面加载时间。当下很多著名的互联网公司，例如百度、淘宝、UPYUN 都在自己的网站或 APP 中采用了 SPDY 系列协议（当前最新版本是 SPDY/3.1），因为它对性能的提升是显而易见的。主流的浏览器（谷歌、火狐、Opera）也都早已经支持 SPDY，它已经成为了工业标准，HTTP Working-Group 最终决定以 SPDY/2 为基础，开发 HTTP/2。2013年8月，进行首次测试，诞生的时间很晚，笔者搜索了网上关于http2实践的相关信息，发现并不多。 1.2 关于项目介绍Spring Cloud是笔者项目采用的微服务框架，具体介绍见Spring Cloud。Spring Cloud是基于Spring Boot开发的组合框架，Spring Boot内置的容器是Tomcat，笔者的项目一般都会exclude Tomcat的引用，使用的是Jetty容器。所以搜索的主题词就变成了 jetty http2。 2. 调研结果大部分的人习惯于将Tomcat运行在8080端口，再用Apache server在前面提供https。这样做是因为简单且验证过的方法。使用http2 ，你将被迫使用https，这样就不用部署Apache (or nginx)。 2.1 服务端 Currently Jetty and undertow are the only servers in Spring Boot that support HTTP/2.Jetty has booked some progress and this repository shows an excellent example. In my opinion it’s still too much custom code, but they’re getting there.The next candidate is undertow. It seems almost too easy, but it works. Because we use AJP in our current configuration it even means this HTTP/2 solution has less lines of code! 当前Spring Boot只有Jetty 和 undertow支持HTTP/2。 样例repo是一个很好的example。总得分为三步： update dependencies org.springframework.boot:spring-boot-starter-undertow org.mortbay.jetty.alpn:alpn-boot:8.1.8.v20160420 create a servlet container bean 1234567@Bean UndertowEmbeddedServletContainerFactory embeddedServletContainerFactory() &#123; UndertowEmbeddedServletContainerFactory factory = new UndertowEmbeddedServletContainerFactory(); factory.addBuilderCustomizers( builder -&gt; builder.setServerOption(UndertowOptions.ENABLE_HTTP2, true)); return factory; &#125; start your server with alpn为了启动服务，需要带上 -Xbootclasspath 参数来包括alpn 。因为alpn 有可能在jdk中没有。 1-Xbootclasspath/p:/home/harrie/.m2/repository/org/mortbay/jetty/alpn/alpn-boot/8.1.8.v20160420/alpn-boot-8.1.8.v20160420.jar 2.2 客户端 Currently Java HTTP/2 clients are scarce. According to this wiki Netty and OkHttp are the only two implementations supported by Spring. To switch HTTP-client in RestTemplate you have to call the constructor with a different ClientHttpRequestFactory (either Netty4ClientHttpRequestFactory or OkHttpClientHttpRequestFactory). 当前Java的http2的客户端也很少，Spring只有Netty and OkHttp支持。这边我们选用了OkHttp，因为OkHttp本来就有在feign client中内置。 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.3.0.RC1&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.3.0.RC1&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt; 2.3 浏览器对于HTTP/2的支持通过浏览器支持http2查看。 2.4 okhttp目前, Http/1.1在全世界大范围的使用中, 直接废弃跳到http/2肯定不现实. 不是每个用户的浏览器都支持http/2的, 也不是每个服务器都打算支持http/2的, 如果我们直接发送http/2格式的协议, 服务器又不支持, 那不是挂掉了! 总不能维护一个全世界的网站列表, 表示哪些支持http/2, 哪些不支持?为了解决这个问题, 从稍高层次上来说, 就是为了更方便地部署新协议, HTTP/1.1 引入了 Upgrade 机制. 这个机制在 RFC7230 的「6.7 Upgrade」这一节中有详细描述.简单说来, 就是先问下你支持http/2么? 如果你支持, 那么接下来我就用http/2和你聊天. 如果你不支持, 那么我还是用原来的http/1.1和你聊天. 客户端在请求头部中指定Connection和Upgrade两个字段发起 HTTP/1.1 协议升级. HTTP/2 的协议名称是 h2c, 代表 HTTP/2 ClearText. 如果服务端不同意升级或者不支持 Upgrade 所列出的协议，直接忽略即可（当成 HTTP/1.1 请求，以 HTTP/1.1 响应）. 如果服务端同意升级，那么需要这样响应 HTTP/1.1 101 Switching ProtocolsConnection: UpgradeUpgrade: h2c[ HTTP/2 connection … ] HTTP Upgrade 响应的状态码是 101，并且响应正文可以使用新协议定义的数据格式。 这样就可以完成从http/1.1升级到http/2了. 同样也可以从http/1.1升级到WebSocket.OkHttp使用了请求协议的协商升级, 无论是1.1还是2, 都先只以1.1来发送, 并在发送的信息头里包含协议升级字段. 接下来就看服务器是否支持协议升级了. OkHttp使用的协议升级字段是ALPN, 如果有兴趣, 可以更深入的查阅相关资料. 3. 总结总体看来，现在Spring boot 是可以支持HTTP/2 server和client。现有项目的api接口面向移动端和web端，web浏览器对于http2的支持在上文已经说明。 参考资料：OkHttp使用完全教程Spring Boot with HTTP/2 – Start a server and make REST calls as a clientHTTPS 与 HTTP2 协议分析]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>HTTP2</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS vs HTTP 1.1 vs HTTP 2]]></title>
    <url>%2F2017%2F08%2F26%2FHTTP2%2F</url>
    <content type="text"><![CDATA[1. HTTPS协议原理分析1.1 需要解决的问题 身份验证:确保通信双方身份的真实性。 通信加密:通信的机密性、完整性依赖于算法与密钥，通信双方是如何选择算法与密钥的。 1.2相关概念 数字证书 CA（certification authority）:数字证书的签发机构。 HTTPS协议、SSL协议、TLS协议、握手协议的关系 HTTPS是Hypertext Transfer Protocol over Secure Socket Layer的缩写，即HTTP over SSL，可理解为基于SSL的HTTP协议。 HTTPS协议安全是由SSL协议（目前常用的，本文基于TLS 1.2进行分析）实现的。 SSL协议是一种记录协议，扩展性良好，可以很方便的添加子协议，而握手协议便是SSL协议的一个子协议。 TLS协议是SSL协议的后续版本，本文中涉及的SSL协议默认是TLS协议1.2版本。 HTTPS协议的安全性由SSL协议实现，当前使用的TLS协议1.2版本包含了四个核心子协议：握手协议、密钥配置切换协议、应用数据协议及报警协议。 1.3 握手协议握手协议的作用便是通信双方进行身份确认、协商安全连接各参数（加密算法、密钥等），确保双方身份真实并且协商的算法与密钥能够保证通信安全。协议交互图： ClientHello消息的作用是，将客户端可用于建立加密通道的参数集合，一次性发送给服务端。 ServerHello消息的作用是，在ClientHello参数集合中选择适合的参数，并将服务端用于建立加密通道的参数发送给客户端。 Certificate消息的作用是，将服务端证书的详细信息发送给客户端，供客户端进行服务端身份校验。 ServerKeyExchange消息的作用是，将需要服务端提供的密钥交换的额外参数，传给客户端。有的算法不需要额外参数，则ServerKeyExchange消息可不发送。 ServerHelloDone消息的作用是，通知客户端ServerHello阶段的数据均已发送完毕，等待客户端下一步消息。 ClientKeyExchange消息的作用是，将客户端需要为密钥交换提供的数据发送给服务端。 ChangeCipherSpec消息的作用，便是声明后续消息均采用密钥加密。在此消息后，我们在WireShark上便看不到明文信息了。 Finished消息的作用，是对握手阶段所有消息计算摘要，并发送给对方校验，避免通信过程中被中间人所篡改。 1.4 总结HTTPS如何保证通信安全，通过握手协议的介绍，我们已经有所了解。但是，在全面使用HTTPS前，我们还需要考虑一个众所周知的问题——HTTPS性能。相对HTTP协议来说，HTTPS协议建立数据通道的更加耗时，若直接部署到App中，势必降低数据传递的效率，间接影响用户体验。 2. HTTP 22.1 HTTP1.x协议随着互联网的快速发展，HTTP1.x协议得到了迅猛发展，但当App一个页面包含了数十个请求时，HTTP1.x协议的局限性便暴露了出来： 每个请求与响应需要单独建立链路进行请求(Connection字段能够解决部分问题)，浪费资源。 每个请求与响应都需要添加完整的头信息，应用数据传输效率较低。 默认没有进行加密，数据在传输过程中容易被监听与篡改。 2.2 HTTP 2介绍HTTP2正是为了解决HTTP1.x暴露出来的问题而诞生的。 说到HTTP2不得不提spdy。由于HTTP1.x暴露出来的问题，Google设计了全新的名为spdy的新协议。spdy在五层协议栈的TCP层与HTTP层引入了一个新的逻辑层以提高效率。spdy是一个中间层，对TCP层与HTTP层有很好的兼容，不需要修改HTTP层即可改善应用数据传输速度。spdy通过多路复用技术，使客户端与服务器只需要保持一条链接即可并发多次数据交互，提高了通信效率。而HTTP2便士基于spdy的思路开发的。通过流与帧概念的引入，继承了spdy的多路复用，并增加了一些实用特性。 新特性： 多路复用 压缩头信息 对请求划分优先级 支持服务端Push消息到客户端 HTTP2目前在实际使用中，只用于HTTPS协议场景下，通过握手阶段ClientHello与ServerHello的extension字段协商而来，所以目前HTTP2的使用场景，都是默认安全加密的。 查看了wiki发现： Netty and OkHttp are the only two implementations supported by Spring. 2.3 协议协商HTTP2协议的协商是在握手阶段进行的。 协商的方式是通过握手协议extension扩展字段进行扩展，新增Application Layer Protocol Negotiation字段进行协商。 在握手协议的ClientHello阶段，客户端将所支持的协议列表填入Application Layer Protocol Negotiation字段，供服务端进行挑选。 2.4 多路复用Multipexing在HTTP2中，同一域名下的请求，可通过同一条TCP链路进行传输，使多个请求不必单独建立链路，节省建立链路的开销。 为了达到这个目的，HTTP2提出了流与帧的概念，流代表请求与响应，而请求与响应具体的数据则包装为帧，对链路中传输的数据通过流ID与帧类型进行区分处理。下图是多路复用的抽象图，每个块代表一帧，而相同颜色的块则代表是同一个流。 归纳下okhttp的多路复用实现思路： 通过请求的Address与连接池中现有连接Address依次匹配，选出可用的Connection。 通过Http2xStream创建的FramedStream在发送了请求后，将FramedStream对象与StreamID的映射关系缓存到FramedConnection中。 收到消息后，FramedConnection解析帧信息，在Map中通过解析的StreamID选出缓存的FramedStream，并唤醒FramedStream进行Response的处理。 2.5 压缩头信息HTTP2为了解决HTTP1.x中头信息过大导致效率低下的问题，提出的解决方案便是压缩头部信息。具体的压缩方式，则引入了HPACK。 HPACK压缩算法是专门为HTTP2头部压缩服务的。为了达到压缩头部信息的目的，HPACK将头部字段缓存为索引，通过索引ID代表头部字段。客户端与服务端维护索引表，通信过程中尽可能采用索引进行通信，收到索引后查询索引表，才能解析出真正的头部信息。 HPACK索引表划分为动态索引表与静态索引表，动态索引表是HTTP2协议通信过程中两端动态维护的索引表，而静态索引表是硬编码进协议中的索引表。 作为分析HPACK压缩头信息的基础，需要先介绍HPACK对索引以及头部字符串的表示方式。 索引 索引以整型数字表示，由于HPACK需要考虑压缩与编解码问题，所以整型数字结构定义下图所示： 类别标识:通过类别标识进行HPACK类别分类，指导后续编解码操作，常见的有1，01，01000000等八个类别。 首字节低位整型:首字节排除类别标识的剩余位，用于表示低位整型。若数值大于剩余位所能表示的容量，则需要后续字节表示高位整型。 结束标识:表示此字节是否为整型解析终止字节。 高位整型:字节余下7bit，用于填充整型高位。]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
        <tag>HTTP2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 集群基础]]></title>
    <url>%2F2017%2F08%2F10%2Fmongodb%E9%9B%86%E7%BE%A4%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[1. MongoDB介绍 MongoDB 是一个可扩展的高性能,开源,模式自由,面向文档的数据库。 它使用 C++编写。MongoDB 包含一下特点: 面向集合的存储:适合存储对象及JSON形式的数据。 动态查询:Mongo 支持丰富的查询方式,查询指令使用 JSON 形式的标记,可轻易查询文档中内嵌的对象及数组。 完整的索引支持:包括文档内嵌对象及数组。Mongo 的查询优化器会分析查询表达式,并生成一个高效的查询计划。 查询监视:Mongo包含一个监控工具用于分析数据库操作性能。 复制及自动故障转移:Mongo 数据库支持服务器之间的数据复制,支持主-从模式及服务器之间的相互复制。复制的主要目的是提供冗余及自动故障转移。 高效的传统存储方式:支持二进制数据及大型对象(如:照片或图片)。 自动分片以支持云级别的伸缩性:自动分片功能支持水平的数据库集群,可动态添加额外的机器。 2.Replica Set集群当中包含了多份数据，保证主节点挂掉了，备节点能继续提供数据服务，提供的前提就是数据需要和主节点一致。 Mongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点。主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。 默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes，同时Java客户端提供了简单的配置方式，可以不必直接对数据库进行操作。 仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。我开始也不相信必须要有仲裁节点，但是自己也试过没仲裁节点的话，主节点挂了备节点还是备节点，所以咱们还是需要它的。 3.Sharding 和Replica Set类似，都需要一个仲裁节点，但是Sharding还需要配置节点和路由节点。 集群搭建方式首选Replica Set，只有真的是大数据，Sharding才能显现威力，毕竟备节点同步数据是需要时间的。Sharding可以将多片数据集中到路由节点上进行一些对比，然后将数据返回给客户端，但是效率还是比较低的说。 我自己有测试过，不过具体的机器配置已经不记得了。Replica Set的ips在数据达到1400w条时基本能达到1000左右，而Sharding在300w时已经下降到500ips了，两者的单位数据大小大概是10kb。大家在应用的时候还是多多做下性能测试，毕竟不像Redis有benchmark。 Mongodb现在用的还是比较多的，但是个人觉得配置太多了。我看官网都看了好多天，才把集群搭建的配置和注意要点弄明白。而且用过的人应该知道mongodb吃内存的问题，解决办法只能通过ulimit来控制内存使用量，但是如果控制不好的话，mongodb会挂掉 PS: 后面继续补充。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 入门]]></title>
    <url>%2F2017%2F07%2F18%2Fspring-cloud%2F</url>
    <content type="text"><![CDATA[1. 微服务架构微服务架构（Micro-Service Archeticture）是当下流行的架构风格，旨在通过将功能模块分解到各个独立的子系统中以实现解耦，它并没有一成不变的规定，而是需要根据业务来做设计[李贞昊,2017]。微服务架构中，每个微服务模块只是对简单、独立、明确的任务进行处理，通过REST API返回处理结果给外部。在微服务推广实践角度来看，微服务将整个系统进行拆分，拆分成更小的粒度，保持这些服务独立运行，应用容器化技术将微服务独立运行在容器中。过去设计架构时，是在内存中以参数或对象的方式实现粒度细化。微服务使用各个子服务控制模块的思想代替总线。不同的业务要求，服务控制模块至少包含服务的发布、注册、路由、代理功能。 2. vs 单体应用架构微服务架构模式相比于单体应用架构，有很多优势。 首先，巨大的单体式应用拆分为多个微服务，降低了复杂性。在具有之前单体应用功能的同时，单体应用被拆分为多个可管理的微服务。每个微服务都具有定义清楚的边界，使用远程过程调用（RPC）或者消息驱动API。拆分后的微服务模块，粒度小，很容易开发和维护。微服务架构模式降低了单体式编码的难度，并且功能提供了模块化的解决方案。 第二，微服务架构下，专门开发团队负责开发一个子服务。每个开发团队可以自主选择技术栈，提供API接口。当然，许多公司将技术栈统一，只提供特定选择的技术。然后，这种自由使得开发团队不需要被迫使用特定的那些技术，他们可以自由地选择适合该微服务的技术。甚至于，重构之前的代码也变得很便捷。 第三，每个微服务都是独立的部署。开发团队不再需要协调其它服务部署对本服务的影响。这样的特性大大加快了部署速度。微服务架构模式使得持续化部署成为可能。 最后，微服务架构模式使得每个微服务应用都可以被独立扩展。单体架构应用也可以横向扩展，即整个应用完整的复制到不同的节点。当应用的不同组件在扩展需求上存在差异时，微服务架构便体现出其优越性。通过在不同的基础设施之间实现扩展，这些服务能够有效地降低风险[陈春霞, 2016]。 3. Spring Cloud开源框架Spring Cloud是一个基于Spring Boot实现的云应用开发工具，它为基于JVM的云应用开发中的服务发现与注册、熔断机制、路由、全局锁、中心配置管理、控制总线、决策竞选、分布式会话和集群状态管理等操作提供了一种简单的开发方式[翟永超,2016]。Spring Cloud整体架构图如图1.1所示。 Spring Cloud整体架构中如下几个基础服务模块：微服务配置管理、API网关服务、服务发现与注册和消息总线模块。 spring-cloud-config，微服务配置管理，即为上图的config service服务模块，为服务端提供了分布式环境的中央配置支持。配置服务器为各应用的所有环境提供了一个中心化的外部配置。它完成了对服务端Spring-Env和配置源抽象的映射，所以config服务不仅适用于Spring框架构建的应用，也可以使用在其他语言的应用程序。作为一个应用，可以通过部署管道来进行测试或者投入生产，分别为这些环境创建配置，并且在需要迁移环境的时候获取对应的配置来运行。 API网关，本系统使用netflix的zuul框架，作为系统的统一入口，具有负载均衡、服务路由、服务过滤等功能。 服务发现与注册有多种开源组件支持，比如zookeeper、etcd、netflix公司的Eureka，以及本系统使用的Consul。服务发现是一个服务将其地址信息在中心注册节点进行注册的过程。该服务一般会将它的主机IP地址以及端口号进行注册，具体还会包括认证信息、使用协议、版本号等信息，以及关于应用服务环境的细节信息。一个应用服务或者组件通过服务发现可以掌握其运行环境以及其它应用服务或组件的信息。用户配置一个服务发现工具之后，就可以将实际容器与运行配置分离开。]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析REST与HTTP]]></title>
    <url>%2F2017%2F07%2F10%2FREST%E4%B8%8EHTTP%2F</url>
    <content type="text"><![CDATA[幂等性Methods can also have the property of &quot;idempotence&quot; in that (aside from error or expiration issues) the side-effects of N &gt; 0 identical requests is the same as for a single request. 安全操作与幂指相等特性（Safety /Idempotence）HTTP 的 GET、HEAD 请求本质上应该是安全的调用，即：GET、HEAD 调用不会有任何的副作用，不会造成服务器端状态的改变。对于服务器来说，客户端对某一 URI 做 n 次的 GET、HAED 调用，其状态与没有做调用是一样的，不会发生任何的改变。 HTTP 的 PUT、DELTE 调用，具有幂指相等特性 , 即：客户端对某一 URI 做 n 次的 PUT、DELTE 调用，其效果与做一次的调用是一样的。HTTP 的 GET、HEAD 方法也具有幂指相等特性。HTTP 这些标准方法在原则上保证你的分布式系统具有这些特性，以帮助构建更加健壮的分布式系统。 当然作为设计的基础，几个必须的原则还是要遵守的： 当标准合理的时候遵守标准。 API应该对程序员友好，并且在浏览器地址栏容易输入。 API应该简单，直观，容易使用的同时优雅。 API应该具有足够的灵活性来支持上层ui。 API设计权衡上述几个原则。 HTTPhttp请求由三部分组成，分别是：请求行、消息报头、请求正文. http 1.1/2 http://www.blogjava.net/yongboy/archive/2015/03/23/423751.html HTTP/1.1，HTTP客户端无法重试非幂等请求，尤其在错误发生的时候，由于无法检测错误性质这会对重试带来不利的影响。 HTTP/2不允许使用连接特定头部字段 新增的5个头部 推送机制的一些特性需求 RST_STREAM等帧标志位的使用]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>REST</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2017%2F02%2F19%2Fdesignsingleton%2F</url>
    <content type="text"><![CDATA[上一篇写了23种设计模式总览，本文主要介绍创建模式中的单例模式，日常工作中也会有经常用到。 1. 定义首先，什么是单例模式？单例模式有以下特点： 从字面就可以理解，单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 单例模式确保某个类只有一个实例，而且自行实例化并向整个系统提供这个实例。适用场合一般是需要频繁地进行创建和销毁的对象。如应用程序中的数据库连接池、线程池等。系统内存中该类只存在一个对象，节省了系统资源，对于一些需要频繁创建销毁的对象，使用单例模式可以提高系统性能。由于单例模式在内存中只有一个实例，减少了内存开销。 单例模式的写法有好几种，这里主要介绍三种：懒汉式单例、饿汉式单例、登记式单例。 2. 实现方法下面以java实现为例，展示几种单例模式的具体实现。 2.1 懒汉式单例12345678910111213//懒汉式单例类.在第一次调用的时候实例化自己 public class Singleton &#123; private Singleton() &#123;&#125; private static Singleton single=null; //静态工厂方法 public static Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single; &#125; //... &#125; 上述Singleton代码通过将构造方法限定为private避免了类在外部被实例化，在同一个虚拟机范围内，Singleton的唯一实例只能通过getInstance()方法访问。（事实上，通过Java反射机制是能够实例化构造方法为private的类的，那基本上会使所有的Java单例实现失效。此问题在此处不做讨论，姑且掩耳盗铃地认为反射机制不存在。） 但是以上实现没有考虑线程安全问题。所谓线程安全是指：如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。或者说：一个类或者程序所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。显然以上实现并不满足线程安全的要求，在并发环境下很可能出现多个Singleton实例。 上述的实现的方式，如果现在存在着线程A和B，线程A执行到了If(singleton == null);，线程B执行到了Singleton = new Singleton();线程B虽然实例化了一个Singleton，但是对于线程A来说判断singleton还是木有初始化的，所以线程A还会对singleton进行初始化。 （1）在getInstance方法上加同步 123456public static synchronized Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single; &#125; 当线程B访问这个函数的时候，其他的任何要访问该函数的代码不能执行，直到线程B执行完该函数（这是利用锁实现的）。 (2) 双重检查锁定DCL synchronized似乎已经解决了多线程下的问题，但多个线程访问同一个函数的时候，那么只能有一个线程能够访问这个函数，效率很低。 12345678910public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; 这种方式将在方法上的声明转移到了内部的代码块中，只有当singleton=null时，才需要锁机制，但是如果线程A和B同时执行到了Synchronized(singleton.class)，虽然也是只有一个线程能够执行，假如线程B先执行，线程B获得锁，线程B执行完之后，线程A获得锁，此时检查singleton是否为空再执行，所以不会出现两个singleton实例的情况。 (3) 静态内部类 关于内部类： 内部类都是在第一次使用时才会被加载。外部类不调用 getInstance（）时候 内部类是不会加载的，所以达到了懒汉的效果。然后调用的时候 内部类被加载，加载的时候就会初始化实例；这个加载的过程是不会有多线程的问题的！类加载的时候有一种机制叫做，缓存机制；第一次加载成功之后会被缓存起来；而且一般一个类不会加载多次。 123456789public class Singleton &#123; private static class LazyHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return LazyHolder.INSTANCE; &#125; &#125; DCL优点是资源利用率高，第一次执行getInstance时单例对象才被实例化，效率高。缺点是第一次加载时反应稍慢一些，在高并发环境下也有一定的缺陷。静态内部类实现，第一次加载Singleton类时并不会初始化sInstance，只有第一次调用getInstance方法时虚拟机加载SingletonHolder 并初始化sInstance ，这样不仅能确保线程安全也能保证Singleton类的唯一性，所以推荐使用静态内部类单例模式。 但是在反序列化时会重新创建对象，将一个单例实例对象写到磁盘再读回来，从而获得了一个实例。反序列化操作提供了readResolve方法，这个方法可以让开发人员控制对象的反序列化。在上述的几个方法示例中如果要杜绝单例对象被反序列化是重新生成对象，就必须加入如下方法： 123private Object readResolve() throws ObjectStreamException&#123; return singleton;&#125; 2.2 饿汉式单例12345678public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123; &#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快。 这种方式基于类加载机制避免了多线程的同步问题，但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到懒加载的效果。 2.3 登记式单例123456789101112131415 //登记式单例类，利用容器实现 //类似Spring里面的方法，将类名注册，下次从里面直接获取。 public class SingletonManager &#123; private static Map&lt;String, Object&gt; objMap = new HashMap&lt;String,Object&gt;(); private Singleton() &#123; &#125; public static void registerService(String key, Objectinstance) &#123; if (!objMap.containsKey(key) ) &#123; objMap.put(key, instance) ; &#125; &#125; public static ObjectgetService(String key) &#123; return objMap.get(key) ; &#125;&#125; SingletonManager将多种的单例类统一管理，在使用时根据key获取对象对应类型的对象。这种方式使得我们可以管理多种类型的单例，并且在使用时可以通过统一的接口进行获取操作，降低了用户的使用成本，也对用户隐藏了具体实现，降低了耦合度。这种不常用，内部实现还是用的饿汉式单例，因为其中的static方法块，它的单例在类被装载的时候就被实例化了。 3. 总结本文主要讲了单例模式的三种方式，分别是懒汉单例、饿汉单例和登记式单例。 主要的使用场景： 需要频繁的进行创建和销毁的对象； 创建对象时耗时过多或耗费资源过多，但又经常用到的对象； 工具类对象； 频繁访问数据库或文件的对象。 饿汉单例，类一旦加载，就把单例初始化完成，保证getInstance的时候，单例是已经存在的了。饿汉式天生就是线程安全的，可以直接用于多线程而不会出现问题。 饿汉式在类创建的同时就实例化一个静态对象出来，占据一定的内存，但是在第一次调用时速度也会更快，因为其资源已经初始化完成。 懒汉单例，只有当调用getInstance的时候，才会去初始化这个单例。是线程不安全的，在饿汉单例实现的基础上，有三种方法对多线程安全进行了处理。懒汉式会延迟加载，在第一次使用该单例的时候才会实例化对象出来，第一次调用时要做初始化，如果要做的工作比较多，性能上会有些延迟，之后就和饿汉式一样了。 参考 JAVA设计模式之单例模式 高并发下线程安全的单例模式（最全最经典）]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23种设计模式总览]]></title>
    <url>%2F2017%2F01%2F12%2FdesignPattern1%2F</url>
    <content type="text"><![CDATA[1. 设计模式分类 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 其他两类：并发型模式和线程池模式。 这边引用下网上的设计模式图。 2. 设计模式的六大原则2.1 总原则总原则为开闭原则。对扩展开放，对修改封闭。在程序需要进行拓展的时候，不用去修改原有的代码，而是扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类等，后面的具体设计中我们会提到这点。 2.2 单一职责原则不要存在多于一个导致类变更的原因，也就是说每个类应该实现单一的职责，否则就应该把类拆分。 2.3 里氏替换原则里氏替换原则（Liskov Substitution Principle），任何基类可以出现的地方，子类一定可以出现。里氏替换原则是继承复用的基石，只有当衍生类可以替换基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。里氏替换原则中，子类对父类的方法尽量不要重写和重载。因为父类代表了定义好的结构，通过这个规范的接口与外界交互，子类不应该随便破坏它。 2.4 依赖倒转原则依赖倒转原则（Dependence Inversion Principle），面向接口编程，依赖于抽象而不依赖于具体。写代码时用到具体类时，不与具体类交互，而与具体类的上层接口交互。 2.5 接口隔离原则接口隔离原则（Interface Segregation Principle），每个接口中不存在子类用不到却必须实现的方法，如果不然，就要将接口拆分。使用多个隔离的接口，比使用单个接口（多个接口方法集合到一个的接口）要好。 2.6 迪米特法则迪米特法则，最少知道原则（Demeter Principle），一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public方法提供给外部。这样当被依赖的类变化时，才能最小的影响该类。最少知道原则的另一个表达方式是：只与直接的朋友通信。类之间只要有耦合关系，就叫朋友关系。耦合分为依赖、关联、聚合、组合等。我们称出现为成员变量、方法参数、方法返回值中的类为直接朋友。局部变量、临时变量则不是直接的朋友。我们要求陌生的类不要作为局部变量出现在类中。 2.7 合成复用原则合成复用原则（Composite Reuse Principle），尽量首先使用合成/聚合的方式，而不是使用继承。 3 总结本文主要写了设计模式的总览，对23种设计模式进行分类，包括创建型模式、结构型模式、行为型模式以及两种其他模式。其次介绍了设计模式的六大原则。后面文章将扩展介绍每一种设计模式。 参考1.23种设计模式全解析]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
</search>