{"meta":{"title":"Aoho's Blog","subtitle":"Grasp All, Lose All.","description":"聚沙成塔！","author":"aoho","url":"http://blueskykong.com"},"pages":[{"title":"","date":"2018-01-09T03:20:16.000Z","updated":"2017-09-04T13:56:03.000Z","comments":true,"path":"404.html","permalink":"http://blueskykong.com/404.html","excerpt":"","text":""},{"title":"分类","date":"2017-07-10T08:42:36.000Z","updated":"2017-07-10T08:44:39.000Z","comments":false,"path":"categories/index.html","permalink":"http://blueskykong.com/categories/index.html","excerpt":"","text":""},{"title":"关于博主","date":"2018-02-11T13:54:56.000Z","updated":"2018-02-11T13:54:55.000Z","comments":false,"path":"about/index.html","permalink":"http://blueskykong.com/about/index.html","excerpt":"","text":"技术栈以Java、Python、Golang为主，主要从事后端服务开发，对于分布式基础的软件架构很感兴趣。 深入研究常用的MQ中间件，对Kafka、Rabbitmq、NSQ中间件较为了解。最近致力于微服务架构，以Spring Cloud为基础，参与中型软件系统设计与实现。 最后，本站所有内容均代表个人观点，与本人雇主及其他团体无关。 邮箱：aoho002#gmail.com 欢迎交流与讨论。"},{"title":"标签","date":"2017-06-22T04:39:04.000Z","updated":"2017-07-10T08:36:24.000Z","comments":false,"path":"tags/index.html","permalink":"http://blueskykong.com/tags/index.html","excerpt":"","text":""},{"title":"归档","date":"2017-06-22T04:39:04.000Z","updated":"2018-02-14T02:16:25.000Z","comments":false,"path":"archives/index.html","permalink":"http://blueskykong.com/archives/index.html","excerpt":"","text":""}],"posts":[{"title":"test","slug":"test","date":"2018-02-28T10:39:47.000Z","updated":"2018-02-28T10:39:47.000Z","comments":true,"path":"2018/02/28/test/","link":"","permalink":"http://blueskykong.com/2018/02/28/test/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Spring中的事件驱动模型（一）","slug":"spring-event-sourcing","date":"2018-02-21T16:00:00.000Z","updated":"2018-02-22T09:43:21.000Z","comments":true,"path":"2018/02/22/spring-event-sourcing/","link":"","permalink":"http://blueskykong.com/2018/02/22/spring-event-sourcing/","excerpt":"","text":"正月初七，新年第一篇。 事件驱动模型简介事件驱动模型通常也被理解成观察者或者发布/订阅模型。 是一种对象间的一对多的关系； 当目标发送改变（发布），观察者（订阅者）就可以接收到改变； 观察者如何处理，目标无需干涉，它们之间的关系是松耦合的。 事件驱动模型的例子很多，如生活中的红绿灯，以及我们在微服务中用到的配置中心，当有配置提交时出发具体的应用实例更新Spring上下文环境。 Spring的事件机制基本概念Spring的事件驱动模型由三部分组成： 事件：ApplicationEvent，继承自JDK的EventObject，所有事件将继承它，并通过source得到事件源。 事件发布者：ApplicationEventPublisher及ApplicationEventMulticaster接口，使用这个接口，我们的Service就拥有了发布事件的能力。 事件订阅者：ApplicationListener，继承自JDK的EventListener，所有监听器将继承它。 Spring事件驱动过程事件Spring 默认对 ApplicationEvent 事件提供了如下实现： ContextStoppedEvent：ApplicationContext停止后触发的事件； ContextRefreshedEvent：ApplicationContext初始化或刷新完成后触发的事件； ContextClosedEvent：ApplicationContext关闭后触发的事件。如web容器关闭时自动会触发Spring容器的关闭，如果是普通java应用，需要调用ctx.registerShutdownHook()注册虚拟机关闭时的钩子才行； ContextStartedEvent：ApplicationContext启动后触发的事件； 12345678910111213public abstract class ApplicationEvent extends EventObject &#123; private static final long serialVersionUID = 7099057708183571937L; //事件发生的时间 private final long timestamp = System.currentTimeMillis(); //创建一个新的ApplicationEvent事件 public ApplicationEvent(Object source) &#123; super(source); &#125; public final long getTimestamp() &#123; return this.timestamp; &#125;&#125; 事件基类ApplicationEvent，所有的具体事件都会继承该抽象事件类。 事件监听者ApplicationListener继承自JDK的EventListener，JDK要求所有监听器将继承它。 1234@FunctionalInterfacepublic interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener &#123; void onApplicationEvent(E var1);&#125; 提供了onApplicationEvent方法，用以处理ApplicationEvent，不过对于具体事件的处理需要进行判断。而GenericApplicationListener和SmartApplicationListener提供了关于事件更多的元数据信息。 123456789101112131415161718192021222324252627public class SourceFilteringListener implements GenericApplicationListener, SmartApplicationListener &#123; private final Object source; @Nullable private GenericApplicationListener delegate; //为特定事件源创建SourceFilteringListener，并传入代理的监听器类 public SourceFilteringListener(Object source, ApplicationListener&lt;?&gt; delegate) &#123; this.source = source; this.delegate = (delegate instanceof GenericApplicationListener ? (GenericApplicationListener) delegate : new GenericApplicationListenerAdapter(delegate)); &#125; //....省略部分代码 @Override public int getOrder() &#123; return (this.delegate != null ? this.delegate.getOrder() : Ordered.LOWEST_PRECEDENCE); &#125; //过滤之后实际处理事件 protected void onApplicationEventInternal(ApplicationEvent event) &#123; //... this.delegate.onApplicationEvent(event); &#125;&#125; SourceFilteringListener是ApplicationListener的装饰器类，过滤特定的事件源。只会注入其事件对应的代理监听器，还提供了按照顺序触发监听器等功能。在启动的时候会加载一部分 ApplicationListener。Spring Context加载初始化完成（refresh）后会再次检测应用中的 ApplicationListener，并且注册，此时会将我们实现的 ApplicationListener 就会加入到 SimpleApplicationEventMulticaster 维护的 Listener 集合中。Spring也支持直接注解的形式进行事件监听@EventListener(Event.class)。 事件发布ApplicationContext接口继承了ApplicationEventPublisher，并在AbstractApplicationContext实现了具体代码，实际执行是委托给ApplicationEventMulticaster。 123456789@FunctionalInterfacepublic interface ApplicationEventPublisher &#123; //通知所有的注册该事件的应用，事件可以是框架事件如RequestHandledEvent或者特定的应用事件。 default void publishEvent(ApplicationEvent event) &#123; this.publishEvent((Object)event); &#125; void publishEvent(Object var1);&#125; 实际的执行是委托给，读者有兴趣可以看一下AbstractApplicationContext中这部分的逻辑。下面我们具体看一下ApplicationEventMulticaster接口中定义的方法。 1234567891011121314public interface ApplicationEventMulticaster &#123; //增加监听者 void addApplicationListener(ApplicationListener&lt;?&gt; listener); //... //移除监听者 void removeApplicationListener(ApplicationListener&lt;?&gt; listener); //... //广播特定事件给监听者 void multicastEvent(ApplicationEvent event, @Nullable ResolvableType eventType);&#125; AbstractApplicationContext中定义了对监听者的操作维护，如增加和删除，并提供了将特定事件进行广播的方法。下面看一下具体实现类SimpleApplicationEventMulticaster。ApplicationContext自动到本地容器里找一个ApplicationEventMulticaster实现，如果没有则会使用默认的SimpleApplicationEventMulticaster。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SimpleApplicationEventMulticaster extends AbstractApplicationEventMulticaster &#123; @Nullable private Executor taskExecutor; //... //用给定的beanFactory创建SimpleApplicationEventMulticaster public SimpleApplicationEventMulticaster(BeanFactory beanFactory) &#123; setBeanFactory(beanFactory); &#125; @Override public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; invokeListener(listener, event); &#125; &#125; &#125; //注入给定事件的给定监听器 protected void invokeListener(ApplicationListener&lt;?&gt; listener, ApplicationEvent event) &#123; ErrorHandler errorHandler = getErrorHandler(); if (errorHandler != null) &#123; try &#123; doInvokeListener(listener, event); &#125; ... &#125; else &#123; doInvokeListener(listener, event); &#125; &#125; @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) private void doInvokeListener(ApplicationListener listener, ApplicationEvent event) &#123; try &#123; listener.onApplicationEvent(event); &#125; //... &#125;&#125; 在multicastEvent方法中，executor不为空的情况下，可以看到是支持异步发布事件。发布事件时只需要调用ApplicationContext中的publishEvent方法即可进行事件的发布。 总结本文主要介绍了Spring中的事件驱动模型相关概念。首先介绍事件驱动模型，也可以说是观察者模式，在我们的日常生活中和应用开发中有很多应用。随后重点篇幅介绍了Spring的事件机制，Spring的事件驱动模型由事件、发布者和订阅者三部分组成，结合Spring的源码分析了这三部分的定义与实现。笔者将会在下一篇文章，结合具体例子以及Spring Cloud Config中的实现进行实战讲解。 参考 事件驱动模型简介 Spring事件驱动模型与观察者模式","categories":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/categories/java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blueskykong.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://blueskykong.com/tags/Spring/"}]},{"title":"我的2017","slug":"2017summary","date":"2018-02-14T04:42:47.000Z","updated":"2018-02-22T05:29:48.000Z","comments":true,"path":"2018/02/14/2017summary/","link":"","permalink":"http://blueskykong.com/2018/02/14/2017summary/","excerpt":"","text":"这篇总结来的有点晚，算是丁酉鸡年的总结吧。明天就是农历新年的除夕，鸡年的最后一个工作日，在下午回家之前总结一下我的2017。 2017的几件事写博客在2017养成了写博客的习惯，其实之前也会在印象记事本上面记录，只是没有系统进行知识的整理。我个人认为这个习惯帮我巩固了很多知识点，首先是对知识的整理，会结合具体组件或者算法进行流程图和思维导图的整理；其次，语言表述的提升，刚开始写得时候经常要参考好多网上的资料，文章的结构组织等等，写了一段时间，发现对于关键需要注意的地方能够把握了。到现在，写文章相对比较轻松了，似乎已经成了一种习惯。平时工作中，将一些感兴趣的记下来，或者是一些想法。下班后尽量抽时间进行整理，当然肯定是要自己完全弄懂，之后整理成文章发布到博客中。这种形式可以是一种记录供以后复习，另一方面给与分享交流。 博客刚开始写了一些基础的设计模式，后面写的主要是微服务相关以及中间件相关的文章。还有些文章写了没有放到博客上（主要是设计模式和golang），慢慢更新吧，博客目前累计文章50篇。 公众号九月份开通了微信公众号：aoho求索。刚开始并不想开通，因为维护很麻烦，因为本来工作已经很饱和了！后来开通的原因很简单，就是博客的关注量太低了，有些东西写出来需要能够和别人交流，在博客上基本没有留言，而微信公众号相对互动性会更好，转发到群里面，分享的同时，也会认真考虑别人的意见进行提升。 微信公众号上面发的文章也不是很多，大概二十篇左右，当然关注量也低，和那些大的公众号完全不能比。虽然关注的人少，每一篇文章都是我的原创，写完也会花时间自己认真读几遍，至于文章的质量，我只能说努力提升自己的技术，尽量一些以讹传讹的知识。当然，我个人的能力是有限的，有不足的地方欢迎指出，我会认真考虑并改进不足的地方。尽最大努力做到不误人子弟。 golang与JVM其实16年实习的时候就接触和学习了golang，花的时间并不是那么多。到了今年上半年，重点花时间学习了一下。后来在工作没怎么用到，当时接触了golang的开源项目NSQ中间件（bitly开源的消息队列系统，性能非常高，目前他们每天处理数十亿条的消息），看了其实现的原理，有C语言的基础上手并不是很难。当然docker更加火热。对于分布式系统，golang语言层面支持并发以及丰富的标准库，我觉得golang更胜一筹，也是发展的趋势。国外如Google、AWS等，国内如七牛、阿里等都已经开始大规模使用golang开发其云计算相关产品。 另一个方面就是Java的底层。年中的时候，把JVM中的一些东西理了一遍。加入了一个JVM交流群，虽然在工作中实际接触的问题少（项目还未上线），群里面倒是经常有人抛问题，借机接触了产线的JVM问题。这部分在明年还需要加强，因为今年花的时间并不多，有些问题还需要深入分析。 基础组件开发今年的工作主要就是搭建了微服务架构的一套，微服务架构采用的是当前很火的Spring Cloud。因为我在Spring Cloud推出的时候就关注了该项目，所以实际组件应用开发也比较轻车熟路。我们的项目并不大，所以前期基础组件还是花了很长时间的。 技术的发展速度还是很快的，不断有新的概念和名词推出。比如Service mesh，一个云原生应用（cloud native application）的构建离不开Service mesh。2015年谷歌成立了CNCF，云原生将成为应用云化开发的主流方式。具体有机会在具体总结吧，积极拥抱新技术。 源码分析Spring Cloud组件的源码看得挺多，偶然的机会有出版社联系，准备和另外两个开发同学一起写一本Spring Cloud的进阶应用书籍。借此机会提升自己与弥补市场上缺少的Spring Cloud进阶应用书籍。已经写了部分章节，写书确实很费时间，工作之外的时间基本被挤压了。年后继续加油。 最后，祝福每个人，新的一年能够心想事成，身体健康。2018，加油！","categories":[{"name":"自留地","slug":"自留地","permalink":"http://blueskykong.com/categories/自留地/"}],"tags":[]},{"title":"Spring Cloud Bus中的事件的订阅与发布（一）","slug":"spring-cloud-bus-event","date":"2018-02-12T16:00:00.000Z","updated":"2018-02-14T01:31:43.000Z","comments":true,"path":"2018/02/13/spring-cloud-bus-event/","link":"","permalink":"http://blueskykong.com/2018/02/13/spring-cloud-bus-event/","excerpt":"","text":"年前最后一篇博客更新，提前祝大家新年快乐（还有情人节）！ 下面进入正题。Spring Cloud Bus用轻量级的消息代理将分布式系统的节点连接起来。这可以用来广播状态的该表（比如配置的改变）或者其他关联的指令。一个关键的想法是，总线就像是一个分布式Actuator，用于Spring Boot应用程序的扩展，但它也可以用作应用程序之间的通信通道。Spring Cloud提供了AMQP 传输的代理和Kafka启动Starters，对具有相同的基本功能集的其他传输组件的支持，也在未来的规划中。 Spring Cloud BusSpring Cloud Bus是在Spring Cloud Stream的基础上进行的封装，对于指定主题的消息的发布与订阅是通过Spring Cloud Stream的具体binder实现。因此引入的依赖可以是spring-cloud-starter-bus-amqp和spring-cloud-starter-bus-kafka其中的一种，分别对应于binder的两种实现。根据上一节的基础应用，我们总结出Spring Cloud Bus的主要功能如下两点： 对指定主题springCloudBus的消息订阅与发布。 事件监听，包括刷新事件、环境变更事件、远端应用的ack事件以及本地服务端发送事件等。 下面我们以这两方面作为主线，进行Spring Cloud Bus的源码分析。本文主要针对事件的订阅户发布。 事件的订阅与发布事件驱动模型这部分需要读者首先了解下Spring的事件驱动模型。我们在这边简单介绍下设计的主要概念，帮助大家易于理解后面的内容。 Spring的事件驱动模型由三部分组成： 事件：ApplicationEvent，继承自JDK的EventObject，所有事件将继承它，并通过source得到事件源。 事件发布者：ApplicationEventPublisher及ApplicationEventMulticaster接口，使用这个接口，我们的Service就拥有了发布事件的能力。 事件订阅者：ApplicationListener，继承自JDK的EventListener，所有监听器将继承它。 事件的定义Spring的事件驱动模型的事件定义均继承自ApplicationEvent，Spring Cloud Bus中有多个事件类，这些事件类都继承了一个重要的抽象类RemoteApplicationEvent，我们看一下事件类的类图： 涉及的事件类有：代表了对特定事件确认的事件AckRemoteApplicationEvent、环境变更的事件EnvironmentChangeRemoteApplicationEvent、刷新事件RefreshRemoteApplicationEvent、发送事件 SentApplicationEvent、以及未知事件UnknownRemoteApplicationEvent。下面我们分别看一下这些事件的定义。 抽象基类：RemoteApplicationEvent通过上面的类图，我们知道RemoteApplicationEvent是其他事件类的基类，定义了事件对象的公共属性。 12345678910111213141516171819202122232425262728@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"type\") //序列化时使用子类的名称作为type@JsonIgnoreProperties(\"source\") //序列化时，忽略 sourcepublic abstract class RemoteApplicationEvent extends ApplicationEvent &#123; private static final Object TRANSIENT_SOURCE = new Object(); private final String originService; private final String destinationService; private final String id; protected RemoteApplicationEvent(Object source, String originService, String destinationService) &#123; super(source); this.originService = originService; if (destinationService == null) &#123; destinationService = \"**\"; &#125; if (!\"**\".equals(destinationService)) &#123; if (StringUtils.countOccurrencesOf(destinationService, \":\") &lt;= 1 &amp;&amp; !StringUtils.endsWithIgnoreCase(destinationService, \":**\")) &#123; //destination的所有实例 destinationService = destinationService + \":**\"; &#125; &#125; this.destinationService = destinationService; this.id = UUID.randomUUID().toString(); &#125; ...&#125; 在RemoteApplicationEvent中定义了主要的三个通用属性事件的来源originService、事件的目的服务destinationService和随机生成的全局id。通过其构造方法可知，destinationService可以使用通配符的形式{serviceId}:{appContextId}，两个变量都省略的话，则通知到所有服务的所有实例。只省略appContextId时，则对应的destinationService为相应serviceId的所有实例。另外，注解@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = &quot;type&quot;)对应于序列化时，使用子类的名称作为type；而@JsonIgnoreProperties(&quot;source&quot;)表示序列化时，忽略source属性，source定义在JDK中的EventObject。 EnvironmentChangeRemoteApplicationEvent用于动态更新服务实例的环境属性，我们在基础应用中更新cloud.version属性时，关联到该事件。 1234567891011public class EnvironmentChangeRemoteApplicationEvent extends RemoteApplicationEvent &#123; private final Map&lt;String, String&gt; values; public EnvironmentChangeRemoteApplicationEvent(Object source, String originService, String destinationService, Map&lt;String, String&gt; values) &#123; super(source, originService, destinationService); this.values = values; &#125; ...&#125; 可以看到，EnvironmentChangeRemoteApplicationEvent事件类的实现很简单。定义了Map类型的成员变量，key对应于环境变量名，而value对应更新后的值。 RefreshRemoteApplicationEvent刷新远端应用配置的事件，用于接收远端刷新的请求。 123456public class RefreshRemoteApplicationEvent extends RemoteApplicationEvent &#123; public RefreshRemoteApplicationEvent(Object source, String originService, String destinationService) &#123; super(source, originService, destinationService); &#125;&#125; 继承自抽象事件类RemoteApplicationEvent，没有特别的成员属性。 AckRemoteApplicationEvent确认远端应用事件，该事件表示一个特定的RemoteApplicationEvent事件被确认。 123456789101112131415161718192021222324public class AckRemoteApplicationEvent extends RemoteApplicationEvent &#123; private final String ackId; private final String ackDestinationService; private Class&lt;? extends RemoteApplicationEvent&gt; event; public AckRemoteApplicationEvent(Object source, String originService, String destinationService, String ackDestinationService, String ackId, Class&lt;? extends RemoteApplicationEvent&gt; type) &#123; super(source, originService, destinationService); this.ackDestinationService = ackDestinationService; this.ackId = ackId; this.event = type; &#125; ... public void setEventName(String eventName) &#123; try &#123; event = (Class&lt;? extends RemoteApplicationEvent&gt;) Class.forName(eventName); &#125; catch (ClassNotFoundException e) &#123; event = UnknownRemoteApplicationEvent.class; &#125; &#125;&#125; 该事件类在RemoteApplicationEvent基础上，定义了成员属性ackId、ackDestinationService和event。ackId和ackDestinationService，分别表示确认的时间的id和对应的目标服务。event对应事件类型，确认事件能够确认的必然是RemoteApplicationEvent的子类，因此event属性设值时需要进行检查，如果转换出现异常，则定义为未知的事件类型。这些事件可以被任何需要统计总线事件响应的应用程序来监听。 它们的行为与普通的远程应用程序事件相似，即如果目标服务与本地服务ID匹配，则应用程序会在其上下文中触发该事件。 SentApplicationEvent发送应用事件，表示系统中的某个地方发送了一个远端事件。 123456789101112131415161718192021222324252627282930313233@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"type\")@JsonIgnoreProperties(\"source\")public class SentApplicationEvent extends ApplicationEvent &#123; private static final Object TRANSIENT_SOURCE = new Object(); private final String originService; private final String destinationService; private final String id; private Class&lt;? extends RemoteApplicationEvent&gt; type; protected SentApplicationEvent() &#123; // for serialization libs like jackson this(TRANSIENT_SOURCE, null, null, null, RemoteApplicationEvent.class); &#125; public SentApplicationEvent(Object source, String originService, String destinationService, String id, Class&lt;? extends RemoteApplicationEvent&gt; type) &#123; super(source); this.originService = originService; this.type = type; if (destinationService == null) &#123; destinationService = \"*\"; &#125; if (!destinationService.contains(\":\")) &#123; // All instances of the destination unless specifically requested destinationService = destinationService + \":**\"; &#125; this.destinationService = destinationService; this.id = id; &#125; ...&#125; 可以看到该事件类继承自ApplicationEvent，它本身并不是一个RemoteApplicationEvent事件，所以不会通过总线发送，而是在本地生成（多为响应远端事件）。想要审计远端事件的应用可以监听该事件，并且所有的AckRemoteApplicationEvent事件中的id来源于相应的SentApplicationEvent中定义的id。在其定义的成员属性中，相比于远端应用事件多了一个事件类型type，该类型限定于RemoteApplicationEvent的子类。 UnknownRemoteApplicationEvent未知的远端应用事件，也是RemoteApplicationEvent事件类的子类。该事件类与之前的SentApplicationEvent、AckRemoteApplicationEvent有关，当序列化时遇到事件的类型转换异常，则自动构造成一个未知的远端应用事件。 事件监听器以及消息的订阅与发布待后续更新。。 参考Spring Cloud Bus-v1.3.3","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blueskykong.com/tags/Spring-Cloud/"}]},{"title":"Eureka Server之间的注册表信息同步","slug":"eureka-instance-registry","date":"2018-02-08T16:00:00.000Z","updated":"2018-02-09T02:49:40.000Z","comments":true,"path":"2018/02/09/eureka-instance-registry/","link":"","permalink":"http://blueskykong.com/2018/02/09/eureka-instance-registry/","excerpt":"","text":"本文作者cangwu，文章节选自其即将出版的《Spring Cloud组件源码解析与高级应用》 一书。 前言Eureka 作为一个服务注册中心，Eureka Server必然是可以通过集群的方式进行部署，但是分布式系统中一个很关键的点就是数据的一致性，多节点部署的Eureka Server必然涉及到不同节点之间的注册表信息的一致性，在CAP中，Eureka 注重的满足了AP，对C只满足的弱一致性(最终一致性)，牺牲了强一致性保证了高可用性，但是Eureka Sever中依然有方式保证节点之间的注册表的信息的一致性。 注册表类结构首先我们来看一下面一张类图 在这里InstanceRegistry就是Eureka Server注册表的最顶级接口，在内存中维护着注册到Eureka Server中的服务实例的信息 LeaseManager定义了对服务实例租约的管理接口 1234567891011public interface LeaseManager&lt;T&gt; &#123; void register(T r, int leaseDuration, boolean isReplication); boolean cancel(String appName, String id, boolean isReplication); boolean renew(String appName, String id, boolean isReplication); void evict();&#125; register(注册)、cancel(下线)、renew(更新)、evict(剔除)，这四个方法对应了Eureka Client与Eureka Server的交互行为相对应，是对注册表信息中的服务实例的租约管理方法，而Lease描述了一个基于时限可用的泛型，表示的是一个Eureka服务实例的租约，这里面也提供了关于对其内持有的类的时间有效性的相关操作，它持有的类恰好服务实例的信息com.netflix.appinfo.InstanceInfo，下面是该类的关键对象引用和方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Lease&lt;T&gt; &#123; // 操作类型 enum Action &#123; Register, Cancel, Renew &#125;; public static final int DEFAULT_DURATION_IN_SECS = 90; private T holder; //服务实例数据 private long evictionTimestamp;//服务剔除时间 private long registrationTimestamp;//注册时间 private long serviceUpTimestamp;//服务上线时间 // Make it volatile so that the expiration task would see this quicker private volatile long lastUpdateTimestamp;//上次更新时间 private long duration;//信息有效时长 public Lease(T r, int durationInSecs) &#123; holder = r; registrationTimestamp = System.currentTimeMillis(); lastUpdateTimestamp = registrationTimestamp; duration = (durationInSecs * 1000); &#125; // 服务续约 public void renew() &#123; lastUpdateTimestamp = System.currentTimeMillis() + duration; &#125; // 服务下线 public void cancel() &#123; if (evictionTimestamp &lt;= 0) &#123; evictionTimestamp = System.currentTimeMillis(); &#125; &#125; public void serviceUp() &#123; if (serviceUpTimestamp == 0) &#123; serviceUpTimestamp = System.currentTimeMillis(); &#125; &#125; .... // 租约是否过期 public boolean isExpired() &#123; return isExpired(0l); &#125; public boolean isExpired(long additionalLeaseMs) &#123; return (evictionTimestamp &gt; 0 || System.currentTimeMillis() &gt; (lastUpdateTimestamp + duration + additionalLeaseMs)); &#125; public T getHolder() &#123; return holder; &#125;&#125; Lease中的定义了租约的操作操作类型，分别是注册、下线、更新，同时具备对租约中时间属性进行的各项操作。默认的租约有效时间duration为90秒 其中AbstractInstanceRegistry中了对上述方法的进行了实现，有兴趣的同学可以去查看一下源码的实现 Server之间的注册表信息的同步复制先介绍一下PeerEurekaNodes，它是管理了Eureka Server的peer节点生命周期的列表，其中peer的信息封装在PeerEurekaNode类中管理了Eureka Server的peer节点生命周期的列表，简单理解，一个PeerEurekaNode就是一个Eureka Server集群的节点 在PeerAwareInstanceRegistryImpl中，对Abstractinstanceregistry中的register()、cancel()、renew()等方法都添加了同步到PeerEurekaNode的操作，使Server集群中的注册表信息保持最终一致性 12345678910111213141516171819202122232425262728@Overridepublic boolean cancel(final String appName, final String id, final boolean isReplication) &#123; if (super.cancel(appName, id, isReplication)) &#123; // 同步下线状态 replicateToPeers(Action.Cancel, appName, id, null, null, isReplication); ... &#125; ...&#125; public void register(final InstanceInfo info, final boolean isReplication) &#123; int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS; if (info.getLeaseInfo() != null &amp;&amp; info.getLeaseInfo().getDurationInSecs() &gt; 0) &#123; leaseDuration = info.getLeaseInfo().getDurationInSecs(); &#125; super.register(info, leaseDuration, isReplication); // 同步注册状态 replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);&#125;public boolean renew(final String appName, final String id, final boolean isReplication) &#123; if (super.renew(appName, id, isReplication)) &#123; // 同步续约状态 replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication); return true; &#125; return false;&#125; 同步的状态主要有： 1234public enum Action &#123; Heartbeat, Register, Cancel, StatusUpdate, DeleteStatusOverride; ...&#125; 对此需要关注的replicateToPeers()方法，对传递的不同的同步状态，进行不同的处理 1234567891011121314151617181920212223242526 private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) &#123; Stopwatch tracer = action.getTimer().start(); try &#123; if (isReplication) &#123; numberOfReplicationsLastMin.increment(); &#125; // 如果peer集群为空，或者这本来就是复制操作，那么就不再复制，防止造成循环复制 if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) &#123; return; &#125; // 向peer集群中的每一个peer进行同步 for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) &#123; // 如果peer节点是自身的话，不进行同步复制 if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) &#123; continue; &#125; // 根据Action调用不同的同步请求 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); &#125; &#125; finally &#123; tracer.stop(); &#125;&#125; 在replicateInstanceActionsToPeers()方法中将根据Action的不同，调用PeerEurekaNode的不同方法进行同步复制 123456789101112131415161718192021222324252627282930private void replicateInstanceActionsToPeers(Action action, String appName, String id, InstanceInfo info, InstanceStatus newStatus, PeerEurekaNode node) &#123; try &#123; InstanceInfo infoFromRegistry = null; CurrentRequestVersion.set(Version.V2); switch (action) &#123; case Cancel: node.cancel(appName, id); break; case Heartbeat: InstanceStatus overriddenStatus = overriddenInstanceStatusMap.get(id); infoFromRegistry = getInstanceByAppAndId(appName, id, false); node.heartbeat(appName, id, infoFromRegistry, overriddenStatus, false); break; case Register: node.register(info); break; case StatusUpdate: infoFromRegistry = getInstanceByAppAndId(appName, id, false); node.statusUpdate(appName, id, newStatus, infoFromRegistry); break; case DeleteStatusOverride: infoFromRegistry = getInstanceByAppAndId(appName, id, false); node.deleteStatusOverride(appName, id, infoFromRegistry); break; &#125; &#125; catch (Throwable t) &#123; logger.error(\"Cannot replicate information to &#123;&#125; for action &#123;&#125;\", node.getServiceUrl(), action.name(), t);&#125; 在PeerEurekaNode中的每一个同步复制方式都是通过批任务流的方式进行操作，同时相同的服务实例的相同操作使用相同的任务编号，方便接受的同步复制的Eureka Server根据任务编号的异同合并操作，检查同步操作的数量，减少网络同步的消耗，由于Eureka Server中的信息同步是通过HTTP的方式，难免会出现网络延迟，造成同步复制的延时性，不满足CAP中的C(强一致性)。 同步冲突对于Eureka Server之间的HTTP以及批任务流交互过程，我们在此不多关注，需要在意的是Eureka Server在接受到对应的同步复制请求后如何修改自身的注册表信息，以及反馈给发起同步复制请求的Eureka Server 这里首先明确一个概念，InstanceInfo中的lastDirtyTimestamp表示的是服务实例信息的上次变动的时间戳，可以比较它来了解服务实例信息的哪边更新 考虑以下的情况，在Euerka Server同步的过程如果出现同一服务实例在两个Server的信息不一致的信息冲突，将如何进行处理？主要有以下两种情况 同步注册信息的时候，被同步的一方也同样存在相同服务实例的租约，如果被同步一方的lastDirtyTimestamp比较小，那么被同步一方的注册表中关于该服务实例的租约将会被覆，如果被同步的一方的lastDirtyTimestamp的比较大，那么租约将不会被覆盖，(这部分在AbstractInstanceRegistry.register()中代码中查看答案)但是这时发起同步的Eureka Server中的租约就是dirty的，该如何处理？(问题1) 同步续约(心跳)信息的时候，被同步一方的租约不存在或者是lastDirtyTimestamp比较小(问题2)(被同步一方的租约是dirty)，如何处理； 或者被同步一方的lastDirtyTimestamp比较大，又如何处理？(问题3)(发起同步的一方的租约是dirty) 这是总共是3个问题，让我们在下面一一解答。 不考虑cancel()的同步情况，是因为这不会对Eureka Server集群中的注册表信息造成污染，由于各Eureka Server中有自身的定时租约剔除操作(evict()) 首先我们看一下InstanceResource，这不仅是Eureka Client与Eureka Server进行通信的endpoint，同时也是Eureka Server与Eureka Server之间进行同步复制的进行处理的委托类 在InstanceResource中我们主要关注renewLease()，是用于Eureka Client请求该接口维持在Eureka Server中的注册表中的租约，就是维持心跳的接口 1234567891011121314151617181920212223242526public Response renewLease( @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication, @QueryParam(\"overriddenstatus\") String overriddenStatus, @QueryParam(\"status\") String status, @QueryParam(\"lastDirtyTimestamp\") String lastDirtyTimestamp) &#123; boolean isFromReplicaNode = \"true\".equals(isReplication); boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode); // 没有发现对应的租约，要求一次注册 if (!isSuccess) &#123; logger.warn(\"Not Found (Renew): &#123;&#125; - &#123;&#125;\", app.getName(), id); return Response.status(Status.NOT_FOUND).build(); &#125; // 是否需要同步数据到发起同步方，因为本地的服务实例信息更新 Response response = null; if (lastDirtyTimestamp != null &amp;&amp; serverConfig.shouldSyncWhenTimestampDiffers()) &#123; // 验证本地的注册表中的服务实例的lastDirtyTimestamp是不是更小，如果是返回404 response = this.validateDirtyTimestamp(Long.valueOf(lastDirtyTimestamp), isFromReplicaNode); ... &#125; &#125; else &#123; response = Response.ok().build(); &#125; logger.debug(\"Found (Renew): &#123;&#125; - &#123;&#125;; reply status=&#123;&#125;\" + app.getName(), id, response.getStatus()); return response;&#125; 在AbstractInstanceRegistry.renew()方法中，返回false的情况只有两种，一种是租约确实不存在，另一种是overriddenInstanceStatus，表示无法续约，这是时候将返回status为404给请求端，同时renewLease()方法调用了validateDirtyTimestamp()方法判断本地注册表中服务实例的lastDirtyTimestamp与续租时传递的lastDirtyTimestamp进行比较，如果本地的比较小，一样会返回404的status，相反如果本地的比较大，就返回409的status，同时将本地的InstanceInfo放到repsonse中，将这就符合了我们的问题2和问题3的情况 123456789101112131415// validateDirtyTimestamp()方法中 ...if (lastDirtyTimestamp &gt; appInfo.getLastDirtyTimestamp()) &#123; // 本地注册表中的服务实例的lastDirtyTimestamp比较小 return Response.status(Status.NOT_FOUND).build();&#125; else if (appInfo.getLastDirtyTimestamp() &gt; lastDirtyTimestamp) &#123; // 本地注册表中的服务实例的lastDirtyTimestamp比较大 if (isReplication) &#123; // 如果在同步复制情况下，返回409，同时将本地的InstanceInfo放到response中 return Response.status(Status.CONFLICT).entity(appInfo).build(); &#125; else &#123; return Response.ok().build(); &#125;&#125;... 接着我们跟踪到PeerReplicationResource，这里是Eureka Server之间进行同步复制的endpoint，我们找到handleHeartbeat()方法 123456789101112131415161718private static Builder handleHeartbeat(EurekaServerConfig config, InstanceResource resource, String lastDirtyTimestamp, String overriddenStatus, String instanceStatus) &#123; Response response = resource.renewLease(REPLICATION, overriddenStatus, instanceStatus, lastDirtyTimestamp); int responseStatus = response.getStatus(); Builder responseBuilder = new Builder().setStatusCode(responseStatus); if (\"false\".equals(config.getExperimental(\"bugfix.934\"))) &#123; if (responseStatus == Status.OK.getStatusCode() &amp;&amp; response.getEntity() != null) &#123; responseBuilder.setResponseEntity((InstanceInfo) response.getEntity()); &#125; &#125; else &#123; // 如果检测到 if ((responseStatus == Status.OK.getStatusCode() || responseStatus == Status.CONFLICT.getStatusCode()) &amp;&amp; response.getEntity() != null) &#123; responseBuilder.setResponseEntity((InstanceInfo) response.getEntity()); &#125; &#125; return responseBuilder;&#125; 处理方式没有多大的变化，虽然对重新构建的Response，但是和上面的返回结果是一致的 现在我们就可以假设一下问题2和问题3的是如何解决的 如果是被同步一方Eureka Server的该服务实例的租约不存在或者是lastDirtyTimestamp比较小，那么它将在设置返回的response status为404；发起同步的一方会将这个服务实例的信息通过同步注册的方式再次发送。在Eureka Client与Eureka Server之间的续租(心跳)就是这样一个流程 如果被同步一方Eureka Server的该服务实例的租约的lastDirtyTimestamp比较大，那么它将在设置返回的response status为409，同时将本地的该服务实例的InstanceInfo发到response中；发起同步的一方会将根据409的状态，抽取出response中的InstanceInfo，将其注册到本地注册表中 以上都还只是我们的猜想，需要我们进行验证。 找到ReplicationTaskProcessor类，这是对同步复制批任务流处理的类，Eureka Server在该类中发起与peer节点的之间的HTTP同步请求，并对返回的response进行处理 在这里，我们发现上述单任务流同步操作，还是批任务流同步操作，在处理结果上都是调用了ReplicationTask中的方法，ReplicationTask类代表的是单个同步复制任务 123456public void handleSuccess() &#123;&#125;public void handleFailure(int statusCode, Object responseEntity) throws Throwable &#123; logger.warn(&quot;The replication of task &#123;&#125; failed with response code &#123;&#125;&quot;, getTaskName(), statusCode);&#125; 但是这里并没有我们猜想中的处理，但是我们发现ReplicationTask是一个abstract，说明底下肯定有其他实现了。 最后，我们回到PeerEurekaNode中，在创建每个ReplicationTask任务的地方，我们发现对handleFailure()方法的重写。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// PeerEurekaNodepublic void heartbeat(final String appName, final String id, final InstanceInfo info, final InstanceStatus overriddenStatus, boolean primeConnection) throws Throwable &#123; ... ReplicationTask replicationTask = new InstanceReplicationTask(targetHost, Action.Heartbeat, info, overriddenStatus, false) &#123; @Override public EurekaHttpResponse&lt;InstanceInfo&gt; execute() throws Throwable &#123; return replicationClient.sendHeartBeat(appName, id, info, overriddenStatus); &#125; @Override public void handleFailure(int statusCode, Object responseEntity) throws Throwable &#123; super.handleFailure(statusCode, responseEntity); if (statusCode == 404) &#123; logger.warn(\"&#123;&#125;: missing entry.\", getTaskName()); if (info != null) &#123; // 如果状态是404，发起一次同步注册 register(info); &#125; &#125; else if (config.shouldSyncWhenTimestampDiffers()) &#123; InstanceInfo peerInstanceInfo = (InstanceInfo) responseEntity; if (peerInstanceInfo != null) &#123; // 如果两者的lastDirtyTimestamp，同步response中的InstanceInfo到本地 syncInstancesIfTimestampDiffers(appName, id, info, peerInstanceInfo); &#125; &#125; &#125; &#125;; long expiryTime = System.currentTimeMillis() + getLeaseRenewalOf(info); // 提交任务到批分发器中 batchingDispatcher.process(taskId(\"heartbeat\", info), replicationTask, expiryTime);&#125;private void syncInstancesIfTimestampDiffers(String appName, String id, InstanceInfo info, InstanceInfo infoFromPeer) &#123; try &#123; if (infoFromPeer != null) &#123; if (infoFromPeer.getOverriddenStatus() != null &amp;&amp; !InstanceStatus.UNKNOWN.equals(infoFromPeer.getOverriddenStatus())) &#123; registry.storeOverriddenStatusIfRequired(appName, id, infoFromPeer.getOverriddenStatus()); &#125; // 将InstanceInfo注册到本地，覆盖本地注册表中服务实例信息 registry.register(infoFromPeer, true); &#125; &#125; catch (Throwable e) &#123; logger.warn(\"Exception when trying to set information from peer :\", e); &#125;&#125; 通过上面的代码，我们最终发现了完整的闭环操作，与我们所做的猜想是一样的。 但是问题1又如何解决呢？厉害的读者一定也猜到了，没错，还是通过续租(心跳)同步，当Eureka Client与Eureka Server发起renew()请求的时候，接受renew()将持有最新的lastDirtyTimestamp，通过同步心跳(续租)的方式，将该服务实例的最新InstanceInfo同步覆盖到peer节点的注册表中，维持Server集群注册表信息的一致性 所以，我们发现整一个Eureka Server的集群是通过续租(心跳)的操作来维持集群的注册表信息的最终一致性，但是由于网络延迟或者波动原因，无法做到强一致性。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blueskykong.com/tags/Spring-Cloud/"}]},{"title":"比较Spring AOP与AspectJ","slug":"aj-vs-aop","date":"2018-01-23T16:00:00.000Z","updated":"2018-02-01T15:01:28.000Z","comments":true,"path":"2018/01/24/aj-vs-aop/","link":"","permalink":"http://blueskykong.com/2018/01/24/aj-vs-aop/","excerpt":"","text":"本文翻译自博客Comparing Spring AOP and AspectJ 介绍如今有多个可用的AOP库，在使用这些组件之前需要回答一系列的问题： 是否与我现有的应用兼容？ 我在哪实现AOP？ 集成到我的应用是否很快？ 性能开销是多少？ 本文中，我们将会着重回答这些问题，并介绍两款Java最流行的AOP框架：Spring AOP 和 AspectJ。 AOP概念在我们开始之前，让我们对术语和核心概念做一个快速，高水平的回顾： Aspect切面：一个分布在应用程序中多个位置的标准代码/功能，通常与实际的业务逻辑（例如事务管理）不同。 每个切面都侧重于一个特定的横切功能。 Joinpoint连接点：这是程序执行中的特定点，如方法执行，构调用造函数或字段赋值等。 Advice通知：在一个连接点中，切面采取的行动 Pointcut切点：一个匹配连接点的正则表达式。 每当任何连接点匹配一个切入点时，就执行与该切入点相关联的指定通知。 Weaving织入：链接切面和目标对象来创建一个通知对象的过程。 Spring AOP and AspectJ现在，一起来讨论Spring AOP and AspectJ，跨越多指标，如能力和目标、织入方式、内部结构、连接点和简单性。 Capabilities and Goals简而言之，Spring AOP和AspectJ有不同的目标。Spring AOP旨在通过Spring IoC提供一个简单的AOP实现，以解决编码人员面临的最常出现的问题。这并不是完整的AOP解决方案，它只能用于Spring容器管理的beans。 另一方面，AspectJ是最原始的AOP实现技术，提供了玩这个的AOP解决方案。AspectJ更为健壮，相对于Spring AOP也显得更为复杂。值得注意的是，AspectJ能够被应用于所有的领域对象。 Weaving AspectJ and Spring AOP使用了不同的织入方式，这影响了他们在性能和易用性方面的行为。 AspectJ使用了三种不同类型的织入： 编译时织入：AspectJ编译器同时加载我们切面的源代码和我们的应用程序，并生成一个织入后的类文件作为输出。 编译后织入：这就是所熟悉的二进制织入。它被用来编织现有的类文件和JAR文件与我们的切面。 加载时织入：这和之前的二进制编织完全一样，所不同的是织入会被延后，直到类加载器将类加载到JVM。 更多关于AspectJ的信息，请见head on over to this article。 AspectJ使用的是编译期和类加载时进行织入，Spring AOP利用的是运行时织入。 运行时织入，在使用目标对象的代理执行应用程序时，编译这些切面（使用JDK动态代理或者CGLIB代理）。 Internal Structure and ApplicationSpring AOP 是一个基于代理的AOP框架。这意味着，要实现目标对象的切面，将会创建目标对象的代理类。这可以通过下面两种方式实现： JDK动态代理：Spring AOP的首选方法。 每当目标对象实现一个接口时，就会使用JDK动态代理。 CGLIB代理：如果目标对象没有实现接口，则可以使用CGLIB代理。 关于Spring AOP可以通过官网了解更多。另一方面，AspectJ在运行时不做任何事情，类和切面是直接编译的。因此，不同于Spring AOP，他不需要任何设计模式。织入切面到代码中，它引入了自己的编译期，称为AspectJ compiler (ajc)。通过它，我们编译应用程序，然后通过提供一个小的（&lt;100K）运行时库运行它。 Joinpoints在上一小节，我们介绍了Spring AOP基于代理模式。因此，它需要目标类的子类，并相应的应用横切关注点。但是也伴随着局限性，我们不能跨越“final”的类来应用横切关注点（或切面），因为它们不能被覆盖，从而导致运行时异常。 同样地，也不能应用于静态和final的方法。由于不能覆写，Spring的切面不能应用于他们。因此，Spring AOP由于这些限制，只支持执行方法的连接点。然而，AspectJ在运行前将横切关注点直接织入实际的代码中。 与Spring AOP不同，它不需要继承目标对象，因此也支持其他许多连接点。AspectJ支持如下的连接点： 同样值得注意的是，在Spring AOP中，切面不适用于同一个类中调用的方法。这很显然，当我们在同一个类中调用一个方法时，我们并没有调用Spring AOP提供的代理的方法。如果我们需要这个功能，可以在不同的beans中定义一个独立的方法，或者使用AspectJ。 SimplicitySpring AOP显然更加简单，因为它没有引入任何额外的编译期或在编译期织入。它使用了运行期织入的方式，因此是无缝集成我们通常的构建过程。尽管看起来很简单，Spring AOP只作用于Spring管理的beans。 然而，使用AspectJ，我们需要引入AJC编译器，重新打包所有库（除非我们切换到编译后或加载时织入）。这种方式相对于前一种，更加复杂，因为它引入了我们需要与IDE或构建工具集成的AspectJ Java工具（包括编译器（ajc），调试器（ajdb），文档生成器（ajdoc），程序结构浏览器（ajbrowser））。 Performance考虑到性能问题，编译时织入比运行时织入快很多。Spring AOP是基于代理的框架，因此应用运行时会有目标类的代理对象生成。另外，每个切面还有一些方法调用，这会对性能造成影响。 AspectJ不同于Spring AOP，是在应用执行前织入切面到代码中，没有额外的运行时开销。 由于以上原因，AspectJ经过测试大概8到35倍快于Spring AOP。benchmarks 对比这个快速表总结了Spring AOP和AspectJ之间的主要区别： 选择合适的框架如果我们分析本节所有的论点，我们就会开始明白，没有绝对的一个框架比另一个框架更好。简而言之，选择很大程度上取决我们的需求： 框架：如果应用程序不使用Spring框架，那么我们别无选择，只能放弃使用Spring AOP的想法，因为它无法管理任何超出spring容器范围的东西。 但是，如果我们的应用程序完全是使用Spring框架创建的，那么我们可以使用Spring AOP，因为它很直接便于学习和应用。 灵活性：鉴于有限的连接点支持，Spring AOP并不是一个完整的AOP解决方案，但它解决了程序员面临的最常见的问题。 如果我们想要深入挖掘并利用AOP达到其最大能力，并希望获得来自各种可用连接点的支持，那么AspectJ是最佳选择。 性能：如果我们使用有限的切面，那么性能差异很小。 但是，有时候应用程序有数万个切面的情况。 在这种情况下，我们不希望使用运行时织入，所以最好选择AspectJ。 已知AspectJ比Spring AOP快8到35倍。 共同优点：这两个框架是完全兼容的。 我们可以随时利用Spring AOP，并且仍然使用AspectJ来获得前者不支持的连接点。 总结在这篇文章中，我们分析了Spring AOP和AspectJ比较关键的几个方面。我们比较了AOP和AOP两种方法的灵活性，以及它们与我们的应用程序的匹配程度。","categories":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/categories/java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blueskykong.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://blueskykong.com/tags/Spring/"}]},{"title":"Spring Cloud 覆写远端的配置属性","slug":"config-server2","date":"2018-01-22T16:00:00.000Z","updated":"2018-01-24T10:51:58.000Z","comments":true,"path":"2018/01/23/config-server2/","link":"","permalink":"http://blueskykong.com/2018/01/23/config-server2/","excerpt":"","text":"覆写远端的配置属性应用的配置源通常都是远端的Config Server服务器，默认情况下，本地的配置优先级低于远端配置仓库。如果想实现本地应用的系统变量和config文件覆盖远端仓库中的属性值，可以通过如下设置： 123456spring: cloud: config: allowOverride: true overrideNone: true overrideSystemProperties: false overrideNone：当allowOverride为true时，overrideNone设置为true，外部的配置优先级更低，而且不能覆盖任何存在的属性源。默认为false allowOverride：标识overrideSystemProperties属性是否启用。默认为true，设置为false意为禁止用户的设置 overrideSystemProperties：用来标识外部配置是否能够覆盖系统属性，默认为true 客户端通过如上配置，可以实现本地配置优先级更高，且不能被覆盖。由于我们基于的Spring Cloud当前版本是Edgware.RELEASE，上面的设置并不能起作用，而是使用了PropertySourceBootstrapProperties中的默认值。具体情况见issue：https://github.com/spring-cloud/spring-cloud-commons/pull/250，我们在下面分析时会讲到具体的bug源。 源码分析ConfigServicePropertySourceLocator覆写远端的配置属性归根结底与客户端的启动时获取配置有关，在获取到配置之后如何处理？我们看一下spring cloud config中的资源获取类ConfigServicePropertySourceLocator的类图。 ConfigServicePropertySourceLocator实质是一个属性资源定位器，其主要方法是locate(Environment environment)。首先用当前运行应用的环境的application、profile和label替换configClientProperties中的占位符并初始化RestTemplate，然后遍历labels数组直到获取到有效的配置信息，最后还会根据是否快速失败进行重试。主要流程如下： locate(Environment environment)调用getRemoteEnvironment(restTemplate, properties, label, state)方法通过http的方式获取远程服务器上的配置数据。实现也很简单，显示替换请求路径path中占位符，然后进行头部headers组装，组装好了就可以发送请求，最后返回结果。在上面的实现中，我们看到获取到的配置信息存放在CompositePropertySource，那是如何使用它的呢？这边补充另一个重要的类是PropertySourceBootstrapConfiguration，它实现了ApplicationContextInitializer接口，该接口会在应用上下文刷新之前refresh()被回调，从而执行初始化操作，应用启动后的调用栈如下： 1SpringApplicationBuilder.run() -&gt; SpringApplication.run() -&gt; SpringApplication.createAndRefreshContext() -&gt; SpringApplication.applyInitializers() -&gt; PropertySourceBootstrapConfiguration.initialize() PropertySourceBootstrapConfiguration而上述ConfigServicePropertySourceLocator的locate方法会在initialize中被调用，从而保证上下文在刷新之前能够拿到必要的配置信息。具体看一下initialize方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class PropertySourceBootstrapConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered &#123; private int order = Ordered.HIGHEST_PRECEDENCE + 10; @Autowired(required = false) private List&lt;PropertySourceLocator&gt; propertySourceLocators = new ArrayList&lt;&gt;(); @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; CompositePropertySource composite = new CompositePropertySource( BOOTSTRAP_PROPERTY_SOURCE_NAME); //对propertySourceLocators数组进行排序，根据默认的AnnotationAwareOrderComparator AnnotationAwareOrderComparator.sort(this.propertySourceLocators); boolean empty = true; //获取运行的环境上下文 ConfigurableEnvironment environment = applicationContext.getEnvironment(); for (PropertySourceLocator locator : this.propertySourceLocators) &#123; //遍历this.propertySourceLocators PropertySource&lt;?&gt; source = null; source = locator.locate(environment); if (source == null) &#123; continue; &#125; logger.info(\"Located property source: \" + source); //将source添加到PropertySource的链表中 composite.addPropertySource(source); empty = false; &#125; //只有source不为空的情况，才会设置到environment中 if (!empty) &#123; //返回Environment的可变形式，可进行的操作如addFirst、addLast MutablePropertySources propertySources = environment.getPropertySources(); String logConfig = environment.resolvePlaceholders(\"$&#123;logging.config:&#125;\"); LogFile logFile = LogFile.get(environment); if (propertySources.contains(BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; //移除bootstrapProperties propertySources.remove(BOOTSTRAP_PROPERTY_SOURCE_NAME); &#125; //根据config server覆写的规则，设置propertySources insertPropertySources(propertySources, composite); reinitializeLoggingSystem(environment, logConfig, logFile); setLogLevels(environment); //处理多个active profiles的配置信息 handleIncludedProfiles(environment); &#125; &#125; //...&#125; 下面我们看一下，在initialize方法中进行了哪些操作。 根据默认的 AnnotationAwareOrderComparator 排序规则对propertySourceLocators数组进行排序 获取运行的环境上下文ConfigurableEnvironment 遍历propertySourceLocators时 调用 locate 方法，传入获取的上下文environment 将source添加到PropertySource的链表中 设置source是否为空的标识标量empty source不为空的情况，才会设置到environment中 返回Environment的可变形式，可进行的操作如addFirst、addLast 移除propertySources中的bootstrapProperties 根据config server覆写的规则，设置propertySources 处理多个active profiles的配置信息 初始化方法initialize处理时，先将所有PropertySourceLocator类型的对象的locate方法遍历，然后将各种方式得到的属性值放到CompositePropertySource中，最后调用insertPropertySources(propertySources, composite)方法设置到Environment中。Spring Cloud Context中提供了覆写远端属性的PropertySourceBootstrapProperties，利用该配置类进行判断属性源的优先级。 123456789101112131415161718192021222324252627282930313233343536private void insertPropertySources(MutablePropertySources propertySources, CompositePropertySource composite) &#123; MutablePropertySources incoming = new MutablePropertySources(); incoming.addFirst(composite); PropertySourceBootstrapProperties remoteProperties = new PropertySourceBootstrapProperties(); new RelaxedDataBinder(remoteProperties, \"spring.cloud.config\") .bind(new PropertySourcesPropertyValues(incoming)); //如果不允许本地覆写 if (!remoteProperties.isAllowOverride() || (!remoteProperties.isOverrideNone() &amp;&amp; remoteProperties.isOverrideSystemProperties())) &#123; propertySources.addFirst(composite); return; &#125; //overrideNone为true，外部配置优先级最低 if (remoteProperties.isOverrideNone()) &#123; propertySources.addLast(composite); return; &#125; if (propertySources .contains(StandardEnvironment.SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME)) &#123; //根据overrideSystemProperties，设置外部配置的优先级 if (!remoteProperties.isOverrideSystemProperties()) &#123; propertySources.addAfter( StandardEnvironment.SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, composite); &#125; else &#123; propertySources.addBefore( StandardEnvironment.SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, composite); &#125; &#125; else &#123; propertySources.addLast(composite); &#125;&#125; 上述实现主要是根据PropertySourceBootstrapProperties中的属性，调整多个配置源的优先级。从其实现可以看到 PropertySourceBootstrapProperties 对象的是被直接初始化，使用的是默认的属性值而并未注入我们在配置文件中设置的。 修复后的实现： 123456789@Autowired(required = false)private PropertySourceBootstrapProperties remotePropertiesForOverriding;private void insertPropertySources(MutablePropertySources propertySources, CompositePropertySource composite) &#123; MutablePropertySources incoming = new MutablePropertySources(); incoming.addFirst(composite); PropertySourceBootstrapProperties remoteProperties = remotePropertiesForOverriding == null ? new PropertySourceBootstrapProperties() : remotePropertiesForOverriding; ... &#125; 参考Spring Cloud Edgware.RELEASE","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blueskykong.com/tags/Spring-Cloud/"}]},{"title":"Redis Cluster深入与实践（续）","slug":"rediscluster2","date":"2018-01-08T16:00:00.000Z","updated":"2018-01-09T11:25:50.000Z","comments":true,"path":"2018/01/09/rediscluster2/","link":"","permalink":"http://blueskykong.com/2018/01/09/rediscluster2/","excerpt":"","text":"前文回顾上一篇文章基于redis的分布式锁实现写了基于redis实现的分布式锁。分布式环境下，不会还使用单点的redis，做到高可用和容灾，起码也是redis主从。redis的单线程工作，一台物理机只运行一个redis实例太过浪费，redis单机显然是存在单点故障的隐患。内存资源往往受限，纵向不停扩展内存并不是很实际，因此横向可伸缩扩展，需要多台主机协同提供服务，即分布式下多个Redis实例协同运行。 在之前的文章Redis Cluster深入与实践介绍过Redis Cluster的相关内容，之前特地花时间在redis官网看了redis cluster的相关文档和实现。本文是那篇文章的续集，因为笔者最近在调研redis的主从切换到redis 集群的方案，将会讲下redis集群的几种方案选型和redis cluster的实践。 redis集群的几种实现方式如下： 客户端分片，如redis的Java客户端jedis也是支持的，使用一致性hash 基于代理的分片，如codis和Twemproxy 路由查询， redis-cluster 下面我们分别介绍下这几种方案。 客户端分片Redis Sharding是Redis Cluster出来之前，业界普遍使用的多Redis实例集群方法。其主要思想是采用哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。java redis客户端驱动jedis，支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool。 Redis Sentinel提供了主备模式下Redis监控、故障转移功能达到系统的高可用性。在主Redis宕机时，备Redis接管过来，上升为主Redis，继续提供服务。主备共同组成一个Redis节点，通过自动故障转移，保证了节点的高可用性。 客户端sharding技术其优势在于非常简单，服务端的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，非常容易线性扩展，系统的灵活性很强。 客户端sharding的劣势也是很明显的。由于sharding处理放到客户端，规模进一步扩大时给运维带来挑战。客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化。 基于代理的分片客户端发送请求到一个代理组件，代理解析客户端的数据，并将请求转发至正确的节点，最后将结果回复给客户端。 该模式的特性如下： 透明接入，业务程序不用关心后端Redis实例，切换成本低。 Proxy 的逻辑和存储的逻辑是隔离的。 代理层多了一次转发，性能有所损耗。 简单的结构图如下： 主流的组件有：Twemproxy和Codis。 Twemproxy Twemproxy也叫nutcraker，是twtter开源的一个redis和memcache代理服务器程序。redis作为一个高效的缓存服务器，非常具有应用价值。但在用户数据量增大时，需要运行多个redis实例，此时将迫切需要一种工具统一管理多个redis实例，避免在每个客户端管理所有连接带来的不方便和不易维护，Twemproxy即为此目标而生。 Twemproxy有以下几个特点： 快 轻量级 维持永久的服务端连接 支持失败节点自动删除；可以设置重新连接该节点的时间，还可以设置连接多少次之后删除该节点 支持设置HashTag；通过HashTag可以自己设定将同一类型的key映射到同一个实例上去。 减少与redis的直接连接数，保持与redis的长连接，可设置代理与后台每个redis连接的数目 自带一致性hash算法，能够将数据自动分片到后端多个redis实例上；支持多种hash算法，可以设置后端实例的权重，目前redis支持的hash算法有：one_at_a_time、md5、crc16、crc32、fnv1_64、fnv1a_64、fnv1_32、fnv1a_32、hsieh、murmur、jenkins。 支持redis pipelining request，将多个连接请求，组成reids pipelining统一向redis请求。 支持状态监控；可设置状态监控ip和端口，访问ip和端口可以得到一个json格式的状态信息串；可设置监控信息刷新间隔时间。 TwemProxy 官网介绍了如上的特性。TwemProxy的使用可以像访问redis客户端一样访问TwemProxy。然而Twitter已经很久放弃了更新TwemProxy。Twemproxy最大的痛点在于，无法平滑地扩容/缩容。Twemproxy另一个痛点是，运维不友好，甚至没有控制面板。 Codis Codis是豌豆荚开源的redis集群方案，是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有显著区别 , 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作, 所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务。 Codis当前最新release 版本为 codis-3.2，codis-server 基于 redis-3.2.8。有一下组件组成： Codis Server：基于 redis-3.2.8 分支开发。增加了额外的数据结构，以支持 slot 有关的操作以及数据迁移指令。 Codis Proxy：客户端连接的 Redis 代理服务, 实现了 Redis 协议。 除部分命令不支持以外(不支持的命令列表)，表现的和原生的 Redis 没有区别（就像 Twemproxy）。 Codis Dashboard：集群管理工具，支持 codis-proxy、codis-server 的添加、删除，以及据迁移等操作。在集群状态发生改变时，codis-dashboard 维护集群下所有 codis-proxy 的状态的一致性。对于同一个业务集群而言，同一个时刻 codis-dashboard 只能有 0个或者1个；所有对集群的修改都必须通过 codis-dashboard 完成。 Codis Admin：集群管理的命令行工具。可用于控制 codis-proxy、codis-dashboard 状态以及访问外部存储。 Codis FE：集群管理界面。多个集群实例共享可以共享同一个前端展示页面；通过配置文件管理后端 codis-dashboard 列表，配置文件可自动更新。 Storage：为集群状态提供外部存储。提供 Namespace 概念，不同集群的会按照不同 product name 进行组织；目前仅提供了 Zookeeper、Etcd、Fs 三种实现，但是提供了抽象的 interface 可自行扩展。 至于具体的安装与使用，见官网CodisLabs，不在此涉及。 Codis的特性： Codis支持的命令更加丰富，基本支持redis的命令。 迁移成本低，迁移到codis没这么麻烦，只要使用的redis命令在codis支持的范围之内，只要修改一下配置即可接入。 Codis提供的运维工具更加友好，提供web图形界面管理集群。 支持多核心CPU，twemproxy只能单核 支持group划分，组内可以设置一个主多个从，通过sentinel 监控redis主从，当主down了自动将从切换为主 路由查询Redis Cluster是一种服务器Sharding技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行。当客户端操作的key没有分配到该node上时，就像操作单一Redis实例一样，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node，这有点儿像浏览器页面的302 redirect跳转。 Redis集群，要保证16384个槽对应的node都正常工作，如果某个node发生故障，那它负责的slots也就失效，整个集群将不能工作。为了增加集群的可访问性，官方推荐的方案是将node配置成主从结构，即一个master主节点，挂n个slave从节点。这时，如果主节点失效，Redis Cluster会根据选举算法从slave节点中选择一个上升为主节点，整个集群继续对外提供服务。 特点： 无中心架构，支持动态扩容，对业务透明 具备Sentinel的监控和自动Failover能力 客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可 高性能，客户端直连redis服务，免去了proxy代理的损耗 缺点是运维也很复杂，数据迁移需要人工干预，只能使用0号数据库，不支持批量操作，分布式逻辑和存储模块耦合等。 选型最后确定redis cluster。主要原因是性能高，去中心化支持扩展。运维方面的数据迁移暂时业内也没有特别成熟的方案解决，redis cluster是redis官方提供，我们期待redis官方在后面能够完美支持。 安装官方推荐集群至少需要六个节点，即三主三从。六个节点的配置文件基本相同，只需要修改端口号。 12345port 7000cluster-enabled yes #开启集群模式cluster-config-file nodes.confcluster-node-timeout 5000appendonly yes 启动后，可以看到如下的日志。 [82462] 26 Nov 11:56:55.329 * No cluster configuration found, I’m 97a3a64667477371c4479320d683e4c8db5858b1 由于没有nodes.conf存在，每个实例启动后都会给自己分配一个ID。为了在集群的环境中有一个唯一的名字，该ID将会被永久使用。每个实例都会保存其他节点使用的ID，而不是通过IP和端口。IP和端口可能会改变，但是唯一的node ID将不会改变直至该node的死亡。 我们现在已经启动了六个redis实例， 需要通过写一些有意义的配置信息到各个节点来创建集群。redis cluster的命令行工具redis-trib，利用Ruby程序在实例上执行一些特殊的命令，很容易实现创建新的集群、检查或者reshard现有的集群等。 12./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \\127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 --replicas 1参数是将每个master带上一个slave。 配置JedisClusterConfig12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Configurationpublic class JedisClusterConfig &#123; private static Logger logger = LoggerFactory.getLogger(JedisClusterConfig.class); @Value(\"$&#123;redis.cluster.nodes&#125;\") private String clusterNodes; @Value(\"$&#123;redis.cluster.timeout&#125;\") private int timeout; @Value(\"$&#123;redis.cluster.max-redirects&#125;\") private int redirects; @Autowired private JedisPoolConfig jedisPoolConfig; @Bean public RedisClusterConfiguration getClusterConfiguration() &#123; Map&lt;String, Object&gt; source = new HashMap(); source.put(\"spring.redis.cluster.nodes\", clusterNodes); logger.info(\"clusterNodes: &#123;&#125;\", clusterNodes); source.put(\"spring.redis.cluster.max-redirects\", redirects); return new RedisClusterConfiguration(new MapPropertySource(\"RedisClusterConfiguration\", source)); &#125; @Bean public JedisConnectionFactory getConnectionFactory() &#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(getClusterConfiguration()); jedisConnectionFactory.setTimeout(timeout); return jedisConnectionFactory; &#125; @Bean public JedisClusterConnection getJedisClusterConnection() &#123; return (JedisClusterConnection) getConnectionFactory().getConnection(); &#125; @Bean public RedisTemplate getRedisTemplate() &#123; RedisTemplate clusterTemplate = new RedisTemplate(); clusterTemplate.setConnectionFactory(getConnectionFactory()); clusterTemplate.setKeySerializer(new StringRedisSerializer()); clusterTemplate.setDefaultSerializer(new GenericJackson2JsonRedisSerializer()); return clusterTemplate; &#125;&#125; 可以配置密码，cluster对密码支持不太友好，如果对集群设置密码，那么requirepass和masterauth都需要设置，否则发生主从切换时，就会遇到授权问题。 配置redis cluster123456redis: cluster: enabled: true timeout: 2000 max-redirects: 8 nodes: 127.0.0.1:7000,127.0.0.1:7001 主要配置了redis cluster的节点、超时时间等。 使用RedisTemplate123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class RedisConfigTest &#123; @Autowired RedisTemplate redisTemplate; @Test public void clusterTest() &#123; redisTemplate.opsForValue().set(\"foo\", \"bar\"); System.out.println(redisTemplate.opsForValue().get(\"foo\")); &#125;&#125; 用法很简单，注入RedisTemplate即可进行操作，RedisTemplate用法比较丰富，可以自行查阅。 总结本文主要讲了redis集群的选型，主要有三种：客户端分片、基于代理的分片以及路由查询。对于前两种方式，分别进行简单地介绍，最后选择redis官方提供的redis cluster方案，并进行了实践。虽然正式版的推出时间不长，目前成功实践的案例也还不多，但是总体来说，redis cluster的整个设计是比较简单的，大部分操作都可以按照单点的操作流程进行操作。笔者使用的jedis客户端支持JedisCluster也是比较好，用起来也很方便。其实还有个压测的数据，后面再补上吧。 参考 Redis集群方案应该怎么做？ cluster-tutorial twemproxy CodisLabs","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blueskykong.com/categories/中间件/"}],"tags":[{"name":"mq","slug":"mq","permalink":"http://blueskykong.com/tags/mq/"},{"name":"redis","slug":"redis","permalink":"http://blueskykong.com/tags/redis/"}]},{"title":"基于redis的分布式锁实现","slug":"redislock","date":"2018-01-05T16:00:00.000Z","updated":"2018-01-07T12:12:52.000Z","comments":true,"path":"2018/01/06/redislock/","link":"","permalink":"http://blueskykong.com/2018/01/06/redislock/","excerpt":"","text":"关于分布式锁很久之前有讲过并发编程中的锁并发编程的锁机制：synchronized和lock。在单进程的系统中，当存在多个线程可以同时改变某个变量时，就需要对变量或代码块做同步，使其在修改这种变量时能够线性执行消除并发修改变量。而同步的本质是通过锁来实现的。为了实现多个线程在一个时刻同一个代码块只能有一个线程可执行，那么需要在某个地方做个标记，这个标记必须每个线程都能看到，当标记不存在时可以设置该标记，其余后续线程发现已经有标记了则等待拥有标记的线程结束同步代码块取消标记后再去尝试设置标记。 分布式环境下，数据一致性问题一直是一个比较重要的话题，而又不同于单进程的情况。分布式与单机情况下最大的不同在于其不是多线程而是多进程。多线程由于可以共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一台物理机上，因此需要将标记存储在一个所有进程都能看到的地方。 常见的是秒杀场景，订单服务部署了多个实例。如秒杀商品有4个，第一个用户购买3个，第二个用户购买2个，理想状态下第一个用户能购买成功，第二个用户提示购买失败，反之亦可。而实际可能出现的情况是，两个用户都得到库存为4，第一个用户买到了3个，更新库存之前，第二个用户下了2个商品的订单，更新库存为2，导致出错。 在上面的场景中，商品的库存是共享变量，面对高并发情形，需要保证对资源的访问互斥。在单机环境中，Java中其实提供了很多并发处理相关的API，但是这些API在分布式场景中就无能为力了。也就是说单纯的Java Api并不能提供分布式锁的能力。分布式系统中，由于分布式系统的分布性，即多线程和多进程并且分布在不同机器中，synchronized和lock这两种锁将失去原有锁的效果，需要我们自己实现分布式锁。 常见的锁方案如下： 基于数据库实现分布式锁 基于缓存，实现分布式锁，如redis 基于Zookeeper实现分布式锁 下面我们简单介绍下这几种锁的实现。 基于数据库基于数据库的锁实现也有两种方式，一是基于数据库表，另一种是基于数据库排他锁。 基于数据库表的增删基于数据库表增删是最简单的方式，首先创建一张锁的表主要包含下列字段：方法名，时间戳等字段。 具体使用的方法，当需要锁住某个方法时，往该表中插入一条相关的记录。这边需要注意，方法名是有唯一性约束的，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 执行完毕，需要delete该记录。 当然，笔者这边只是简单介绍一下。对于上述方案可以进行优化，如应用主从数据库，数据之间双向同步。一旦挂掉快速切换到备库上；做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍；使用while循环，直到insert成功再返回成功，虽然并不推荐这样做；还可以记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了，实现可重入锁。 基于数据库排他锁我们还可以通过数据库的排他锁来实现分布式锁。基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作： 12345678910111213141516171819public void lock()&#123; connection.setAutoCommit(false) int count = 0; while(count &lt; 4)&#123; try&#123; select * from lock where lock_name=xxx for update; if(结果不为空)&#123; //代表获取到锁 return; &#125; &#125;catch(Exception e)&#123; &#125; //为空或者抛异常的话都表示没有获取到锁 sleep(1000); count++; &#125; throw new LockException();&#125; 在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。其他没有获取到锁的就会阻塞在上述select语句上，可能的结果有2种，在超时之前获取到了锁，在超时之前仍未获取到锁。 获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，释放锁connection.commit()。 存在的问题主要是性能不高和sql超时的异常。 基于数据库锁的优缺点上面两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。 优点是直接借助数据库，简单容易理解。 缺点是操作数据库需要一定的开销，性能问题需要考虑。 基于Zookeeper基于zookeeper临时有序节点可以实现的分布式锁。每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。 提供的第三方库有curator，具体使用读者可以自行去看一下。Curator提供的InterProcessMutex是分布式锁的实现。acquire方法获取锁，release方法释放锁。另外，锁释放、阻塞锁、可重入锁等问题都可以有有效解决。讲下阻塞锁的实现，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是就获取到锁，便可以执行业务逻辑。 最后，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。并发问题，可能存在网络抖动，客户端和ZK集群的session连接断了，zk集群以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。 基于缓存相对于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点，存取速度快很多。而且很多缓存是可以集群部署的，可以解决单点问题。基于缓存的锁有好几种，如memcached、redis、本文下面主要讲解基于redis的分布式实现。 基于redis的分布式锁实现SETNX使用redis的SETNX实现分布式锁，多个进程执行以下Redis命令： 1SETNX lock.id &lt;current Unix time + lock timeout + 1&gt; SETNX是将 key 的值设为 value，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。 返回1，说明该进程获得锁，SETNX将键 lock.id 的值设置为锁的超时时间，当前时间 +加上锁的有效时间。 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SETNX 操作，以获得锁。 存在死锁的问题SETNX实现分布式锁，可能会存在死锁的情况。与单机模式下的锁相比，分布式环境下不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。某个线程获取了锁之后，断开了与Redis 的连接，锁没有及时释放，竞争该锁的其他线程都会hung，产生死锁的情况。 在使用 SETNX 获得锁时，我们将键 lock.id 的值设置为锁的有效时间，线程获得锁后，其他线程还会不断的检测锁是否已超时，如果超时，等待的线程也将有机会获得锁。然而，锁超时，我们不能简单地使用 DEL 命令删除键 lock.id 以释放锁。 考虑以下情况: A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁； B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时； B执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁； C由于各刚刚检测到锁已超时，执行 DEL lock.id命令，将B刚刚设置的键 lock.id 删除，执行 SETNX lock.id命令，并返回1，即C获得锁。 上面的步骤很明显出现了问题，导致B,C同时获取了锁。在检测到锁超时后，线程不能直接简单地执行 DEL 删除键的操作以获得锁。 对于上面的步骤进行改进，问题是出在删除键的操作上面，那么获取锁之后应该怎么改进呢？首先看一下redis的GETSET这个操作，GETSET key value，将给定 key 的值设为 value ，并返回 key 的旧值(old value)。利用这个操作指令，我们改进一下上述的步骤。 A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁； B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时； B检测到锁已超时，即当前的时间大于键 lock.id 的值，B会执行GETSET lock.id &lt;current Unix timestamp + lock timeout + 1&gt;设置时间戳，通过比较键 lock.id 的旧值是否小于当前时间，判断进程是否已获得锁； B发现GETSET返回的值小于当前时间，则执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁； C执行GETSET得到的时间大于当前时间，则继续等待。 在线程释放锁，即执行 DEL lock.id 操作前，需要先判断锁是否已超时。如果锁已超时，那么锁可能已由其他线程获得，这时直接执行 DEL lock.id 操作会导致把其他线程已获得的锁释放掉。 一种实现方式获取锁1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public boolean lock(long acquireTimeout, TimeUnit timeUnit) throws InterruptedException &#123; acquireTimeout = timeUnit.toMillis(acquireTimeout); long acquireTime = acquireTimeout + System.currentTimeMillis(); //使用J.U.C的ReentrantLock threadLock.tryLock(acquireTimeout, timeUnit); try &#123; //循环尝试 while (true) &#123; //调用tryLock boolean hasLock = tryLock(); if (hasLock) &#123; //获取锁成功 return true; &#125; else if (acquireTime &lt; System.currentTimeMillis()) &#123; break; &#125; Thread.sleep(sleepTime); &#125; &#125; finally &#123; if (threadLock.isHeldByCurrentThread()) &#123; threadLock.unlock(); &#125; &#125; return false;&#125;public boolean tryLock() &#123; long currentTime = System.currentTimeMillis(); String expires = String.valueOf(timeout + currentTime); //设置互斥量 if (redisHelper.setNx(mutex, expires) &gt; 0) &#123; //获取锁，设置超时时间 setLockStatus(expires); return true; &#125; else &#123; String currentLockTime = redisUtil.get(mutex); //检查锁是否超时 if (Objects.nonNull(currentLockTime) &amp;&amp; Long.parseLong(currentLockTime) &lt; currentTime) &#123; //获取旧的锁时间并设置互斥量 String oldLockTime = redisHelper.getSet(mutex, expires); //旧值与当前时间比较 if (Objects.nonNull(oldLockTime) &amp;&amp; Objects.equals(oldLockTime, currentLockTime)) &#123; //获取锁，设置超时时间 setLockStatus(expires); return true; &#125; &#125; return false; &#125;&#125; lock调用tryLock方法，参数为获取的超时时间与单位，线程在超时时间内，获取锁操作将自旋在那里，直到该自旋锁的保持者释放了锁。 tryLock方法中，主要逻辑如下： setnx(lockkey, 当前时间+过期超时时间) ，如果返回1，则获取锁成功；如果返回0则没有获取到锁 get(lockkey)获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取 计算newExpireTime=当前时间+过期超时时间，然后getset(lockkey, newExpireTime) 会返回当前lockkey的值currentExpireTime 判断currentExpireTime与oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试 释放锁12345678910111213141516public boolean unlock() &#123; //只有锁的持有线程才能解锁 if (lockHolder == Thread.currentThread()) &#123; //判断锁是否超时，没有超时才将互斥量删除 if (lockExpiresTime &gt; System.currentTimeMillis()) &#123; redisHelper.del(mutex); logger.info(\"删除互斥量[&#123;&#125;]\", mutex); &#125; lockHolder = null; logger.info(\"释放[&#123;&#125;]锁成功\", mutex); return true; &#125; else &#123; throw new IllegalMonitorStateException(\"没有获取到锁的线程无法执行解锁操作\"); &#125;&#125; 在上面获取锁的实现下，其实此处的释放锁函数可以不需要了，有兴趣的读者可以结合上面的代码看下为什么？有想法可以留言哦！ 总结本文主要讲解了基于redis分布式锁的实现，在分布式环境下，数据一致性问题一直是一个比较重要的话题，而synchronized和lock锁在分布式环境已经失去了作用。常见的锁的方案有基于数据库实现分布式锁、基于缓存实现分布式锁、基于Zookeeper实现分布式锁，简单介绍了每种锁的实现特点；然后，文中探索了一下redis锁的实现方案；最后，本文给出了基于Java实现的redis分布式锁，读者可以自行验证一下。 参考 分布式锁的一点理解 分布式锁1 Java常用技术方案 分布式锁的几种实现方式","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://blueskykong.com/categories/并发编程/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/tags/java/"},{"name":"redis","slug":"redis","permalink":"http://blueskykong.com/tags/redis/"}]},{"title":"云原生架构概述","slug":"cloudnative","date":"2017-12-24T16:00:00.000Z","updated":"2017-12-27T03:25:21.000Z","comments":true,"path":"2017/12/25/cloudnative/","link":"","permalink":"http://blueskykong.com/2017/12/25/cloudnative/","excerpt":"","text":"1. 什么是云原生1.1 CNCF组织在讲云原生之前，我们先了解一下CNCF，即云原生计算基金会，2015年由谷歌牵头成立，基金会成员目前已有一百多企业与机构，包括亚马逊、微软、思科等巨头。 目前CNCF所托管的应用已达14个，下图为其公布的Cloud Native Landscape，给出了云原生生态的参考体系。 1.2 云原生CNCF给出了云原生应用的三大特征： 容器化封装：以容器为基础，提高整体开发水平，形成代码和组件重用，简化云原生应用程序的维护。在容器中运行应用程序和进程，并作为应用程序部署的独立单元，实现高水平资源隔离。 动态管理：通过集中式的编排调度系统来动态的管理和调度。 面向微服务：明确服务间的依赖，互相解耦。 云原生包含了一组应用的模式，用于帮助企业快速，持续，可靠，规模化地交付业务软件。云原生由微服务架构，DevOps 和以容器为代表的敏捷基础架构组成。 这边引用网上关于云原生所需要的能力和特征总结，如下图。 1.3 The Twelve Factors12-Factors经常被直译为12要素，也被称为12原则，12原则由公有云PaaS的先驱Heroku于2012年提出（https://12factor.net/），目的是告诉开发者如何利用云平台提供的便利来开发更具可靠性和扩展性、更加易于维护的云原生应用。具体如下： 基准代码 显式声明依赖关系 在环境中存储配置 把后端服务当作附加资源 严格分离构建、发布和运行 无状态进程 通过端口绑定提供服务 通过进程模型进行扩展 快速启动和优雅终止 开发环境与线上环境等价 日志作为事件流 管理进程 另外还有补充的三点： API声明管理 认证和授权 监控与告警 距离12原则的提出已有五年多，12原则的有些细节可能已经不那么跟得上时代，也有人批评12原则的提出从一开始就有过于依赖Heroku自身特性的倾向。不过不管怎么说，12原则依旧是业界最为系统的云原生应用开发指南。 2. 容器化封装最近几年docker容器化技术很火，经常在各种场合能够听到关于docker的分享。Docker让开发工程师可以将他们的应用和依赖封装到一个可移植的容器中。Docker背后的想法是创建软件程序可移植的轻量容器，让其可以在任何安装了Docker的机器上运行，而不用关心底层操作系统。 Docker可以解决虚拟机能够解决的问题，同时也能够解决虚拟机由于资源要求过高而无法解决的问题。其优势包括： 隔离应用依赖 创建应用镜像并进行复制 创建容易分发的即启即用的应用 允许实例简单、快速地扩展 测试应用并随后销毁它们 自动化运维工具可以降低环境搭建的复杂度，但仍然不能从根本上解决环境的问题。在看似稳定而成熟的场景下，使用Docker的好处越来越多。 3. 服务编排笔者看到Jimmy Song对云原生架构中运用服务编排的总结是： Kubernetes——让容器应用进入大规模工业生产。 这个总结确实很贴切。编排调度的开源组件还有：Kubernetes、Mesos和Docker swarm。 Kubernetes是目前世界上关注度最高的开源项目，它是一个出色的容器编排系统。Kubernetes出身于互联网行业的巨头Google公司，它借鉴了由上百位工程师花费十多年时间打造Borg系统的理念，通过极其简易的安装，以及灵活的网络层对接方式，提供一站式的服务。 Mesos则更善于构建一个可靠的平台，用以运行多任务关键工作负载，包括Docker容器、遗留应用程序(例如Java)和分布式数据服务(例如Spark、Kafka、Cassandra、Elastic)。Mesos采用两级调度的架构，开发人员可以很方便的结合公司业务场景自定制MesosFramework。 他们为云原生应用提供的强有力的编排和调度能力，它们是云平台上的分布式操作系统。在单机上运行容器，无法发挥它的最大效能，只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势，而对于容器的编排管理，Swarm、Mesos和Kubernetes的大战已经基本宣告结束，kubernetes成为了无可争议的赢家。 4. 微服务架构传统的web开发方式，一般被称为单体架构（Monolithic）所有的功能打包在一个WAR包里，基本没有外部依赖（除了容器），部署在一个JEE容器（Tomcat，JBoss，WebLogic）里，包含了DO/DAO，Service，UI等所有逻辑。其架构如下图所示。 单体架构进行演化升级之后，过渡到SOA架构，即面向服务架构。近几年微服务架构（Micro-Service Archeticture）是最流行的架构风格，旨在通过将功能模块分解到各个独立的子系统中以实现解耦，它并没有一成不变的规定，而是需要根据业务来做设计。微服务架构是对SOA的传承，是SOA的具体实践方法。微服务架构中，每个微服务模块只是对简单、独立、明确的任务进行处理，通过REST API返回处理结果给外部。在微服务推广实践角度来看，微服务将整个系统进行拆分，拆分成更小的粒度，保持这些服务独立运行，应用容器化技术将微服务独立运行在容器中。过去设计架构时，是在内存中以参数或对象的方式实现粒度细化。微服务使用各个子服务控制模块的思想代替总线。不同的业务要求，服务控制模块至少包含服务的发布、注册、路由、代理功能。 容器化的出现，一定程度上带动了微服务架构。架构演化从单体式应用到分布式，再从分布式架构到云原生架构，微服务在其中有着不可或缺的角色。微服务带给我们很多开发和部署上的灵活性和技术多样性，但是也增加了服务调用的开销、分布式系事务、调试与服务治理方面的难题。 从上图Spring Cloud组件的架构可以看出在微服务架构中所必须的组件，包括：服务发现与注册、熔断机制、路由、全局锁、中心配置管理、控制总线、决策竞选、分布式会话和集群状态管理等基础组件。 Spring Cloud和Kubernetes有很大的不同，Spring Cloud和Kubernetes处理了不同范围的微服务架构技术点，而且是用了不同的方法。Spring Cloud方法是试图解决在JVM中的微服务架构要点，而Kubernetes方法是试图让问题消失，为开发者在平台层解决。Spring Cloud在JVM中非常强大，Kubernetes管理那些JVM很强大。看起来各取所长，充分利用这两者的优势是自然而然的趋势了。 5. 总结技术架构的演变非常快，各种新的名词也是层出不穷。本文主要是对云原生的概述。云原生应用的三大特征：容器化封装、动态管理、面向微服务。首先由CNCF组织介绍了云原生的概念，然后分别对这三个特征进行详述。云原生架构是当下很火的讨论话题，是不同思想的集合，集目前各种热门技术之大成。 最后，祝大家圣诞节快乐😆 ! 参考 云原生应用之路 架构演化：云原生时代正式开启 cncf/landscape","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"micro-service","slug":"micro-service","permalink":"http://blueskykong.com/tags/micro-service/"}]},{"title":"深入理解Spring AOP的动态代理","slug":"aop","date":"2017-12-13T16:00:00.000Z","updated":"2017-12-24T08:35:10.000Z","comments":true,"path":"2017/12/14/aop/","link":"","permalink":"http://blueskykong.com/2017/12/14/aop/","excerpt":"","text":"1. Spring AOPSpring是一个轻型容器，Spring整个系列的最最核心的概念当属IoC、AOP。可见AOP是Spring框架中的核心之一，在应用中具有非常重要的作用，也是Spring其他组件的基础。AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。 关于AOP的基础知识，并不是本文的重点，我们主要来看下AOP的核心功能的底层实现机制：动态代理的实现原理。AOP的拦截功能是由java中的动态代理来实现的。在目标类的基础上增加切面逻辑，生成增强的目标类（该切面逻辑或者在目标类函数执行之前，或者目标类函数执行之后，或者在目标类函数抛出异常时候执行。不同的切入时机对应不同的Interceptor的种类，如BeforeAdviseInterceptor，AfterAdviseInterceptor以及ThrowsAdviseInterceptor等）。 那么动态代理是如何实现将切面逻辑（advise）织入到目标类方法中去的呢？下面我们就来详细介绍并实现AOP中用到的两种动态代理。 AOP的源码中用到了两种动态代理来实现拦截切入功能：jdk动态代理和cglib动态代理。两种方法同时存在，各有优劣。jdk动态代理是由java内部的反射机制来实现的，cglib动态代理底层则是借助asm来实现的。总的来说，反射机制在生成类的过程中比较高效，而asm在生成类之后的相关执行过程中比较高效（可以通过将asm生成的类进行缓存，这样解决asm生成类过程低效问题）。 下面我们分别来示例实现这两种方法。 2. JDK动态代理2.1 定义接口与实现类1234567public interface OrderService &#123; public void save(UUID orderId, String name); public void update(UUID orderId, String name); public String getByName(String name);&#125; 上面代码定义了一个被拦截对象接口，即横切关注点。下面代码实现被拦截对象接口。 1234567891011121314151617181920212223242526272829public class OrderServiceImpl implements OrderService &#123; private String user = null; public OrderServiceImpl() &#123; &#125; public OrderServiceImpl(String user) &#123; this.setUser(user); &#125; //... @Override public void save(UUID orderId, String name) &#123; System.out.println(\"call save()方法,save:\" + name); &#125; @Override public void update(UUID orderId, String name) &#123; System.out.println(\"call update()方法\"); &#125; @Override public String getByName(String name) &#123; System.out.println(\"call getByName()方法\"); return \"aoho\"; &#125;&#125; 2.2 JDK动态代理类123456789101112131415161718192021222324252627public class JDKProxy implements InvocationHandler &#123; //需要代理的目标对象 private Object targetObject; public Object createProxyInstance(Object targetObject) &#123; this.targetObject = targetObject; return Proxy.newProxyInstance(this.targetObject.getClass().getClassLoader(), this.targetObject.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //被代理对象 OrderServiceImpl bean = (OrderServiceImpl) this.targetObject; Object result = null; //切面逻辑（advise），此处是在目标类代码执行之前 System.out.println(\"---before invoke----\"); if (bean.getUser() != null) &#123; result = method.invoke(targetObject, args); &#125; System.out.println(\"---after invoke----\"); return result; &#125; //...&#125; 上述代码实现了动态代理类JDKProxy，实现InvocationHandler接口，并且实现接口中的invoke方法。当客户端调用代理对象的业务方法时，代理对象执行invoke方法，invoke方法把调用委派给targetObject，相当于调用目标对象的方法，在invoke方法委派前判断权限，实现方法的拦截。 2.3 测试12345678910public class AOPTest &#123; public static void main(String[] args) &#123; JDKProxy factory = new JDKProxy(); //Proxy为InvocationHandler实现类动态创建一个符合某一接口的代理实例 OrderService orderService = (OrderService) factory.createProxyInstance(new OrderServiceImpl(\"aoho\")); //由动态生成的代理对象来orderService 代理执行程序 orderService.save(UUID.randomUUID(), \"aoho\"); &#125;&#125; 结果如下： 123---before invoke----call save()方法,save:aoho---after invoke---- 3. CGLIB字节码生成3.1 要代理的类CGLIB既可以对接口的类生成代理，也可以针对类生成代理。示例中，实现对类的代理。 12345678910111213141516171819202122232425public class OrderManager &#123; private String user = null; public OrderManager() &#123; &#125; public OrderManager(String user) &#123; this.setUser(user); &#125; //... public void save(UUID orderId, String name) &#123; System.out.println(\"call save()方法,save:\" + name); &#125; public void update(UUID orderId, String name) &#123; System.out.println(\"call update()方法\"); &#125; public String getByName(String name) &#123; System.out.println(\"call getByName()方法\"); return \"aoho\"; &#125;&#125; 该类的实现和上面的接口实现一样，为了保持统一。 3.2 CGLIB动态代理类123456789101112131415161718192021222324252627public class CGLibProxy implements MethodInterceptor &#123; // CGLib需要代理的目标对象 private Object targetObject; public Object createProxyObject(Object obj) &#123; this.targetObject = obj; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(obj.getClass()); //回调方法的参数为代理类对象CglibProxy，最后增强目标类调用的是代理类对象CglibProxy中的intercept方法 enhancer.setCallback(this); //增强后的目标类 Object proxyObj = enhancer.create(); // 返回代理对象 return proxyObj; &#125; @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object obj = null; //切面逻辑（advise），此处是在目标类代码执行之前 System.out.println(\"---before intercept----\"); obj = method.invoke(targetObject, args); System.out.println(\"---after intercept----\"); return obj; &#125;&#125; 上述实现了创建子类的方法与代理的方法。getProxy(SuperClass.class)方法通过入参即父类的字节码，扩展父类的class来创建代理对象。intercept()方法拦截所有目标类方法的调用，obj表示目标类的实例，method为目标类方法的反射对象，args为方法的动态入参，methodProxy为代理类实例。method.invoke(targetObject, args)通过代理类调用父类中的方法。 3.3 测试12345public class AOPTest &#123; public static void main(String[] args) &#123; OrderManager order = (OrderManager) new CGLibProxy().createProxyObject(new OrderManager(\"aoho\")); order.save(UUID.randomUUID(), \"aoho\"); &#125; 结果如下： 123---before intercept----call save()方法,save:aoho---after intercept---- 4. 总结本文主要讲了Spring Aop动态代理实现的两种方式，并分别介绍了其优缺点。jdk动态代理的应用前提是目标类基于统一的接口。如果没有该前提，jdk动态代理不能应用。由此可以看出，jdk动态代理有一定的局限性，cglib这种第三方类库实现的动态代理应用更加广泛，且在效率上更有优势。 JDK动态代理机制是委托机制，不需要以来第三方的库，只要要JDK环境就可以进行代理，动态实现接口类，在动态生成的实现类里面委托为hanlder去调用原始实现类方法；CGLib 必须依赖于CGLib的类库，使用的是继承机制，是被代理类和代理类继承的关系，所以代理类是可以赋值给被代理类的，如果被代理类有接口，那么代理类也可以赋值给接口。 参考 jdk动态代理代理与cglib代理原理探究 AOP的底层实现-CGLIB动态代理和JDK动态代理","categories":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/categories/java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blueskykong.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://blueskykong.com/tags/Spring/"}]},{"title":"微服务架构中整合网关、权限服务","slug":"integration","date":"2017-12-09T16:00:00.000Z","updated":"2017-12-12T04:56:04.000Z","comments":true,"path":"2017/12/10/integration/","link":"","permalink":"http://blueskykong.com/2017/12/10/integration/","excerpt":"","text":"前言：之前的文章有讲过微服务的权限系列和网关实现，都是孤立存在，本文将整合后端服务与网关、权限系统。安全权限部分的实现还讲解了基于前置验证的方式实现，但是由于与业务联系比较紧密，没有具体的示例。业务权限与业务联系非常密切，本次的整合项目将会把这部分的操作权限校验实现基于具体的业务服务。 1. 前文回顾与整合设计在认证鉴权与API权限控制在微服务架构中的设计与实现系列文章中，讲解了在微服务架构中Auth系统的授权认证和鉴权。在微服务网关中，讲解了基于netflix-zuul组件实现的微服务网关。下面我们看一下这次整合的架构图。 整个流程分为两类： 用户尚未登录。客户端（web和移动端）发起登录请求，网关对于登录请求直接转发到auth服务，auth服务对用户身份信息进行校验（整合项目省略用户系统，读者可自行实现，直接硬编码返回用户信息），最终将身份合法的token返回给客户端。 用户已登录，请求其他服务。这种情况，客户端的请求到达网关，网关会调用auth系统进行请求身份合法性的验证，验证不通则直接拒绝，并返回401；如果通过验证，则转发到具体服务，服务经过过滤器，根据请求头部中的userId，获取该user的安全权限信息。利用切面，对该接口需要的权限进行校验，通过则proceed，否则返回403。 第一类其实比较简单，在讲解认证鉴权与API权限控制在微服务架构中的设计与实现就基本实现，现在要做的是与网关进行结合；第二类中，我们新建了一个后端服务，与网关、auth系统整合。 下面对整合项目涉及到的三个服务分别介绍。网关和auth服务的实现已经讲过，本文主要讲下这两个服务进行整合需要的改动，还有就是对于后端服务的主要实现进行讲解。 2. gateway实现微服务网关已经基本介绍完了网关的实现，包括服务路由、几种过滤方式等。这一节将重点介绍实际应用时的整合。对于需要修改增强的地方如下： 区分暴露接口（即对外直接访问）和需要合法身份登录之后才能访问的接口 暴露接口直接放行，转发到具体服务，如登录、刷新token等 需要合法身份登录之后才能访问的接口，根据传入的Access token进行构造头部，头部主要包括userId等信息，可根据自己的实际业务在auth服务中进行设置。 最后，比较重要的一点，引入Spring Security的资源服务器配置，对于暴露接口设置permitAll()，其余接口进入身份合法性校验的流程，调用auth服务，如果通过则正常继续转发，否则抛出异常，返回401。 绘制的流程图如下： 2.1 permitAll实现对外暴露的接口可以直接访问，这可以依赖配置文件，而配置文件又可以通过配置中心进行动态更新，所以不用担心有hard-code的问题。在配置文件中定义需要permitall的路径。 123456auth: permitall: - pattern: /login/** - pattern: /web/public/** 服务启动时，读入相应的Configuration，下面的配置属性读取以auth开头的配置。 12345@Bean@ConfigurationProperties(prefix = \"auth\")public PermitAllUrlProperties getPermitAllUrlProperties() &#123; return new PermitAllUrlProperties();&#125; 当然还需要有PermitAllUrlProperties对应的实体类，比较简单，不列出来了。 2.2 加强头部Filter过滤器，它是Servlet技术中最实用的技术，Web开发人员通过Filter技术，对web服务器管理的所有web资源进行拦截。这边使用Filter进行头部增强，解析请求中的token，构造统一的头部信息，到了具体服务，可以利用头部中的userId进行操作权限获取与判断。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class HeaderEnhanceFilter implements Filter &#123; //... @Autowired private PermitAllUrlProperties permitAllUrlProperties; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; //主要的过滤方法 @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; String authorization = ((HttpServletRequest) servletRequest).getHeader(\"Authorization\"); String requestURI = ((HttpServletRequest) servletRequest).getRequestURI(); // test if request url is permit all , then remove authorization from header LOGGER.info(String.format(\"Enhance request URI : %s.\", requestURI)); //将isPermitAllUrl的请求进行传递 if(isPermitAllUrl(requestURI) &amp;&amp; isNotOAuthEndpoint(requestURI)) &#123; //移除头部，但不包括登录端点的头部 HttpServletRequest resetRequest = removeValueFromRequestHeader((HttpServletRequest) servletRequest); filterChain.doFilter(resetRequest, servletResponse); return; &#125; //判断是不是符合规范的头部 if (StringUtils.isNotEmpty(authorization)) &#123; if (isJwtBearerToken(authorization)) &#123; try &#123; authorization = StringUtils.substringBetween(authorization, \".\"); String decoded = new String(Base64.decodeBase64(authorization)); Map properties = new ObjectMapper().readValue(decoded, Map.class); //解析authorization中的token，构造USER_ID_IN_HEADER String userId = (String) properties.get(SecurityConstants.USER_ID_IN_HEADER); RequestContext.getCurrentContext().addZuulRequestHeader(SecurityConstants.USER_ID_IN_HEADER, userId); &#125; catch (Exception e) &#123; LOGGER.error(\"Failed to customize header for the request\", e); &#125; &#125; &#125; else &#123; //为了适配，设置匿名头部 RequestContext.getCurrentContext().addZuulRequestHeader(SecurityConstants.USER_ID_IN_HEADER, ANONYMOUS_USER_ID); &#125; filterChain.doFilter(servletRequest, servletResponse); &#125; @Override public void destroy() &#123; &#125; //... &#125; 上面代码列出了头部增强的基本处理流程，将isPermitAllUrl的请求进行直接传递，否则判断是不是符合规范的头部，然后解析authorization中的token，构造USER_ID_IN_HEADER。最后为了适配，设置匿名头部。需要注意的是，HeaderEnhanceFilter也要进行注册。Spring 提供了FilterRegistrationBean类，此类提供setOrder方法，可以为filter设置排序值，让spring在注册web filter之前排序后再依次注册。 2.3 资源服务器配置利用资源服务器的配置，控制哪些是暴露端点不需要进行身份合法性的校验，直接路由转发，哪些是需要进行身份loadAuthentication，调用auth服务。 123456789101112131415161718192021222324@Configuration@EnableResourceServerpublic class ResourceServerConfig extends ResourceServerConfigurerAdapter &#123; //... //配置permitAll的请求pattern，依赖于permitAllUrlProperties对象 @Override public void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable() .requestMatchers().antMatchers(\"/**\") .and() .authorizeRequests() .antMatchers(permitAllUrlProperties.getPermitallPatterns()).permitAll() .anyRequest().authenticated(); &#125; //通过自定义的CustomRemoteTokenServices，植入身份合法性的相关验证 @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &#123; CustomRemoteTokenServices resourceServerTokenServices = new CustomRemoteTokenServices(); //... resources.tokenServices(resourceServerTokenServices); &#125;&#125; 资源服务器的配置大家看了笔者之前的文章应该很熟悉，此处不过多重复讲了。关于ResourceServerSecurityConfigurer配置类，之前的安全系列文章已经讲过，ResourceServerTokenServices接口，当时我们也用到了，只不过用的是默认的DefaultTokenServices。这边通过自定义的CustomRemoteTokenServices，植入身份合法性的相关验证。 当然这个配置还要引入Spring Cloud Security oauth2的相应依赖。 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; 2.4 自定义RemoteTokenServices实现ResourceServerTokenServices接口其中的一个实现是RemoteTokenServices。 Queries the /check_token endpoint to obtain the contents of an access token.If the endpoint returns a 400 response, this indicates that the token is invalid. RemoteTokenServices主要是查询auth服务的/check_token端点以获取一个token的校验结果。如果有错误，则说明token是不合法的。笔者这边的的CustomRemoteTokenServices实现就是沿用该思路。需要注意的是，笔者的项目基于Spring cloud，auth服务是多实例的，所以这边使用了Netflix Ribbon获取auth服务进行负载均衡。Spring Cloud Security添加如下默认配置，对应auth服务中的相应端点。 123456789security: oauth2: client: accessTokenUri: /oauth/token clientId: gateway clientSecret: gateway resource: userInfoUri: /user token-info-uri: /oauth/check_token 至于具体的CustomRemoteTokenServices实现，可以参考上面讲的思路以及RemoteTokenServices，很简单，此处略去。 至此，网关服务的增强完成，下面看一下我们对auth服务和后端backend服务的实现。强调一下，为什么头部传递的userId等信息需要在网关构造？读者可以自己思考一下，结合安全等方面，😆笔者暂时不给出答案。 3. auth整合auth服务的整合修改，其实没那么多，之前对于user、role以及permission之间的定义和关系没有给出实现，这部分的sql语句已经在auth.sql中。所以为了能给出一个完整的实例，笔者把这部分实现给补充了，主要就是user-role，role、role-permission的相应接口定义与实现，实现增删改查。 读者要是想参考整合项目进行实际应用，这部分完全可以根据自己的业务进行增强，包括token的创建，其自定义的信息还可以在网关中进行统一处理，构造好之后传递给后端服务。 这边的接口只是列出了需要的几个，其他接口没写（因为懒。。） 这两个接口也是给backend项目用来获取相应的userId权限。 123456789//根据userId获取用户对应的权限 @RequestMapping(method = RequestMethod.GET, value = \"/api/userPermissions?userId=&#123;userId&#125;\", consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE) List&lt;Permission&gt; getUserPermissions(@RequestParam(\"userId\") String userId);//根据userId获取用户对应的accessLevel（好像暂时没用到。。） @RequestMapping(method = RequestMethod.GET, value = \"/api/userAccesses?userId=&#123;userId&#125;\", consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE) List&lt;UserAccess&gt; getUserAccessList(@RequestParam(\"userId\") String userId); 好了，这边的实现已经讲完了，具体见项目中的实现。 4. backend项目实现本节是进行实现一个backend的实例，后端项目主要实现哪些功能呢？我们考虑一下，之前网关服务和auth服务所做的准备： 网关构造的头部userId（可能还有其他信息，这边只是示例），可以在backend获得 转发到backend服务的请求，都是经过身份合法性校验，或者是直接对外暴露的接口 auth服务，提供根据userId进行获取相应的权限的接口 根据这些，笔者绘制了一个backend的通用流程图： 上面的流程图其实已经非常清晰了，首先经过filter过滤器，填充SecurityContextHolder的上下文。其次，通过切面来实现注解，是否需要进入切面表达式处理。不需要的话，直接执行接口内的方法；否则解析注解中需要的权限，判断是否有权限执行，有的话继续执行，否则返回403 forbidden。 4.1 filter过滤器Filter过滤器，和上面网关使用一样，拦截客户的HttpServletRequest。 12345678910111213141516171819202122232425262728293031323334public class AuthorizationFilter implements Filter &#123; @Autowired private FeignAuthClient feignAuthClient; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; logger.info(\"过滤器正在执行...\"); // pass the request along the filter chain String userId = ((HttpServletRequest) servletRequest).getHeader(SecurityConstants.USER_ID_IN_HEADER); if (StringUtils.isNotEmpty(userId)) &#123; UserContext userContext = new UserContext(UUID.fromString(userId)); userContext.setAccessType(AccessType.ACCESS_TYPE_NORMAL); List&lt;Permission&gt; permissionList = feignAuthClient.getUserPermissions(userId); List&lt;SimpleGrantedAuthority&gt; authorityList = new ArrayList&lt;&gt;(); for (Permission permission : permissionList) &#123; SimpleGrantedAuthority authority = new SimpleGrantedAuthority(); authority.setAuthority(permission.getPermission()); authorityList.add(authority); &#125; CustomAuthentication userAuth = new CustomAuthentication(); userAuth.setAuthorities(authorityList); userContext.setAuthorities(authorityList); userContext.setAuthentication(userAuth); SecurityContextHolder.setContext(userContext); &#125; filterChain.doFilter(servletRequest, servletResponse); &#125; //...&#125; 上述代码主要实现了，根据请求头中的userId，利用feign client获取auth服务中的该user所具有的权限集合。之后构造了一个UserContext，UserContext是自定义的，实现了Spring Security的UserDetails, SecurityContext接口。 4.2 通过切面来实现@PreAuth注解基于Spring的项目，使用Spring的AOP切面实现注解是比较方便的一件事，这边我们使用了自定义的注解@PreAuth 1234567@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface PreAuth &#123; String value();&#125; Target用于描述注解的使用范围，超出范围时编译失败,可以用在方法或者类上面。在运行时生效。不了解注解相关知识的，可以自行Google。 123456789101112131415161718192021222324252627282930313233@Component@Aspectpublic class AuthAspect &#123; @Pointcut(\"@annotation(com.blueskykong.auth.demo.annotation.PreAuth)\") private void cut() &#123; &#125; /** * 定制一个环绕通知，当想获得注解里面的属性，可以直接注入该注解 * * @param joinPoint * @param preAuth */ @Around(\"cut()&amp;&amp;@annotation(preAuth)\") public Object record(ProceedingJoinPoint joinPoint, PreAuth preAuth) throws Throwable &#123; //取出注解中的表达式 String value = preAuth.value(); //Spring EL 对value进行解析 SecurityExpressionOperations operations = new CustomerSecurityExpressionRoot(SecurityContextHolder.getContext().getAuthentication()); StandardEvaluationContext operationContext = new StandardEvaluationContext(operations); ExpressionParser parser = new SpelExpressionParser(); Expression expression = parser.parseExpression(value); //获取表达式判断的结果 boolean result = expression.getValue(operationContext, boolean.class); if (result) &#123; //继续执行接口内的方法 return joinPoint.proceed(); &#125; return \"Forbidden\"; &#125;&#125; 因为Aspect作用在bean上，所以先用Component把这个类添加到容器中。@Pointcut定义要拦截的注解。@Around定制一个环绕通知，当想获得注解里面的属性，可以直接注入该注解。切面表达式内主要实现了，利用Spring EL对value进行解析，将SecurityContextHolder.getContext()转换成标准的操作上下文，然后解析注解中的表达式，最后获取对表达式判断的结果。 123456public class CustomerSecurityExpressionRoot extends SecurityExpressionRoot &#123; public CustomerSecurityExpressionRoot(Authentication authentication) &#123; super(authentication); &#125;&#125; CustomerSecurityExpressionRoot继承的是抽象类SecurityExpressionRoot，而我们用到的实际表达式是定义在SecurityExpressionOperations接口，SecurityExpressionRoot又实现了SecurityExpressionOperations接口。不过这里面的具体判断实现，Spring Security 调用的也是Spring EL。 4.3 controller接口下面我们看看最终接口是怎么用上面实现的注解。 12345@RequestMapping(value = \"/test\", method = RequestMethod.GET)@PreAuth(\"hasAuthority('CREATE_COMPANY')\") // 还可以定义很多表达式，如hasRole('Admin')public String test() &#123; return \"ok\";&#125; @PreAuth中，可以定义的表达式很多，可以看SecurityExpressionOperations接口中的方法。目前笔者只是实现了hasAuthority()表达式，如果你想支持其他所有表达式，只需要构造相应的SecurityContextHolder即可。 4.4 为什么这样设计？有些读者看了上面的设计，既然好多用到了Spring Security的工具类，肯定会问，为什么要引入这么复杂的工具类？ 其实很简单，首先因为SecurityExpressionOperations接口中定义的表达式足够多，且较为合理，能够覆盖我们在平时用到的大部分场景；其次，笔者之前的设计是直接在注解中指定所需权限，没有扩展性，且可读性差；最后，Spring Security 4 确实引入了@PreAuthorize,@PostAuthorize等注解，本来想用来着，自己尝试了一下，发现对于微服务架构这样的接口级别的操作权限校验不是很适合，十多个过滤器太过复杂，而且还涉及到的Principal、Credentials等信息，这些已经在auth系统实现了身份合法性校验。笔者认为这边的功能实现并不是很复杂，需要很轻量的实现，读者有兴趣可以试着这部分的实现封装成jar包或者Spring Boot的starter。 4.5 后期优化优化的地方主要有两点： 现在的设计是，每次请求过来都会去调用auth服务获取该user相应的权限信息。而后端微服务数量有很多，没必要每个服务，或者说一个服务的多个服务实例，每次都去调用auth服务，笔者认为完全可以引入redis集群的缓存机制，在请求到达一个服务的某个实例时，首先去查询对应的user的缓存中的权限，如果没有再调用auth服务，最后写入redis缓存。当然，如果权限更新了，在auth服务肯定要delete相应的user权限缓存。 关于被拒绝的请求，在切面表达式中，直接返回了对象，笔者认为可以和response status 403进行绑定，定制返回对象的内容，返回的response更加友好。 5. 总结如上，首先讲了整合的设计思路，主要包含三个服务：gateway、auth和backend demo。整合的项目，总体比较复杂，其中gateway服务扩充了好多内容，对于暴露的接口进行路由转发，这边引入了Spring Security 的starter，配置资源服务器对暴露的路径进行放行；对于其他接口需要调用auth服务进行身份合法性校验，保证到达backend的请求都是合法的或者公开的接口；auth服务在之前的基础上，补充了role、permission、user相应的接口，供外部调用；backend demo是新起的服务，实现了接口级别的操作权限的校验，主要用到了自定义注解和Spring AOP切面。 由于实现的细节实在有点多，本文限于篇幅，只对部分重要的实现进行列出与讲解。如果读者有兴趣实际的应用，可以根据实际的业务进行扩增一些信息，如auth授权的token、网关拦截请求构造的头部信息、注解支持的表达式等等。 可以优化的地方当然还有很多，整合项目中设计不合理的地方，各位同学可以多多提意见。 推荐阅读 微服务网关netflix-zuul 认证鉴权与API权限控制在微服务架构中的设计与实现（一） 认证鉴权与API权限控制在微服务架构中的设计与实现（二） 认证鉴权与API权限控制在微服务架构中的设计与实现（三） 认证鉴权与API权限控制在微服务架构中的设计与实现（四） 源码网关、auth权限服务和backend服务的整合项目地址为：GitHub：https://github.com/keets2012/microservice-integration或者 码云：https://gitee.com/keets/microservice-integration","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"zuul","slug":"zuul","permalink":"http://blueskykong.com/tags/zuul/"},{"name":"gateway","slug":"gateway","permalink":"http://blueskykong.com/tags/gateway/"},{"name":"OAuth2","slug":"OAuth2","permalink":"http://blueskykong.com/tags/OAuth2/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"http://blueskykong.com/tags/Spring-Security/"}]},{"title":"几种分布式调用链监控组件的实践与比较（二）比较","slug":"apm2","date":"2017-12-04T16:00:00.000Z","updated":"2017-12-06T01:27:55.000Z","comments":true,"path":"2017/12/05/apm2/","link":"","permalink":"http://blueskykong.com/2017/12/05/apm2/","excerpt":"","text":"引言：最近在调研与选型分布式调用链监控组件。选了主要的三种APM组件进行了实践与比较。本来打算一篇文章写完的，篇幅太长，打算分两篇。距离第一篇已经有近一个月时间了，主要最近工作比较忙，更新很慢。本文将会讲下几种APM选型的比较与性能测试。 1. 前文回顾上一篇文章主要讲了三种分布式调用链监控组件的实践。问题的背景由微服务架构展开，微服务的好处已经不用多说，而微服务的多了之后，千头万绪，下面这张图经常被用到。 系统的复杂度因此提升。系统越复杂，越难解决问题，例如系统失败或者性能问题。在三层架构中找到解决方案还不是太难，仅仅需要分析3个组件比如web服务器，应用服务器和数据库，而服务器数量也不多。但是，如果问题发生在n层架构中，就需要调查大量的组件和服务器。另一个问题是仅仅分析单个组件很难看到大局;当发生一个低可见度的问题时，系统复杂度越高，就需要更长的时间来查找原因。最糟糕的是，某些情况下我们甚至可能无法查找出来。 上面其实已经提到存在的故障定位问题，基于微服务体系之下构建的业务系统存在的问题基本上分为三类： 故障定位难，一个简单操作，其背后可能是由十几个微服务共同完成的，这些微服务也由不同的团队去负责。一旦出现问题，最坏情况下我们也许需要这十几个团队一起来解决问题。 链路梳理难，应用没有形成应用拓扑，不知道自己的服务下游会影响其他哪些人。 资源浪费多，容量预估难。对于一些服务，其消耗的cpm和memory可能连10%不到，远远没有充分利用物理机。这其实和容量预估关联，过大或者过小估算峰值的机器容量，都是浪费。 APM主要的目的就是解决上面所说的这四个问题，主要的手段是通过收集、存储、分析、分布式系统中的调用事件数据，协助开发运营人员进行故障诊断、容量预估、性能瓶颈定位以及调用链路梳理。第一篇其实已经讲过链路监控组件的需求： 代码的侵入性 探针的性能消耗 全面的调用链路数据分析 可扩展性 这边列一下pinpoint在其wiki中提到的几点： 分布式事务跟踪，跟踪跨分布式应用的消息 自动检测应用拓扑，帮助你搞清楚应用的架构 水平扩展以便支持大规模服务器集群 提供代码级别的可见性以便轻松定位失败点和瓶颈 使用字节码增强技术，添加新功能而无需修改代码 下面我们沿着这些需求，看一下这几种分布式调用链监控组件。 2. AMP比较上面列了需求，但是不够通用，笔者将需要对比的项提炼出来： 探针的性能 主要是agent对服务的吞吐量、CPU和内存的影响。微服务的规模和动态性使得数据收集的成本大幅度提高。 collector的可扩展性 能够水平扩展以便支持大规模服务器集群。 全面的调用链路数据分析 提供代码级别的可见性以便轻松定位失败点和瓶颈。 对于开发透明，容易开关 添加新功能而无需修改代码，容易启用或者禁用。 完整的调用链应用拓扑 自动检测应用拓扑，帮助你搞清楚应用的架构 笔者根据主要的需求，提炼出如上五点。 2.1 探针的性能笔者其实也是比较关注探针的性能，毕竟APM定位还是工具，如果启用了链路监控组建后，直接导致吞吐量降低过半，那也是不能接受的。笔者对skywalking、zipkin、pinpoint进行了压测，并与基线（未使用探针）的情况进行了对比。 选用了一个常见的基于Spring的应用程序，他包含Spring Boot, Spring MVC，redis客户端，mysql。 监控这个应用程序，每个trace，探针会抓取5个span(1 Tomcat, 1 SpringMVC, 2 Jedis, 1 Mysql)。这边基本和skywalkingtest的测试应用差不多。 模拟了三种并发用户：500，750，1000。使用jmeter测试，每个线程发送30个请求，设置思考时间为10ms。使用的采样率为1，即100%，这边与产线可能有差别。pinpoint默认的采样率为20，即50%，通过设置agent的配置文件改为100%。zipkin默认也是1。组合起来，一共有12种。下面看下汇总表。 从上表可以看出，在三种链路监控组件中，skywalking的探针对吞吐量的影响最小，zipkin的吞吐量居中。pinpoint的探针对吞吐量的影响较为明显，在500并发用户时，测试服务的吞吐量从1385降低到774，影响很大。然后再看下CPU和memory的影响，笔者是在内部服务器进行的压测，对CPU和memory的影响都差不多在10%之内。 2.2 collector的可扩展性collector的可扩展性，使得能够水平扩展以便支持大规模服务器集群。 zipkin在前一篇文章中，我们开发了zipkin-Server（其实就是提供的开箱即用包），zipkin-agent与zipkin-Server通过http或者mq进行通信，http通信会对正常的访问造成影响，所以还是推荐基于mq异步方式通信，zipkin-Server通过订阅具体的topic进行消费。这个当然是可以扩展的，多个zipkin-Server实例进行异步消费mq中的监控信息。 skywalkingskywalking的collector支持两种部署方式：单机和集群模式。collector与agent之间的通信使用了gRPC。 pinpoint同样，pinpoint也是支持集群和单机部署的。pinpoint agent通过thrift通信框架，发送链路信息到collector。 2.3 全面的调用链路数据分析全面的调用链路数据分析，提供代码级别的可见性以便轻松定位失败点和瓶颈。 zipkin zipkin的链路监控粒度相对没有那么细，从上图可以看到调用链中具体到接口级别，再进一步的调用信息并未涉及。 skywalking skywalking 还支持20+的中间件、框架、类库，比如主流的dubbo、Okhttp，还有DB和消息中间件。上图skywalking链路调用分析截取的比较简单，网关调用user服务，由于支持众多的中间件，所以skywalking链路调用分析比zipkin完备些。 pinpoint pinpoint应该是这三种APM组件中，数据分析最为完备的组件。提供代码级别的可见性以便轻松定位失败点和瓶颈，上图可以看到对于执行的sql语句，都进行了记录。还可以配置报警规则等，设置每个应用对应的负责人，根据配置的规则报警，支持的中间件和框架也比较完备。 2.4 对于开发透明，容易开关对于开发透明，容易开关，添加新功能而无需修改代码，容易启用或者禁用。我们期望功能可以不修改代码就工作并希望得到代码级别的可见性。 对于这一点，Zipkin 使用修改过的类库和它自己的容器(Finagle)来提供分布式事务跟踪的功能。但是，它要求在需要时修改代码。skywalking和pinpoint都是基于字节码增强的方式，开发人员不需要修改代码，并且可以收集到更多精确的数据因为有字节码中的更多信息。 2.5 完整的调用链应用拓扑自动检测应用拓扑，帮助你搞清楚应用的架构。 上面三幅图，分别展示了APM组件各自的调用拓扑，都能实现完整的调用链应用拓扑。相对来说，pinpoint界面显示的更加丰富，具体到调用的DB名，zipkin的拓扑局限于服务于服务之间。 3. 总结本文讲了三种分布式调用链监控组件的比较，主要从五方面着手，笔者对每一项都进了对比。至于具体选用哪款组件，大家可以根据实际的业务需求和场景进行选型，上面比较的数据仅供参考。这三款都是开源项目，一般公司都对针对实际情况进行一些二次开发，比如增加一些组件的支持、对接现存的大数据平台等等。 最后，看了eagleEye的相关介绍，想提下监控系统如何从被动报警转化为主动发现，其实和AIOps很密切。链路监控数据量很大，尽管可以通过压缩比来降低传输的数据量，但是我们真的需要存储每一条链路吗？是不是只需要识别每一个链路当中出现异常的情况。时序指标当中的异常点，那个时间点我们要识别出来。识别完了之后，对异常进行关联，定位出最后的问题。当然这个涉及到业务和应用系统层面，很复杂，但笔者认为是后面AIOps的大趋势。 推荐阅读几种分布式调用链监控组件的实践与比较（一）实践 参考 Technical Overview Of Pinpoint 阿里微服务之殇及分布式链路追踪技术原理","categories":[{"name":"Ops","slug":"Ops","permalink":"http://blueskykong.com/categories/Ops/"}],"tags":[{"name":"APM","slug":"APM","permalink":"http://blueskykong.com/tags/APM/"},{"name":"zipkin","slug":"zipkin","permalink":"http://blueskykong.com/tags/zipkin/"},{"name":"micro-service","slug":"micro-service","permalink":"http://blueskykong.com/tags/micro-service/"}]},{"title":"微服务之分布式配置中心Cloud Config","slug":"config-server1","date":"2017-11-19T16:00:00.000Z","updated":"2018-01-04T12:13:04.000Z","comments":true,"path":"2017/11/20/config-server1/","link":"","permalink":"http://blueskykong.com/2017/11/20/config-server1/","excerpt":"","text":"1. 分布式配置中心分布式系统中，服务数量剧增，其配置文件需要实现统一管理并且能够实时更新，分布式配置中心组件必然是需要的。Spring Cloud提供了配置中心组件Spring Cloud Config ，它支持配置服务放在远程Git仓库和本地文件中。默认采用git来存储配置信息，笔者示例也是采用默认的git repository，这样通过git客户端工具来方便的管理和访问配置内容。 在Spring Cloud Config 组件中，有两个角色，一是Config Server配置服务器，为其他服务提供配置文件信息；另一个是Config Client即其他服务，启动时从Config Server拉取配置。下面分别介绍下Config Server和Config Client的搭建实现方法。 2. 配置服务器Config Server2.1 pom中的jars只需要添加如下两个jar包的引用。 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jsr311-api&lt;/artifactId&gt; &lt;groupId&gt;javax.ws.rs&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 因为Spring Cloud Config服务器为客户端提供配置是要通过服务发现，所以这边引入consul的starter，配置服务器和客户端都注册到consul集群中。 2.2 入口类简单，因为Spring Cloud 提供了很多开箱即用的功能，通过spring-cloud-config-server的注解激活配置服务器。 12345678@SpringBootApplication@EnableDiscoveryClient@EnableConfigServerpublic class ConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigServerApplication.class, args); &#125;&#125; @EnableConfigServer注解很重要，将该服务标注为配置服务器；@EnableDiscoveryClient注册服务，供其他服务发现调用。 2.3 bootstrap.yml1234567891011121314151617181920212223242526server: port: 8888spring: application: name: config-server cloud: consul: discovery: preferIpAddress: true enabled: true register: true service-name: config-service //... host: localhost port: 8500---spring: cloud: config: server: git: uri: https://gitee.com/keets/Config-Repo.git searchPaths: $&#123;APP_LOCATE:dev&#125; username: user password: pwd 配置第一段指定了服务的端口；第二段是服务发现相关的配置；第三段是配置服务器的信息，这里将配置文件存储在码云上，默认的搜索文件路径为dev文件夹，可以通过环境变量指定，再下面是用户名和密码，公开的项目不需要设置用户名和密码。 至此配置服务器已经搭建完成，是不是很简单？ 3. 配置的git仓库配置服务器配置的仓库是https://gitee.com/keets/Config-Repo.git。笔者在这个仓库中建了两个文件夹：dev和prod。并且在dev文件夹中新建了文件configclient-dev.yml。为什么这样命名，能随便命名吗？答案是不可以，下面我们看下config文件的命名规则。 URL与配置文件的映射关系如下： /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.properties上面的url会映射{application}-{profile}.yml对应的配置文件，{label}对应git上不同的分支，默认为master比如Config Client，{application}对应spring.application：configclient，exp对应{profile}，{label}不指定则默认为master。 新建的configclient-dev.yml如下： 12345spring: profiles: devcloud: version: Dalston.SR4 4. 配置客户端Config Client4.1 pom中的jars只需要添加如下两个jar包的引用。 12345678910111213141516171819202122 &lt;dependencies&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jsr311-api&lt;/artifactId&gt; &lt;groupId&gt;javax.ws.rs&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 新增spring-boot-starter-actuator监控模块，为了配置信息是动态刷新，其中包含了/refresh刷新API。其他和配置服务器中添加的相同，没啥可说。 4.2 入口类简单，因为Spring Cloud 提供了很多开箱即用的功能，通过spring-cloud-config-server的注解激活配置服务器。 1234567@SpringBootApplication@EnableDiscoveryClientpublic class ConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigServerApplication.class, args); &#125;&#125; 配置客户端不需要@EnableConfigServer注解。 4.3 bootstrap.yml123456789101112131415161718192021222324252627282930313233343536373839404142server: port: 9901cloud: version: Brixton SR7spring: cloud: consul: discovery: preferIpAddress: true enabled: true register: true service-name: config-client //... host: localhost port: 8500---spring: profiles: active: dev application: #app名称 name: configclient cloud: config: #指定profile profile: dev label: master discovery: enabled: true #server名 service-id: config-service enabled: true fail-fast: true---spring: profiles: default application: name: configclient 从上面配置可以看出我们所激活的profile是dev，配置的配置服务名为config-service，指定从master分支拉取配置。所以configclient启动时会去配置服务器中拉取对应的configclient-dev的配置文件信息。 4.4 TestResource笔者新建了一个TestResource，对应的API端点为/api/test。 1234567@Value(\"$&#123;cloud.version&#125;\")private String version;@GetMapping(\"/test\")public String from() &#123; return version;&#125; cloud.version可以在上面的配置文件看到默认指定的是Brixton SR7，而笔者在配置中心设置的值为Dalston.SR4。 5. 测试结果5.1 获取配置首先看一下配置客户端启动时的日志信息，是不是真的按照我们配置的，从配置服务器拉取configclient-dev信息。 从日志看来，是符合的上面的配置猜想的。我们再从配置客户端提供的API接口进一步验证。 可以看到确实是Dalston.SR4，配置服务能够正常运行。 5.2 动态刷新配置Spring Cloud Config还可以实现动态更新配置的功能。下面我们修改下Config Repo中的cloud.version配置为Camden SR7，并通过刷新config client的/refresh端点来应用配置。从下图可以看到结果是预期所想。 这边配置的刷新是通过手工完成了，还可以利用githook进行触发。当本地提交代码到git后，调用了下图设置的url。有两个端点可以使用： refresh：以post方式执行/refresh 会刷新env中的配置 restart：如果配置信息已经注入到bean中，由于bean是单例的，不会去加载修改后的配置需要通过post方式去执行/restart, 还需要配置endpoints.restart.enabled: true。 第二种情况比较耗时，@RefreshScope是spring cloud提供的注解，在执行refresh时会刷新bean中变量值。 Convenience annotation to put a @Bean definition in RefreshScope. Beans annotated this way can be refreshed at runtime and any components that are using them will get a new instance on the next method call, fully initialized and injected with all dependencies. 上面说了RefreshScope是一个方便的bean注解，加上这个注解可以在运行态刷新bean。其他使用该bean的components下次调用时会获取一个已经被初始化好和注入的新实例对象。 githook设置页面如下。 6. 总结本文主要讲了配置服务器和配置客户端的搭建过程，最后通过配置客户端的日志和端点信息验证是否能成功使用配置服务中心。总体来说，非常简单。文中的部分配置没有写完整，读者需要可以看文末的git项目。 不过关于配置中心，本文的讲解并不完整，下一篇文章将会讲解配置服务器与消息总线的结合使用，实现对配置客户端的自动更新及灰度发布等功能。 本文源码github: https://github.com/keets2012/Spring-Boot-Samples/gitee: https://gitee.com/keets/spring-boot-samples/ 参考 Spring Cloud Config 分布式配置中心","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blueskykong.com/tags/Spring-Cloud/"}]},{"title":"Spring Cloud 服务第一次请求超时的优化","slug":"first-timeout","date":"2017-11-17T16:00:00.000Z","updated":"2017-11-19T09:13:48.000Z","comments":true,"path":"2017/11/18/first-timeout/","link":"","permalink":"http://blueskykong.com/2017/11/18/first-timeout/","excerpt":"","text":"1. 问题背景使用Spring Cloud组件构建的服务集群，在第一次请求时经常会出现timeout的情况，然而第二次就正常了。Spring Cloud版本为Dalston.SR4。 启动涉及到的相关服务： gateway(zuul网关) auth-Service（鉴权服务） user-Service（用户服务） 测试的端点接口为：http:/login/oauth/token。服务之间的调用顺序为：gateway-&gt;auth-Service-&gt;user-Service。网关收到客户端的请求，转发请求到鉴权服务，鉴权服务对用户身份的核验是通过调用用户服，用户服务给鉴权服务返回身份校验的结果，鉴权服务将身份授权信息返回给gateway，gateway将最终的结果response返回给客户端。三个服务启动后，通过zipkin监控调用链路信息，可以看到第一次和第二次调用情况如下图所示： 通过上面两次的链路监控信息截图，可以看到第一次的耗时是第二次的10多倍。遇到某些情况，很可能会出现第一次请求的超时。去官网看了下，主要原因是zuul网关和各个调用服务之间的Ribbon进行客户端负载均衡的Client懒加载，导致第一次的请求调用包括了创建Ribbon Client的时间。通过启动日志信息就可以发现： 下面分两部分解决这个问题，一是服务之间调用Ribbon的饥饿加载，对应上面的测试为auth-Service调用user-Service；二是zuul网关的饥饿加载。 2. ribbon的饥饿加载经过调查发现，造成第一次auth-Service调用user-Service耗时长的原因主要是，Ribbon进行客户端负载均衡的服务实例并不是在服务启动的时候就初始化好的，而是在调用的时候才会去创建相应的服务实例。所以第一次调用user-Service耗时不仅仅包含发送HTTP请求的时间，还包含了创建Ribbon Client的时间，这样一来如果创建时间速度较慢，同时设置的请求超时又比较短的话，很容易就会出现耗时很长甚至超时的情况。在官网可以看到如下的配置说明： Each Ribbon named client has a corresponding child Application Context that Spring Cloud maintains, this application context is lazily loaded up on the first request to the named client. This lazy loading behavior can be changed to instead eagerly load up these child Application contexts at startup by specifying the names of the Ribbon clients. 意为Spring Cloud为每个Ribbon客户端维护了一个相对的子应用环境的上下文，应用的上下文在第一次请求到指定客户端的时候懒加载。不过可以通过如下配置进行修改： 1234ribbon: eager-load: enabled: true clients: client1, client2, client3 按照如上的配置之后，发现鉴权服务启动时就将user服务的Ribbon客户端进行了加载。 3. zuul网关的饥饿加载上面小节解决了auth-Service调用user-Service的Ribbon客户端启动时饥饿加载。网关作为对外请求的入口，zuul内部使用Ribbon调用其他服务，Spring Cloud默认在第一次调用时懒加载Ribbon客户端。zuul同样需要维护一个相对的子应用环境的上下文，所以也需要启动时饥饿加载。 Zuul internally uses Ribbon for calling the remote url’s and Ribbon clients are by default lazily loaded up by Spring Cloud on first call. This behavior can be changed for Zuul using the following configuration and will result in the child Ribbon related Application contexts being eagerly loaded up at application startup time. 具体配置如下： 1234zuul: ribbon: eager-load: enabled: true 至此，优化完成，再次重启服务进行第一次请求，发现情况已经好多了，大家可以自己动手尝试改进一下。 4. 总结本文主要介绍了Spring Cloud的服务第一次请求超时的优化方法。首先介绍了问题的背景，并排查了问题造成的原因，主要是Ribbon客户端的懒加载；然后分别针对zuul网关和服务之间调用的Ribbon客户端进行配置，使其启动时便加载Ribbon客户端的相关上下文信息。最后想说的是，http调用毕竟还是性能远低于RPC。。🙂 参考 spring-cloud Dalston.SR4 Spring Cloud实战小贴士：Ribbon的饥饿加载(eager-load)模式","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blueskykong.com/tags/Spring-Cloud/"},{"name":"Ribbon","slug":"Ribbon","permalink":"http://blueskykong.com/tags/Ribbon/"}]},{"title":"微服务之配置服务器切换profile","slug":"profile","date":"2017-11-15T16:00:00.000Z","updated":"2017-11-16T07:11:54.000Z","comments":true,"path":"2017/11/16/profile/","link":"","permalink":"http://blueskykong.com/2017/11/16/profile/","excerpt":"","text":"最近遇到Spring-boot的多个profile切换问题，需求是这样的：微服务中引入了Spring Cloud Config，服务启动的时候，从Config Server中读取该实例对应的配置信息。本地开发环境可能使用的profile是default，到了集成测试环境就需要切换到jenkins，到了预发布环境又变成了prod。多个profile需要之间可以切换。 这边设置的时候还走了点弯路，先是探索了一遍pom的profile，后来才到Spring-boot的配置文件。 这两部分实现的功能不太一样，本文将会具体讲下这两部分。 1. profile之Maven maven切换profile的命令很简单，加上-P参数指定你的profile，如指定prod： 1mvn clean package -P prod maven使用名字为prod的profile来打包，即所有的配置文件都使用生产环境。 下面看下pom中的profiles： 12345678910111213141516171819202122232425262728293031 &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;profileActive&gt;dev&lt;/profileActive&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;profileActive&gt;prod&lt;/profileActive&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 对于resources的配置如下： 12345678910111213141516171819202122 &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;!-- 过滤掉所有配置文件--&gt; &lt;excludes&gt; &lt;exclude&gt;application-dev.yml&lt;/exclude&gt; &lt;exclude&gt;application-prod.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;!--根据profile中的变量profileActive指定对应的配置文件--&gt; &lt;includes&gt; &lt;include&gt;application-$&#123;profileActive&#125;.yml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 上面的两段pom配置相结合，当指定profile为prod时，环境变量profileActive的属性值变为prod。指定打包时，包含application-prod.yml。 所以当你有多套配置文件，可以动态根据mvn命令的参数-P动态指定你所需要加载的配置文件。 2. profile之Spring bootProfile是Spring boot用来针对不同环境对不同配置提供支持的,全局Profile配置使用。application-{profile}.yml 如:application-yml。 spring通过配置spring.profiles.active指定激活某个具体的profile。除了spring.profiles.active来激活一个或者多个profile之外，还可以用spring.profiles.include来叠加profile。 1spring.profiles.include: prod,dev 下面看一下我们的application.yml中包含的配置： 1234567891011121314151617181920212223spring: profiles: active: dev---#开发环境配置spring: profiles: devserver: port: 8080---#测试环境配置spring: profiles: testserver: port: 8081---#生产环境配置spring: profiles: prodserver: port: 8082 application.yml文件分为四部分，使用一组(—)来作为分隔符。第一部分，通用配置部分，表示三个环境都通用的属性，默认激活了dev的profile；后面三部分分别表示不同的环境，指定了不同的port。 部署到服务器的话，正常会打成jar包，加上参数--spring.profiles.active=test指定加载哪个环境的配置。 在IDE中也可以直接配置激活的profile。 3. config server的配置这节讲下与Spring cloud config的结合使用。既然使用了config server，动态配置这块基本就由配置服务器完成了。配置服务器中对该服务指定多个profile。config Server中的配置优先于本地配置，当服务启动时，根据激活的profile，去配置服务器拉取其对应的配置。 既然知道了上面的主要流程，就可以明白我们的需求其实是要在服务启动时指定激活的profile。所以上面一节关于Spring boot的profile动态配置，我们的问题就能解决了。但上面讲到的是jar包启动时指定--spring.profiles.active，实际都是微服务的容器化部署，服务通过容器直接启动jar包，这样就需要容器启动的时候能够动态指定active profile，所以上面的配置改一下，如下： 123spring: profiles: active: $&#123;ACTIVE_PROFILE:dev&#125; 从容器的启动截图来看，指定了docker run -d -e ACTIVE_PROFILE=exp ...后，active profile 变味了exp，并且从config server中拉取对应的是gatewayserver的exp配置。 4. 总结本文主要写了Spring-boot配置服务器切换profile。首先描述了需求背景，然后是对maven pom中profile进行了探索与讲解，其次是讲解了Spring-boot中的profile切换，最后结合config server实现容器部署微服务的profile。笔者最开始一直认为通过pom的profile切换就可以设置服务启动的profile，经过一番探索，发现与配置服务器结合好像并不需要pom的profile这么繁琐，结合配置服务器可以更方便的使用Spring boot的profile。 参考 详解Spring Boot Profiles 配置和使用 [Spring Boot 系列] 集成maven和Spring boot的profile功能","categories":[{"name":"Ops","slug":"Ops","permalink":"http://blueskykong.com/categories/Ops/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://blueskykong.com/tags/Spring-Boot/"},{"name":"Docker","slug":"Docker","permalink":"http://blueskykong.com/tags/Docker/"},{"name":"Ops","slug":"Ops","permalink":"http://blueskykong.com/tags/Ops/"},{"name":"Maven","slug":"Maven","permalink":"http://blueskykong.com/tags/Maven/"}]},{"title":"微服务网关netflix-zuul","slug":"gateway","date":"2017-11-12T16:00:00.000Z","updated":"2017-11-14T03:15:20.000Z","comments":true,"path":"2017/11/13/gateway/","link":"","permalink":"http://blueskykong.com/2017/11/13/gateway/","excerpt":"","text":"引言：前面一个系列文章介绍了认证鉴权与API权限控制在微服务架构中的设计与实现 ，好多同学询问有没有完整的demo项目，笔者回答肯定有的。由于之前系列文章侧重讲解了权限前置，所以近期补上完整的后置项目，但是这最好有一个完整的微服务调用。本文主要讲下API网关的设计与实现。netflix-zuul是由netflix开源的API网关，在微服务架构下，网关作为对外的门户，实现动态路由、监控、授权、安全、调度等功能。 1. 网关介绍当使用单体应用程序架构时，客户端（web和移动端）通过向后端应用程序发起一次REST调用来获取数据。负载均衡器将请求路由给N个相同的应用程序实例中的一个。然后应用程序会查询各种数据库表，并将响应返回给客户端。微服务架构下，单体应用被切割成多个微服务，如果将所有的微服务直接对外暴露，势必会出现安全方面的各种问题。客户端可以直接向每个微服务发送请求，其问题主要如下： 客户端需求和每个微服务暴露的细粒度API不匹配。 部分服务使用的协议不是Web友好协议。可能使用Thrift二进制RPC，也可能使用AMQP消息传递协议。 微服务难以重构。如果合并两个服务，或者将一个服务拆分成两个或更多服务，这类重构就非常困难了。 如上问题，解决的方法是使用API网关。API网关是一个服务，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API网关封装了系统内部架构，为每个客户端提供一个定制的API。它可能还具有其它职责，如身份验证、监控、负载均衡、限流、降级与应用检测。 2. zuul网关API Gateway，常见的选型有基于 Openresty 的 Kong和基于 JVM 的 Zuul，其他还有基于Go的Tyk。技术选型上，之前稍微调研了Kong，性能还可以。考虑到快速应用和二次开发，netflix-zuul也在Spring Cloud的全家桶中，和其他组件配合使用还挺方便，后期可能还会对网关的功能进行扩增，最后选了Zuul。 2.1 pom配置123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在Spring Cloud的项目中，引入zuul的starter，consul-discovery是为了服务的动态路由，这边没有用eureka，是通过注册到consul上的服务实例进行路由。 2.2 入口类12345678@SpringBootApplication@EnableZuulProxypublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class, args); &#125;&#125; Spring boot的入口类需要加上@EnableZuulProxy，下面看下这个注解。 1234567@EnableCircuitBreaker@EnableDiscoveryClient@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Import(&#123;ZuulProxyConfiguration.class&#125;)public @interface EnableZuulProxy &#123;&#125; 可以看到该注解还包含了@EnableCircuitBreaker 和 @EnableDiscoveryClient。@EnableDiscoveryClient注解在服务启动的时候，可以触发服务注册的过程，向配置文件中指定的服务注册中心；@EnableCircuitBreaker则开启了Hystrix的断路器。 2.3 bootstrap.yml12345678910111213141516171819202122232425262728293031323334server: port: 10101 #spring configspring: application: name: gateway-server cloud: consul: discovery: preferIpAddress: true enabled: true register: true service-name: api-getway ip-address: localhost port: $&#123;server.port&#125; lifecycle: enabled: true scheme: http prefer-agent-address: false host: localhost port: 8500#zuul config and routeszuul: host: maxTotalConnections: 500 maxPerRouteConnections: 50 routes: user: path: /user/** ignoredPatterns: /consul serviceId: user sensitiveHeaders: Cookie,Set-Cookie 配置主要包括三块，服务端口，Spring Cloud服务注册，最后是zuul的路由配置。 默认情况下，Zuul在请求路由时，会过滤HTTP请求头信息中的一些敏感信息，默认的敏感头信息通过zuul.sensitiveHeaders定义，包括Cookie、Set-Cookie、Authorization。 zuul.host.maxTotalConnections配置了每个服务的http客户端连接池最大连接，默认值是200。maxPerRouteConnections每个route可用的最大连接数，默认值是20。 2.3 支持https上线的项目一般域名都会改为https协议，顺手写下https的配置。 首先申请https的数字证书在阿里云生成的针对tomcat服务器CA证书在申请成功后， 下载相应的tomcat证书文件。 包含如下：1): .pfx为keystore文件，服务器用的就是这个文件2): pfx-password.txt里包含有keystore所用到的密码3): .key里面包含的是私钥，暂时没用到此文件4): *.pem里面包含的是公钥，主要给客户端 bootstrap.yml增加如下配置 123456789# httpsserver: port: 5443 http: 10101 ssl: enabled: true key-store: classpath:214329585620980.pfx key-store-password: password keyStoreType: PKCS12 同时支持http和https 1234567891011121314151617181920212223242526272829@Bean public EmbeddedServletContainerFactory servletContainer() &#123; TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint constraint = new SecurityConstraint(); constraint.setUserConstraint(\"CONFIDENTIAL\"); SecurityCollection collection = new SecurityCollection(); collection.addPattern(\"\"); constraint.addCollection(collection); context.addConstraint(constraint); &#125; &#125;; tomcat.addAdditionalTomcatConnectors(httpConnector()); return tomcat; &#125; @Bean public Connector httpConnector() &#123; Connector connector = new Connector(\"org.apache.coyote.http11.Http11NioProtocol\"); connector.setScheme(\"http\"); //Connector监听的http的端口号 connector.setPort(httpPort); connector.setSecure(false); //监听到http的端口号后转向到的https的端口号 connector.setRedirectPort(securePort); return connector; &#125; servletContainer()把EmbeddedServletContainerFactory注入到web容器中，用postProcessContext拦截所有的/*请求，并把其关联到下面的httpConnector中。最后，在httpConnector()中，把http设为10101端口，并把http的请求跳转到5443的https端口，这边是读取的配置文件。 至此，至此同时支持https和http的API网关完成，将匹配到/user的请求，路由到user服务，是不是很简单？下面一起深入了解下Zuul。 3. 一些internalsinternals可以理解为内幕。 3.1 过滤器filter是Zuul的核心，用来实现对外服务的控制。filter的生命周期有4个，分别是pre、route、post、error，整个生命周期可以用下图来表示。 一个请求会先按顺序通过所有的前置过滤器，之后在路由过滤器中转发给后端应用，得到响应后又会通过所有的后置过滤器，最后响应给客户端。error可以在所有阶段捕获异常后执行。 一般来说，如果需要在请求到达后端应用前就进行处理的话，会选择前置过滤器，例如鉴权、请求转发、增加请求参数等行为。后面衔接auth系统部分给出具体实现，也是基于pre过滤。 在请求完成后需要处理的操作放在后置过滤器中完成，例如统计返回值和调用时间、记录日志、增加跨域头等行为。路由过滤器一般只需要选择 Zuul 中内置的即可。 错误过滤器一般只需要一个，这样可以在 Gateway 遇到错误逻辑时直接抛出异常中断流程，并直接统一处理返回结果。 3.2 配置管理后端服务 API可能根据情况，有些不需要登录校验了，这个配置信息怎么动态加载到网关配置当中？笔者认为有两种方式：一是配置信息存到库中，定期实现对网关服务的配置刷新；另一种就是基于配置中心服务，当配置提交到配置中心时，触发网关服务的热更新。 后端应用无关的配置，有些是自动化的，例如恶意请求拦截，Gateway 会将所有请求的信息通过消息队列发送给一些实时数据分析的应用，这些应用会对请求分析，发现恶意请求的特征，并通过 Gateway 提供的接口将这些特征上报给 Gateway，Gateway 就可以实时的对这些恶意请求进行拦截。 3.3 隔离机制在微服务的模式下，应用之间的联系变得没那么强烈，理想中任何一个应用超过负载或是挂掉了，都不应该去影响到其他应用。但是在 Gateway 这个层面，有没有可能出现一个应用负载过重，导致将整个 Gateway 都压垮了，已致所有应用的流量入口都被切断？ 这当然是有可能的，想象一个每秒会接受很多请求的应用，在正常情况下这些请求可能在 10 毫秒之内就能正常响应，但是如果有一天它出了问题，所有请求都会 Block 到 30 秒超时才会断开（例如频繁 Full GC 无法有效释放内存）。那么在这个时候，Gateway 中也会有大量的线程在等待请求的响应，最终会吃光所有线程，导致其他正常应用的请求也受到影响。 在 Zuul 中，每一个后端应用都称为一个 Route，为了避免一个 Route 抢占了太多资源影响到其他 Route 的情况出现，Zuul 使用 Hystrix 对每一个 Route 都做了隔离和限流。 Hystrix 的隔离策略有两种，基于线程或是基于信号量。Zuul 默认的是基于线程的隔离机制，之前章节的配置可以回顾下，这意味着每一个 Route 的请求都会在一个固定大小且独立的线程池中执行，这样即使其中一个 Route 出现了问题，也只会是某一个线程池发生了阻塞，其他 Route 不会受到影响。 一般使用 Hystrix 时，只有调用量巨大会受到线程开销影响时才会使用信号量进行隔离策略，对于 Zuul 这种网络请求的用途使用线程隔离更加稳妥。 3.4 重试机制一般来说，后端应用的健康状态是不稳定的，应用列表随时会有修改，所以 Gateway 必须有足够好的容错机制，能够减少后端应用变更时造成的影响。 简单介绍下 Ribbon 支持哪些容错配置。重试的场景分为三种： okToRetryOnConnectErrors：只重试网络错误 okToRetryOnAllErrors：重试所有错误 OkToRetryOnAllOperations：重试所有操作 重试的次数有两种： MaxAutoRetries：每个节点的最大重试次数 MaxAutoRetriesNextServer：更换节点重试的最大次数 一般来说我们希望只在网络连接失败时进行重试、或是对 5XX 的 GET 请求进行重试（不推荐对 POST 请求进行重试，无法保证幂等性会造成数据不一致）。单台的重试次数可以尽量小一些，重试的节点数尽量多一些，整体效果会更好。 如果有更加复杂的重试场景，例如需要对特定的某些 API、特定的返回值进行重试，那么也可以通过实现 RequestSpecificRetryHandler 定制逻辑（不建议直接使用 RetryHandler，因为这个子类可以使用很多已有的功能）。 4. 总结本文首先介绍了API网关的相关知识；其次介绍了zuul网关的配置实现，同时支持https；最后介绍了zuul网关的一些内幕原理，这边大部分参考了网上的文章。网关作为内网与外网之间的门户，所有访问内网的请求都会经过网关，网关处进行反向代理。在整个Spring Cloud微服务框架里，Zuul扮演着”智能网关“的角色。 github: https://github.com/keets2012/Spring-Boot-Samples/tree/master/api-gatewaygitee: https://gitee.com/keets/spring-boot-samples/tree/master/api-gateway 参考 聊聊 API Gateway 和 Netflix Zuul Spring Cloud技术分析（4）- spring cloud zuul netflix-zuul","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"zuul","slug":"zuul","permalink":"http://blueskykong.com/tags/zuul/"},{"name":"gateway","slug":"gateway","permalink":"http://blueskykong.com/tags/gateway/"}]},{"title":"几种分布式调用链监控组件的实践与比较（一）实践","slug":"apm1","date":"2017-11-09T16:00:00.000Z","updated":"2017-11-10T10:01:05.000Z","comments":true,"path":"2017/11/10/apm1/","link":"","permalink":"http://blueskykong.com/2017/11/10/apm1/","excerpt":"","text":"引言：最近在调研与选型分布式调用链监控组件。选了主要的三种APM组件进行了实践与比较。本来打算一篇文章写完的，篇幅太长，打算分两篇。本文主要讲下链路traceing的基本概念和几种APM组件的实践，实践部分也没给出特别详细的步骤，因为本文重点不在具体的步骤。第二篇将会讲下几种APM选型的比较与性能测试。 1. 问题背景微服务架构下，服务按照不同的维度进行拆分，一次请求请求往往需要涉及到多个服务。互联网应用构建在不同的软件模块集上，这些软件模块，有可能是由不同的团队开发、可能使用不同的编程语言来实现、有可能布在了几千台服务器，横跨多个不同的数据中心。因此，就需要一些可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题。 分布式调用链监控组件在这样的环境下产生了。最出名的是谷歌公开的论文提到的Dapper。开发Dapper是为了收集更多的复杂分布式系统的行为信息，然后呈现给Google的开发者们。这样的分布式系统有一个特殊的好处，因为那些大规模的低端服务器，作为互联网服务的载体，是一个特殊的经济划算的平台。想要在这个上下文中理解分布式系统的行为，就需要监控那些横跨了不同的应用、不同的服务器之间的关联动作。 市面上的APM（Application Performance Management）理论模型大多都是借鉴（borrow）Google Dapper论文，本文重点关注以下几种APM组件： Zipkin 由Twitter公司开源，开放源代码分布式的跟踪系统，用于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。 PinpointPinpoint是一款对Java编写的大规模分布式系统的APM工具，由韩国人开源的分布式跟踪组件。 Skywalking国产的优秀APM组件，是一个对JAVA分布式应用程序集群的业务运行情况进行追踪、告警和分析的系统。 其他类似的组件还有美团点评的CAT，淘宝的鹰眼EgleEye。 如上所述，那么我们选择链路监控组件有哪些要求呢？Dapper中也提到了，笔者总结如下： 探针的性能消耗。APM组件服务的影响应该做到足够小。在一些高度优化过的服务，即使一点点损耗也会很容易察觉到，而且有可能迫使在线服务的部署团队不得不将跟踪系统关停。 代码的侵入性对于应用的程序员来说，是不需要知道有跟踪系统这回事的。如果一个跟踪系统想生效，就必须需要依赖应用的开发者主动配合，那么这个跟踪系统也太脆弱了，往往由于跟踪系统在应用中植入代码的bug或疏忽导致应用出问题，这样才是无法满足对跟踪系统“无所不在的部署”这个需求。 可扩展性能够支持的组件越多当然越好。或者提供便捷的插件开发API，对于一些没有监控到的组件，应用开发者也可以自行扩展。 数据的分析数据的分析要快 ，分析的维度尽可能多。跟踪系统能提供足够快的信息反馈，就可以对生产环境下的异常状况做出快速反应。分析的全面，能够避免二次开发。 2. 基础概念上面列出的几种组件，其中Zipkin是严格按照Google Dapper论文实现的，下面介绍下其中涉及的基本概念。 Span基本工作单元，一次链路调用(可以是RPC，DB等没有特定的限制)创建一个span，通过一个64位ID标识它，uuid较为方便，span中还有其他的数据，例如描述信息，时间戳，key-value对的(Annotation)tag信息，parent-id等,其中parent-id可以表示span调用链路来源。 Trace:类似于树结构的Span集合，表示一条调用链路，存在唯一标识。比如你运行的分布式大数据存储一次Trace就由你的一次请求组成。 Annotation: 注解,用来记录请求特定事件相关信息(例如时间)，通常包含四个注解信息： (1) cs：Client Start,表示客户端发起请求 (2) sr：Server Receive,表示服务端收到请求 (3) ss：Server Send,表示服务端完成处理，并将结果发送给客户端 (4) cr：Client Received,表示客户端获取到服务端返回信息 2.1 Trace下面看一下，在系统中Trace是什么样子。 每种颜色的note标注了一个span，一条链路通过TraceId唯一标识，Span标识发起的请求信息。树节点是整个架构的基本单元，而每一个节点又是对span的引用。节点之间的连线表示的span和它的父span直接的关系。虽然span在日志文件中只是简单的代表span的开始和结束时间，他们在整个树形结构中却是相对独立的。 2.2 Span 上图说明了span在一次大的跟踪过程中是什么样的。Dapper记录了span名称，以及每个span的ID和父ID，以重建在一次追踪过程中不同span之间的关系。如果一个span没有父ID被称为root span。所有span都挂在一个特定的跟踪上，也共用一个跟踪id。 2.3 Annotation自动的探针，不需要修改应用程序源代码，对应用开发者近乎零浸入的成本对分布式控制路径进行跟踪，几乎完全依赖于基于少量通用组件库的改造。Dapper还允许应用程序开发人员在Dapper跟踪的过程中添加额外的信息，以监控更高级别的系统行为，或帮助调试问题。 下面章节将会介绍下上述三种APM组件的使用与实践。 3. zipkinzipkin主要涉及几个组件：collector收集agent的数据，storage存储，web UI图形化界面，search查询Storage中存储的数据,提供简单的JSON API获取数据。 我们的项目基于微服务框架spring cloud构建微服务。spring cloud也提供了spring-cloud-sleuth来方便集成zipkin实现。所以笔者就在项目中试了下spring-cloud-sleuth-zipkin。 起了三个服务：zipkin-server、zipkin-client-backend、zipkin-client。其中server服务负责收集以及信息展示。client-backend调用client，产生调用链路信息。 3.1 zipkin-server实现zipkin-server实现主要有两点需要注意，其一是收集到数据的存储，方式包括内存、数据库、ES等；其二是通信方式，包括http通信和mq异步方式通信，http通信会对正常的访问造成影响，所以还是推荐基于mq异步方式通信。 本文使用mysql作为存储，使用MQ通信，MQ通信基于Spring-cloud-Stream。本文重点不在zipkin-server的具体几种实现方式，其他方式，读者可以自己去官网查看。 （1）pom需要添加的引用如下： 1234567891011121314151617181920212223242526272829&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--zipkin依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--保存到数据库需要如下依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; （2）启动类： 12345678// 使用Stream方式启动ZipkinServer@EnableZipkinStreamServer@SpringBootApplicationpublic class ZipkinStreamServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipkinStreamServerApplication.class,args); &#125;&#125; @EnableZipkinStreamServer注解引入了@EnableZipkinServer注解，同时还创建了一个rabbit-mq的SleuthSink消息队列监听器。 （3）配置文件 123456789101112131415161718192021222324252627server: port: 9411spring: datasource: username: root password: root123 schema[0]: classpath:/zipkin.sqlzipkin: storage: type: mysql---spring: application: name: microservice-zipkin-stream-server rabbitmq: host: $&#123;RABBIT_ADDR:localhost&#125; port: $&#123;RABBIT_PORT:5672&#125; username: guest password: guest sleuth: enabled: false profiles: default datasource: url: jdbc:mysql://localhost:3307/zipkin?autoReconnect=true&amp;useSSL=false zipkin.sql可以去官网获取，设置了zipkin-server的端口号为9411。 3.2 zipkin-client两个zipkin-client的配置一样，所以放在一起。 （1）pom依赖 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; (2) 配置文件 123456spring: rabbitmq: host: 127.0.0.1 port : 5672 username: guest password: guest 3.3 结果服务之间的调用关系如下： 可以看到客户端的请求经过gateway，调用内网中的各个服务，部分还涉及到调用notice服务。从图中可以清楚的看出客户端请求所经过的服务。下面看下demo2-default服务实例中的http path： 上图中demo2-default服务的几个http path按照时长排序，显示了trace调用时长和span数量。点进去可以看到： 图中列出了从父span开始，每一个span的耗时。本次trace中，涉及到两个服务demo1和demo2。demo2调用demo1，从597ms开始调用demo1，完成最终的请求总共耗时1265ms。 4. pinpoint对代码零侵入，运用JavaAgent字节码增强技术，只需要加启动参数即可。pinpoint的几个组件部分和zipkin差不多，架构图如下： Pinpoint-Collector收集各种性能数据、Pinpoint-Agent和自己运行的应用关联起来的探针、Pinpoint-Web将收集到的数据显示成WEB网页形式、HBase Storage收集到的数据存到HBase中。 4.1 pinpoint安装主要涉及以下软件的安装： jdk 1.8Java环境必须的，没啥好解释。 Hbasepinpoint收集来的测试数据，主要是存在Hbase数据库的。所以它可以收集大量的数据，可以进行更加详细的分析。Hbase安装完成后，需要初始化Hbase的pinpoint库，由pinpoint提供。Hbase内置了zookeeper。 pinpoint-collectorcollector收集agent的数据，将数据存到hbase集群，对外暴露collector的tcp和udp的监听端口9994，9995，9996。 pinpoint-web页面展示，配置文件中设置环境变量HBASE_HOST、HBASE_PORT等。 pinpoint-agent 到官网release页面下载pinpoint-agent-x-SNAPSHOT.tar.gz，配置pinpoint.config中相关collector的信息。 安装确实还比较麻烦，本文篇幅太长了，具体步骤后面再单独写文章讲解。 4.2 运行pinpoint-agent笔者使用的是spring-boot项目，所以只需要在启动jar包的命令中加入-javaagent参数，并指定pinpoint-bootstrap包的绝对路径。实例代码如下： 1java -javaagent:/aoho/auth_compose/pinpoint-bootstrap-1.6.0.jar -Dpinpoint.agentId=aoho-consumer -Dpinpoint.applicationName=aoho-consumer -jar id_generator/snowflake-id-generate-1.0-SNAPSHOT.jar 起的id生成器服务比较简单，没有用到数据库等存储介质。服务注册到consul上，本地客户端请求了id-server获取id。其调用链如下： pinpoint提供的功能比较丰富，下图是调用/api/id接口的详细信息。 可以看到，pinpoint记录了客户端的相应时间、IP地址等，调用树在下面也有详细列出，每个方法的耗时等。 serverMap中还展示了服务器的堆、永久代、CPU等信息，非常强大。 5. SkywalkingSkywalking是国内开源的APM监控组件，官网OpenSkywalking，根据官网介绍，其着力于性能和实时性两方面。网上找到的Skywalking的架构图。 可以看到Skywalking也是四部分组成，collector、agent、web、storage。支持集群部署，集群之间还引入了grpc通信。存储支持内置的h2和elasticsearch存储。 5.1 安装具体安装可见官网。 collector安装此处笔者使用单机版的collector，在release页面下载好压缩包，解压后，单机版的collector默认使用h2数据库，所以配置文件可以不需要修改，即可以运行bin/startup.sh。 目录结构如上，logs文件夹中，有启动的日志，可以查看启动情况。 web解压好skywalking-ui，设置server的config/collector_config.properties、log4j2以及监听端口等相关信息， agent拷贝skywalking-agent目录到所需位置，探针包含整个目录，设置/config/agent.config中的collector信息。 5.2 运行agentSpring boot的项目，启动和上面pinpoint agent启动方式相同。增加JVM启动参数，-javaagent:/path/to/skywalking-agent/skywalking-agent.jar。 这次起了user服务，涉及到mysql、redis、consul等组件。可以看到其调用链路图如下： 当访问/api/external/register-code和/api/external/validate-code接口时，形成了上图中的调用链。 上图TraceId为 2.59.15103021777910001的请求/api/external/register-code。这次trace中，每个涉及的span的耗时都有在图中统计。 上面这张图，是对userService中的Entry Service List接口进行了统计，包括调用数、成功率等信息。（因为内置的h2，这边在UI响应很久） 还有个对instance的统计，统计jvm的相关信息，API响应也很慢，可能与我用的存储有关吧，就不截图了。 6. 总结本文主要写了链路监控组件的实践。首先介绍了链路监控组件产生与应用的背景，以及选择的要求；其次介绍了opentracing中涉及的基本概念；最后大篇幅介绍了三种APM组件的安装与使用，并展示了每种APM的UI截图。本文比较简单，下一篇文章主要介绍几种APM选型的比较与性能测试。 zipkin-server-stream的源码github: https://github.com/keets2012/Spring-Boot-Samples/oschina: https://gitee.com/keets/spring-boot-samples 参考(疯狂找资料) OpenTracing官方标准-中文版 Skywalking Zipkin PinPoint Spring Cloud Sleuth Dapper pinpoint 安装部署 java开源APM概要 分布式系统监控系统zipkin入门 跟着小程学微服务-自己动手扩展分布式调用链","categories":[{"name":"Ops","slug":"Ops","permalink":"http://blueskykong.com/categories/Ops/"}],"tags":[{"name":"APM","slug":"APM","permalink":"http://blueskykong.com/tags/APM/"},{"name":"zipkin","slug":"zipkin","permalink":"http://blueskykong.com/tags/zipkin/"},{"name":"micro-service","slug":"micro-service","permalink":"http://blueskykong.com/tags/micro-service/"}]},{"title":"微服务部署之Maven插件构建Docker镜像","slug":"dockermaven","date":"2017-11-01T16:00:00.000Z","updated":"2017-11-08T03:14:57.000Z","comments":true,"path":"2017/11/02/dockermaven/","link":"","permalink":"http://blueskykong.com/2017/11/02/dockermaven/","excerpt":"","text":"1.背景微服务架构下，微服务在带来良好的设计和架构理念的同时，也带来了运维上的额外复杂性，尤其是在服务部署和服务监控上。单体应用是集中式的，就一个单体跑在一起，部署和管理的时候非常简单，而微服务是一个网状分布的，有很多服务需要维护和管理，对它进行部署和维护的时候则比较复杂。 下面从Dev的角度来看一下Ops的工作。从Dev提交代码，到完成集成测试的一系列步骤如下： 首先是开发人员把程序代码更新后上传到Git，然后其他的事情都将由Jenkins自动完成。 然后Git在接收到用户更新的代码后，会把消息和任务传递给Jenkins，然后Jenkins会自动构建一个任务，下载Maven相关的软件包。下载完成后，就开始利用Maven Build新的项目包，然后重建Maven容器，构建新的Image并Push到Docker私有库中。 最后删除正在运行的Docker容器，再基于新的镜像重新把Docker容器启动，自动完成集成测试。 整个过程都是自动的，这样就简化了原本复杂的集成工作，一天可以集成一次，甚至是多次。 本文主要关注的第二步，作为Dev使用Maven插件构建Docker镜像。 2. 过程步骤2.1 环境笔者的电脑系统是MacOS，在进行下面的步骤之前，先具备一下条件： Docker Registry Maven（3.5.0） JDK(1.8.0_131) Docker for Mac (17.09.0-ce-mac35) Maven 和JDK 就不用过多多了，必须具有的。Docker Registry是私有的hub，mac上装好docker之后，配置一下Docker Registry的地址，配置如下： 1234567&#123; \"debug\" : true, \"experimental\" : false, \"insecure-registries\" : [ \"192.168.1.202\" ]&#125; 配置好registry地址之后，本地pull镜像，还需要命令行login到registry： 1docker login 192.168.1.202 --username admin --password 123456 2.2 pom文件pom文件中需要引入相应的插件。docker-maven-plugin有三款：spotify、fabric8io和bibryam。其中第一款最为流行，资料也多，所以毫不犹豫选择第一款。插件有两种使用方式，一种是在直接在pom配置中指定baseImage和entryPoint。另一种适合于复杂的构建，使用dockerfile，只需要在配置中指定dockerfile的位置。前一种比较简单，此处略过，主要讲下第二种的配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.docker.version&#125;&lt;/version&gt; &lt;!--插件绑定到phase--&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!--配置变量，包括是否build、imageName、imageTag，非常灵活--&gt; &lt;skipDocker&gt;$&#123;docker.skip.build&#125;&lt;/skipDocker&gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;!--最后镜像产生了两个tag，版本和和最新的--&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;imageTag&gt;latest&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;env&gt; &lt;TZ&gt;Asia/Shanghai&lt;/TZ&gt; &lt;/env&gt; &lt;!--时区配置--&gt; &lt;runs&gt; &lt;run&gt;ln -snf /usr/share/zoneinfo/$TZ /etc/localtime&lt;/run&gt; &lt;run&gt;echo $TZ &gt; /etc/timezone&lt;/run&gt; &lt;/runs&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--push到私有的hub--&gt; &lt;serverId&gt;docker-registry&lt;/serverId&gt; &lt;/configuration&gt; &lt;/plugin&gt; ${maven.docker.version}、${docker.skip.build}、${docker.image.prefix}都是可配置的变量。${project.basedir}、${project.build.directory}、${project.build.finalName}、${project.version}分别对应项目根目录、构建目录、打包后生成的结果名称、项目版本号。上面的pom插件配置，指定了dockerfile的位置和镜像的命名规则。并将docker的build目标，绑定在install这个phase上。 2.3 dockerfile12345FROM 192.168.1.202/library/basejavaVOLUME /tmpADD ./target/cloud-api-gateway-1.2.0.RELEASE.jar app.jarRUN bash -c 'touch /app.jar'ENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"/app.jar\"] dockerfile 写的很简单，将jar包ADD进去，提供ENTRYPOINT。 2.4 setting.xml在pom插件中，还有一个serverId的配置。这个配置是必要的，对于需要将image上传到私有hub上，在如上配置之后，只需要加上-DpushImage即可实现。serverId是与maven的配置文件setting.xml相对应，setting.xml中增加的配置： 12345678&lt;server&gt; &lt;id&gt;docker-registry&lt;/id&gt; &lt;username&gt;用户名&lt;/username&gt; &lt;password&gt;密码&lt;/password&gt; &lt;configuration&gt; &lt;email&gt;邮箱&lt;/email&gt; &lt;/configuration&gt;&lt;/server&gt; 2.5 结果 上图是执行mvn clean install -DpushImage成功的结果。mvn首先是打包，将生产的文件拷贝到target下的docker目录，然后执行dockerfile中的步骤，将打成的镜像进行tag，最后上传到私有hub上。 上图是VMware Harbor中的截图，可以看到，我们已经成功将镜像上传，其tag有两个：1.2.0.RELEASE和latest。 3. 总结本文属于工程实践类文章，比较简单。开头由背景介绍了Dev到继承测试的一系列步骤，本文主要关注的是第二步，作为Dev使用Maven插件构建Docker镜像。正文部分主要讲了实践的环境，然后讲了docker-maven-plugin插件的使用方式，重点介绍了使用dockerfile的方式，对于涉及到的配置进行了解释。 本文的源码地址：GitHub：https://github.com/keets2012/snowflake-id-generator码云： https://gitee.com/keets/snowflake-id-generator 参考 从运维的角度看微服务和容器 Docker与微服务-使用Maven插件构建Docker镜像","categories":[{"name":"Ops","slug":"Ops","permalink":"http://blueskykong.com/categories/Ops/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blueskykong.com/tags/Spring-Cloud/"},{"name":"Docker","slug":"Docker","permalink":"http://blueskykong.com/tags/Docker/"},{"name":"Ops","slug":"Ops","permalink":"http://blueskykong.com/tags/Ops/"}]},{"title":"认证鉴权与API权限控制在微服务架构中的设计与实现（四）","slug":"security4","date":"2017-10-25T16:00:00.000Z","updated":"2017-10-26T13:13:51.000Z","comments":true,"path":"2017/10/26/security4/","link":"","permalink":"http://blueskykong.com/2017/10/26/security4/","excerpt":"","text":"引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的完结篇，前面三篇已经将认证鉴权与API权限控制的流程和主要细节讲解完。本文比较长，对这个系列进行收尾，主要内容包括对授权和鉴权流程之外的endpoint以及Spring Security过滤器部分踩坑的经历。欢迎阅读本系列文章。 1. 前文回顾首先还是照例对前文进行回顾。在第一篇 认证鉴权与API权限控制在微服务架构中的设计与实现（一）介绍了该项目的背景以及技术调研与最后选型。第二篇认证鉴权与API权限控制在微服务架构中的设计与实现（二）画出了简要的登录和校验的流程图，并重点讲解了用户身份的认证与token发放的具体实现。第三篇认证鉴权与API权限控制在微服务架构中的设计与实现（三）先介绍了资源服务器配置，以及其中涉及的配置类，后面重点讲解了token以及API级别的鉴权。 本文将会讲解剩余的两个内置端点：注销和刷新token。注销token端点的处理与Spring Security默认提供的有些’/logout’有些区别，不仅清空SpringSecurityContextHolder中的信息，还要增加对存储token的清空。另一个刷新token端点其实和之前的请求授权是一样的API，只是参数中的grant_type不一样。 除了以上两个内置端点，后面将会重点讲下几种Spring Security过滤器。API级别的操作权限校验本来设想是通过Spring Security的过滤器实现，特地把这边学习了一遍，踩了一遍坑。 最后是本系列的总结，并对于存在的不足和后续工作进行论述。 2. 其他端点2.1 注销端点在第一篇中提到了Auth系统内置的注销端点 /logout，如果还记得第三篇资源服务器的配置，下面的关于/logout配置一定不陌生。 123456//... .and().logout() .logoutUrl(\"/logout\") .clearAuthentication(true) .logoutSuccessHandler(new HttpStatusReturningLogoutSuccessHandler()) .addLogoutHandler(customLogoutHandler()); 上面配置的主要作用是： 设置注销的URL 清空Authentication信息 设置注销成功的处理方式 设置自定义的注销处理方式 当然在LogoutConfigurer中还有更多的设置选项，笔者此处列出项目所需要的配置项。这些配置项围绕着LogoutFilter过滤器。顺带讲一下Spring Security的过滤器。其使用了springSecurityFillterChian作为了安全过滤的入口，各种过滤器按顺序具体如下： SecurityContextPersistenceFilter：与SecurityContext安全上下文信息有关 HeaderWriterFilter：给http响应添加一些Header CsrfFilter：防止csrf攻击，默认开启 LogoutFilter：处理注销的过滤器 UsernamePasswordAuthenticationFilter：表单认证过滤器 RequestCacheAwareFilter：缓存request请求 SecurityContextHolderAwareRequestFilter：此过滤器对ServletRequest进行了一次包装，使得request具有更加丰富的API AnonymousAuthenticationFilter：匿名身份过滤器 SessionManagementFilter：session相关的过滤器，常用来防止session-fixation protection attack，以及限制同一用户开启多个会话的数量 ExceptionTranslationFilter：异常处理过滤器 FilterSecurityInterceptor：web应用安全的关键Filter 各种过滤器简单标注了作用，在下一节重点讲其中的几个过滤器。注销过滤器排在靠前的位置，我们一起看下LogoutFilter的UML类图。 类图和我们之前配置时的思路是一致的，HttpSecurity创建了LogoutConfigurer，我们在这边配置了LogoutConfigurer的一些属性。同时LogoutConfigurer根据这些属性创建了LogoutFilter。 LogoutConfigurer的配置，第一和第二点就不用再详细解释了，一个是设置端点，另一个是清空认证信息。对于第三点，配置注销成功的处理方式。由于项目是前后端分离，客户端只需要知道执行成功该API接口的状态，并不用返回具体的页面或者继续向下传递请求。因此，这边配置了默认的HttpStatusReturningLogoutSuccessHandler，成功直接返回状态码200。对于第四点配置，自定义注销处理的方法。这边需要借助TokenStore，对token进行操作。TokenStore在之前文章的配置中已经讲过，使用的是JdbcTokenStore。首先校验请求的合法性，如果合法则对其进行操作，先后移除refreshToken和existingAccessToken。 12345678910111213141516171819202122232425262728293031323334public class CustomLogoutHandler implements LogoutHandler &#123; //... @Override public void logout(HttpServletRequest request, HttpServletResponse response, Authentication authentication) &#123; //确定注入了tokenStore Assert.notNull(tokenStore, \"tokenStore must be set\"); //获取头部的认证信息 String token = request.getHeader(\"Authorization\"); Assert.hasText(token, \"token must be set\"); //校验token是否符合JwtBearer格式 if (isJwtBearerToken(token)) &#123; token = token.substring(6); OAuth2AccessToken existingAccessToken = tokenStore.readAccessToken(token); OAuth2RefreshToken refreshToken; if (existingAccessToken != null) &#123; if (existingAccessToken.getRefreshToken() != null) &#123; LOGGER.info(\"remove refreshToken!\", existingAccessToken.getRefreshToken()); refreshToken = existingAccessToken.getRefreshToken(); tokenStore.removeRefreshToken(refreshToken); &#125; LOGGER.info(\"remove existingAccessToken!\", existingAccessToken); tokenStore.removeAccessToken(existingAccessToken); &#125; return; &#125; else &#123; throw new BadClientCredentialsException(); &#125; &#125; //...&#125; 执行如下请求： 123456method: geturl: http://localhost:9000/logoutheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=&#125; 注销成功则会返回200，将token和SecurityContextHolder进行清空。 2.2 刷新端点在第一篇就已经讲过，由于token的时效一般不会很长，而refresh token一般周期会很长，为了不影响用户的体验，可以使用refresh token去动态的刷新token。刷新token主要与RefreshTokenGranter有关，CompositeTokenGranter管理一个List列表，每一种grantType对应一个具体的真正授权者，refresh_ token对应的granter就是RefreshTokenGranter，而granter内部则是通过grantType来区分是否是各自的授权类型。执行如下请求： 123456method: post url: http://localhost:12000/oauth/token?grant_type=refresh_token&amp;refresh_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeEheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=&#125; 在refresh_ token正确的情况下，其返回的response和/oauth/token得到正常的响应是一样的。具体的代码可以参阅第二篇的讲解。 3. Spring Security过滤器在上一节我们介绍了内置的两个端点的实现细节，还提到了HttpSecurity过滤器，因为注销端点的实现就是通过过滤器的作用。核心的过滤器主要有： FilterSecurityInterceptor UsernamePasswordAuthenticationFilter SecurityContextPersistenceFilter ExceptionTranslationFilter 这一节将重点介绍其中的UsernamePasswordAuthenticationFilter和FilterSecurityInterceptor。 3.1 UsernamePasswordAuthenticationFilter笔者在刚开始看关于过滤器的文章，对于UsernamePasswordAuthenticationFilter有不少的文章介绍。如果只是引入Spring-Security，必然会与/login端点熟悉。SpringSecurity强制要求我们的表单登录页面必须是以POST方式向/login URL提交请求，而且要求用户名和密码的参数名必须是username和password。如果不符合，则不能正常工作。原因在于，当我们调用了HttpSecurity对象的formLogin方法时，其最终会给我们注册一个过滤器UsernamePasswordAuthenticationFilter。看一下该过滤器的源码。 1234567891011121314151617181920212223242526272829303132333435public class UsernamePasswordAuthenticationFilter extends AbstractAuthenticationProcessingFilter &#123; //用户名、密码 public static final String SPRING_SECURITY_FORM_USERNAME_KEY = \"username\"; public static final String SPRING_SECURITY_FORM_PASSWORD_KEY = \"password\"; private String usernameParameter = SPRING_SECURITY_FORM_USERNAME_KEY; private String passwordParameter = SPRING_SECURITY_FORM_PASSWORD_KEY; private boolean postOnly = true; //post请求/login public UsernamePasswordAuthenticationFilter() &#123; super(new AntPathRequestMatcher(\"/login\", \"POST\")); &#125; //实现抽象类AbstractAuthenticationProcessingFilter的抽象方法，尝试验证 public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if (postOnly &amp;&amp; !request.getMethod().equals(\"POST\")) &#123; throw new AuthenticationServiceException( \"Authentication method not supported: \" + request.getMethod()); &#125; String username = obtainUsername(request); String password = obtainPassword(request); //··· username = username.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); //··· return this.getAuthenticationManager().authenticate(authRequest); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public abstract class AbstractAuthenticationProcessingFilter extends GenericFilterBean implements ApplicationEventPublisherAware, MessageSourceAware &#123; //... //调用requiresAuthentication，判断请求是否需要authentication，如果需要则调用attemptAuthentication //有三种结果可能返回： //1.Authentication对象 //2. AuthenticationException //3. Authentication对象为空 public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; //不需要校验，继续传递 if (!requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); return; &#125; Authentication authResult; try &#123; authResult = attemptAuthentication(request, response); if (authResult == null) &#123; // return immediately as subclass has indicated that it hasn't completed authentication return; &#125; sessionStrategy.onAuthentication(authResult, request, response); &#125; //... catch (AuthenticationException failed) &#123; // Authentication failed unsuccessfulAuthentication(request, response, failed); return; &#125; // Authentication success if (continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; successfulAuthentication(request, response, chain, authResult); &#125; //实际执行的authentication，继承类必须实现该抽象方法 public abstract Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException, IOException, ServletException; //成功authentication的默认行为 protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; //... &#125; //失败authentication的默认行为 protected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response, AuthenticationException failed) throws IOException, ServletException &#123; //... &#125; ... //设置AuthenticationManager public void setAuthenticationManager(AuthenticationManager authenticationManager) &#123; this.authenticationManager = authenticationManager; &#125; ...&#125; UsernamePasswordAuthenticationFilter因为继承了AbstractAuthenticationProcessingFilter才拥有过滤器的功能。AbstractAuthenticationProcessingFilter要求设置一个authenticationManager，authenticationManager的实现类将实际处理请求的认证。AbstractAuthenticationProcessingFilter将拦截符合过滤规则的request，并试图执行认证。子类必须实现 attemptAuthentication 方法，这个方法执行具体的认证。认证之后的处理和上注销的差不多。如果认证成功，将会把返回的Authentication对象存放在SecurityContext，并调用SuccessHandler，也可以设置指定的URL和指定自定义的处SuccessHandler。如果认证失败，默认会返回401代码给客户端，也可以设置URL，指定自定义的处理FailureHandler。 基于UsernamePasswordAuthenticationFilter自定义的AuthenticationFilte还是挺多案例的，这边推荐一篇博文Spring Security(五)–动手实现一个IP_Login，写得比较详细。 3.2 FilterSecurityInterceptorFilterSecurityInterceptor是filterchain中比较复杂，也是比较核心的过滤器，主要负责web应用安全授权的工作。首先看下对于自定义的FilterSecurityInterceptor配置。 12345678910111213@Override public void configure(HttpSecurity http) throws Exception &#123; ... //添加CustomSecurityFilter，过滤器的顺序放在FilterSecurityInterceptor http.antMatcher(\"/oauth/check_token\").addFilterAt(customSecurityFilter(), FilterSecurityInterceptor.class); &#125; //提供实例化的自定义过滤器 @Bean public CustomSecurityFilter customSecurityFilter() &#123; return new CustomSecurityFilter(); &#125; 从上述配置可以看到，在FilterSecurityInterceptor的位置注册了CustomSecurityFilter，对于匹配到/oauth/check_token，则会调用该进入该过滤器。下图为FilterSecurityInterceptor的类图，在其中还添加了CustomSecurityFilter和相关实现的接口的类，方便读者对比着看。 CustomSecurityFilter是模仿FilterSecurityInterceptor实现，继承AbstractSecurityInterceptor和实现Filter接口。整个过程需要依赖AuthenticationManager、AccessDecisionManager和FilterInvocationSecurityMetadataSource。AuthenticationManager是认证管理器，实现用户认证的入口；AccessDecisionManager是访问决策器，决定某个用户具有的角色，是否有足够的权限去访问某个资源；FilterInvocationSecurityMetadataSource是资源源数据定义，即定义某一资源可以被哪些角色访问。从上面的类图中可以看到自定义的CustomSecurityFilter同时又实现了AccessDecisionManager和FilterInvocationSecurityMetadataSource。分别为SecureResourceFilterInvocationDefinitionSource和SecurityAccessDecisionManager。下面分析下主要的配置。 12345678910111213//通过一个实现的filter，对HTTP资源进行安全处理public class FilterSecurityInterceptor extends AbstractSecurityInterceptor implements Filter &#123; //被filter chain真实调用的方法，通过invoke代理 public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FilterInvocation fi = new FilterInvocation(request, response, chain); invoke(fi); &#125; //代理的方法 public void invoke(FilterInvocation fi) throws IOException, ServletException &#123; //...省略 &#125;&#125; 上述代码是FilterSecurityInterceptor中的实现，具体实现细节就没列出了，我们这边重点在于对自定义的实现进行讲解。 123456789101112131415161718192021222324252627282930313233343536373839404142public class CustomSecurityFilter extends AbstractSecurityInterceptor implements Filter &#123; @Autowired SecureResourceFilterInvocationDefinitionSource invocationSource; @Autowired private AuthenticationManager authenticationManager; @Autowired private SecurityAccessDecisionManager decisionManager; //设置父类中的属性 @PostConstruct public void init() &#123; super.setAccessDecisionManager(decisionManager); super.setAuthenticationManager(authenticationManager); &#125; //主要的过滤方法，与原来的一致 @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; //logger.info(\"doFilter in Security \"); //构造一个FilterInvocation，封装request, response, chain FilterInvocation fi = new FilterInvocation(servletRequest, servletResponse, filterChain); //beforeInvocation会调用SecureResourceDataSource中的逻辑，类似于aop中的before InterceptorStatusToken token = super.beforeInvocation(fi); try &#123; //执行下一个拦截器 fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; finally &#123; //完成后续工作，类似于aop中的after super.afterInvocation(token, null); &#125; &#125; //... //资源源数据定义，设置为自定义的SecureResourceFilterInvocationDefinitionSource @Override public SecurityMetadataSource obtainSecurityMetadataSource() &#123; return invocationSource; &#125;&#125; 上面自定义的CustomSecurityFilter，与我们之前的讲解是一样的流程。主要依赖的三个接口都有在实现中实例化注入。看下父类的beforeInvocation方法，其中省略了一些不重要的代码片段。 12345678910111213141516171819protected InterceptorStatusToken beforeInvocation(Object object) &#123; //根据SecurityMetadataSource获取配置的权限属性 Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object); //... //判断是否需要对认证实体重新认证，默认为否 Authentication authenticated = authenticateIfRequired(); // Attempt authorization try &#123; //决策管理器开始决定是否授权，如果授权失败，直接抛出AccessDeniedException this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException accessDeniedException) &#123; publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, accessDeniedException)); throw accessDeniedException; &#125; &#125; 上面代码可以看出，第一步是根据SecurityMetadataSource获取配置的权限属性，accessDecisionManager会用到权限列表信息。然后判断是否需要对认证实体重新认证，默认为否。第二步是接着决策管理器开始决定是否授权，如果授权失败，直接抛出AccessDeniedException。 (1). 获取配置的权限属性 12345678910111213141516171819202122232425262728293031323334353637383940public class SecureResourceFilterInvocationDefinitionSource implements FilterInvocationSecurityMetadataSource, InitializingBean &#123; private PathMatcher matcher; //map保存配置的URL对应的权限集 private static Map&lt;String, Collection&lt;ConfigAttribute&gt;&gt; map = new HashMap&lt;&gt;(); //根据传入的对象URL进行循环 @Override public Collection&lt;ConfigAttribute&gt; getAttributes(Object o) throws IllegalArgumentException &#123; logger.info(\"getAttributes\"); //应该做instanceof FilterInvocation filterInvocation = (FilterInvocation) o; //String method = filterInvocation.getHttpRequest().getMethod(); String requestURI = filterInvocation.getRequestUrl(); //循环资源路径，当访问的Url和资源路径url匹配时，返回该Url所需要的权限 for (Iterator&lt;Map.Entry&lt;String, Collection&lt;ConfigAttribute&gt;&gt;&gt; iterator = map.entrySet().iterator(); iter.hasNext(); ) &#123; Map.Entry&lt;String, Collection&lt;ConfigAttribute&gt;&gt; entry = iterator.next(); String url = entry.getKey(); if (matcher.match(url, requestURI)) &#123; return map.get(requestURI); &#125; &#125; return null; &#125; //... //设置权限集，即上述的map @Override public void afterPropertiesSet() throws Exception &#123; logger.info(\"afterPropertiesSet\"); //用来匹配访问资源路径 this.matcher = new AntPathMatcher(); //可以有多个权限 Collection&lt;ConfigAttribute&gt; atts = new ArrayList&lt;&gt;(); ConfigAttribute c1 = new SecurityConfig(\"ROLE_ADMIN\"); atts.add(c1); map.put(\"/oauth/check_token\", atts); &#125;&#125; 上面是getAttributes()实现的具体细节，将请求的URL取出进行匹配事先设定的受限资源，最后返回需要的权限、角色。系统在启动的时候就会读取到配置的map集合，对于拦截到请求进行匹配。代码中注释比较详细，这边不多说。 (2). 决策管理器 1234567891011121314151617181920212223242526272829public class SecurityAccessDecisionManager implements AccessDecisionManager &#123; //... @Override public void decide(Authentication authentication, Object o, Collection&lt;ConfigAttribute&gt; collection) throws AccessDeniedException, InsufficientAuthenticationException &#123; logger.info(\"decide url and permission\"); //集合为空 if (collection == null) &#123; return; &#125; Iterator&lt;ConfigAttribute&gt; ite = collection.iterator(); //判断用户所拥有的权限，是否符合对应的Url权限，如果实现了UserDetailsService，则用户权限是loadUserByUsername返回用户所对应的权限 while (ite.hasNext()) &#123; ConfigAttribute ca = ite.next(); String needRole = ca.getAttribute(); for (GrantedAuthority ga : authentication.getAuthorities()) &#123; logger.info(\"GrantedAuthority: &#123;&#125;\", ga); if (needRole.equals(ga.getAuthority())) &#123; return; &#125; &#125; &#125; logger.error(\"AccessDecisionManager: no right!\"); throw new AccessDeniedException(\"no right!\"); &#125; //...&#125; 上面的代码是决策管理器的实现，其逻辑也比较简单，将请求所具有的权限与设定的受限资源所需的进行匹配，如果具有则返回，否则抛出没有正确的权限异常。默认提供的决策管理器有三种，分别为AffirmativeBased、ConsensusBased、UnanimousBased，篇幅有限，我们这边不再扩展了。 补充一下，所具有的权限是通过之前配置的认证方式，有password认证和client认证两种。我们之前在授权服务器中配置了withClientDetails，所以用frontend身份验证获得的权限是我们预先配置在数据库中的authorities。 4. 总结Auth系统主要功能是授权认证和鉴权。项目微服务化后，原有的单体应用基于HttpSession认证鉴权不能满足微服务架构下的需求。每个微服务都需要对访问进行鉴权，每个微应用都需要明确当前访问用户以及其权限，尤其当有多个客户端，包括web端、移动端等等，单体应用架构下的鉴权方式就不是特别合适了。权限服务作为基础的公共服务，也需要微服务化。 笔者的设计中，Auth服务一方面进行授权认证，另一方面是基于token进行身份合法性和API级别的权限校验。对于某个服务的请求，经过网关会调用Auth服务，对token合法性进行验证。同时笔者根据当前项目的整体情况，存在部分遗留服务，这些遗留服务又没有足够的时间和人力立马进行微服务改造，而且还需要继续运行。为了适配当前新的架构，采取的方案就是对这些遗留服务的操作API，在Auth服务进行API级别的操作权限鉴定。API级别的操作权限校验需要的上下文信息需要结合业务，与客户端进行商定，应该在token能取到相应信息，传递给Auth服务，不过应尽量减少在header取上下文校验的信息。 笔者将本次开发Auth系统所涉及的大部分代码及源码进行了解析，至于没有讲到的一些内容和细节，读者可以自行扩展。 5. 不足与后续工作5.1 存在的不足 API级别操作权限校验的通用性 (1). 对于API级别操作权限校验，需要在网关处调用时构造相应的上下文信息。上下文信息基本依赖于 token中的payload，如果信息太多引起token太长，导致每次客户端的请求头部长度变长。 (2). 并不是所有的操作接口都能覆盖到，这个问题是比较严重的，根据上下文集合很可能出现好多接口 的权限没法鉴定，最后的结果就是API级别操作权限校验失败的是绝对没有权限访问该接口，而通过不一定能访问，因为该接口涉及到的上下文根本没法完全得到。我们的项目在现阶段，定义的最小上下文集合能勉强覆盖到，但是对于后面扩增的服务接口真的是不乐观。 (3). 每个服务的每个接口都在Auth服务注册其所需要的权限，太过麻烦，Auth服务需要额外维护这样的信息。 网关处调用Auth服务带来的系统吞吐量瓶颈 (1). 这个其实很容易理解，Auth服务作为公共的基础服务，大多数服务接口都会需要鉴权，Auth服务需要经过复杂。 (2). 网关调用Auth服务，阻塞调用，只有等Auth服务返回校验结果，才会做进一步处理。虽说Auth服务可以多实例部署，但是并发量大了之后，其瓶颈明显可见，严重可能会造成整个系统的不可用。 5.2 后续工作 从整个系统设计角度来讲，API级别操作权限后期将会分散在各个服务的接口上，由各个接口负责其所需要的权限、身份等。Spring Security对于接口级别的权限校验也是支持的，之所以采用这样的做法，也是为了兼容新服务和遗留的服务，主要是针对遗留服务，新的服务采用的是分散在各个接口之上。 将API级别操作权限分散到各个服务接口之后，相应的能提升Auth服务的响应。网关能够及时的对请求进行转发或者拒绝。 API级别操作权限所需要的上下文信息对各个接口真的设计的很复杂，这边我们确实花了时间，同时管理移动服务的好几百操作接口所对应的权限，非常烦。！ 本文的源码地址：GitHub：https://github.com/keets2012/Auth-service码云： https://gitee.com/keets/Auth-Service 参考 配置表单登录 Spring Security3源码分析-FilterSecurityInterceptor分析 Core Security Filters Spring Security(四)–核心过滤器源码分析 相关阅读认证鉴权与API权限控制在微服务架构中的设计与实现（一）认证鉴权与API权限控制在微服务架构中的设计与实现（二）认证鉴权与API权限控制在微服务架构中的设计与实现（三）","categories":[{"name":"Security","slug":"Security","permalink":"http://blueskykong.com/categories/Security/"}],"tags":[{"name":"OAuth2","slug":"OAuth2","permalink":"http://blueskykong.com/tags/OAuth2/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"http://blueskykong.com/tags/Spring-Security/"}]},{"title":"认证鉴权与API权限控制在微服务架构中的设计与实现（三）","slug":"security3","date":"2017-10-23T16:00:00.000Z","updated":"2017-10-24T08:47:15.000Z","comments":true,"path":"2017/10/24/security3/","link":"","permalink":"http://blueskykong.com/2017/10/24/security3/","excerpt":"","text":"引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第三篇，本文重点讲解token以及API级别的鉴权。本文对涉及到的大部分代码进行了分析，欢迎订阅本系列文章。 1. 前文回顾在开始讲解这一篇文章之前，先对之前两篇文章进行回忆下。在第一篇 认证鉴权与API权限控制在微服务架构中的设计与实现（一）介绍了该项目的背景以及技术调研与最后选型。第二篇认证鉴权与API权限控制在微服务架构中的设计与实现（二）画出了简要的登录和校验的流程图，并重点讲解了用户身份的认证与token发放的具体实现。 本文重点讲解鉴权，包括两个方面：token合法性以及API级别的操作权限。首先token合法性很容易理解，第二篇文章讲解了获取授权token的一系列流程，token是否是认证服务器颁发的，必然是需要验证的。其次对于API级别的操作权限，将上下文信息不具备操作权限的请求直接拒绝，当然此处是设计token合法性校验在先，其次再对操作权限进行验证，如果前一个验证直接拒绝，通过则进入操作权限验证。 2.资源服务器配置ResourceServer配置在第一篇就列出了，在进入鉴权之前，把这边的配置搞清，即使有些配置在本项目中没有用到，大家在自己的项目有可能用到。 1234567891011121314151617181920212223242526272829303132333435@Configuration@EnableResourceServerpublic class ResourceServerConfig extends ResourceServerConfigurerAdapter &#123; //http安全配置 @Override public void configure(HttpSecurity http) throws Exception &#123; //禁掉csrf，设置session策略 http.csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and()//默认允许访问 .requestMatchers().antMatchers(\"/**\") .and().authorizeRequests() .antMatchers(\"/**\").permitAll() .anyRequest().authenticated() .and().logout() //logout注销端点配置 .logoutUrl(\"/logout\") .clearAuthentication(true) .logoutSuccessHandler(new HttpStatusReturningLogoutSuccessHandler()) .addLogoutHandler(customLogoutHandler()); &#125; //添加自定义的CustomLogoutHandler @Bean public CustomLogoutHandler customLogoutHandler() &#123; return new CustomLogoutHandler(); &#125; //资源安全配置相关 @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &#123; super.configure(resources); &#125;&#125; (1). @EnableResourceServer这个注解很重要，OAuth2资源服务器的简便注解。其使得Spring Security filter通过请求中的OAuth2 token来验证请求。通常与EnableWebSecurity配合使用，该注解还创建了硬编码的@Order(3) WebSecurityConfigurerAdapter，由于当前spring的技术，order的顺序不易修改，所以在项目中避免还有其他order=3的配置。 (2). 关联的HttpSecurity，与之前的 Spring Security XML中的 “http”元素配置类似，它允许配置基于web安全以针对特定http请求。默认是应用到所有的请求，通过requestMatcher可以限定具体URL范围。HttpSecurity类图如下。 总的来说：HttpSecurity是SecurityBuilder接口的一个实现类，从名字上我们就可以看出这是一个HTTP安全相关的构建器。当然我们在构建的时候可能需要一些配置，当我们调用HttpSecurity对象的方法时，实际上就是在进行配置。 authorizeRequests()，formLogin()、httpBasic()这三个方法返回的分别是ExpressionUrlAuthorizationConfigurer、FormLoginConfigurer、HttpBasicConfigurer，他们都是SecurityConfigurer接口的实现类，分别代表的是不同类型的安全配置器。因此，从总的流程上来说，当我们在进行配置的时候，需要一个安全构建器SecurityBuilder(例如我们这里的HttpSecurity)，SecurityBuilder实例的创建需要有若干安全配置器SecurityConfigurer实例的配合。 (3).关联的ResourceServerSecurityConfigurer，为资源服务器添加特殊的配置，默认的适用于很多应用，但是这边的修改至少以resourceId为单位。类图如下。 ResourceServerSecurityConfigurer创建了OAuth2核心过滤器OAuth2AuthenticationProcessingFilter，并为其提供固定了OAuth2AuthenticationManager。只有被OAuth2AuthenticationProcessingFilter拦截到的oauth2相关请求才被特殊的身份认证器处理。同时设置了TokenExtractor、异常处理实现。 OAuth2AuthenticationProcessingFilter是OAuth2保护资源的预先认证过滤器。配合OAuth2AuthenticationManager使用，根据请求获取到OAuth2 token，之后就会使用OAuth2Authentication来填充Spring Security上下文。OAuth2AuthenticationManager在前面的文章给出的AuthenticationManager类图就出现了，与token认证相关。这边略过贴出源码进行讲解，读者可以自行阅读。 3. 鉴权endpoint鉴权主要是使用内置的endpoint /oauth/check_token，笔者将对端点的分析放在前面，因为这是鉴权的唯一入口。下面我们来看下该API接口中的主要代码。 123456789101112131415161718192021222324252627282930@RequestMapping(value = \"/oauth/check_token\") @ResponseBody public Map&lt;String, ?&gt; checkToken(CheckTokenEntity checkTokenEntity) &#123; //CheckTokenEntity为自定义的dto Assert.notNull(checkTokenEntity, \"invalid token entity!\"); //识别token OAuth2AccessToken token = resourceServerTokenServices.readAccessToken(checkTokenEntity.getToken()); //判断token是否为空 if (token == null) &#123; throw new InvalidTokenException(\"Token was not recognised\"); &#125; //未过期 if (token.isExpired()) &#123; throw new InvalidTokenException(\"Token has expired\"); &#125; //加载OAuth2Authentication OAuth2Authentication authentication = resourceServerTokenServices.loadAuthentication(token.getValue()); //获取response，token合法性验证完毕 Map&lt;String, Object&gt; response = (Map&lt;String, Object&gt;) accessTokenConverter.convertAccessToken(token, authentication); //check for api permission if (response.containsKey(\"jti\")) &#123; //上下文操作权限校验 Assert.isTrue(checkPermissions.checkPermission(checkTokenEntity)); &#125; response.put(\"active\", true); // Always true if token exists and not expired return response; &#125; 看过security-oauth源码的同学可能立马就看出上述代码与源码不同，熟悉/oauth/check_token校验流程的也会看出来，这边笔者对security-oauth jar进行了重新编译，修改了部分源码用于该项目需求的场景。主要是加入了前置的API级别的权限校验。 4. token 合法性验证从上面的CheckTokenEndpoint中可以看出，对于token合法性验证首先是识别请求体中的token。用到的主要方法是ResourceServerTokenServices提供的readAccessToken()方法。该接口的实现类为DefaultTokenServices，在之前的配置中有讲过这边配置了jdbc的TokenStore。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class JdbcTokenStore implements TokenStore &#123; ... public OAuth2AccessToken readAccessToken(String tokenValue) &#123; OAuth2AccessToken accessToken = null; try &#123; //使用selectAccessTokenSql语句，调用了私有的extractTokenKey()方法 accessToken = jdbcTemplate.queryForObject(selectAccessTokenSql, new RowMapper&lt;OAuth2AccessToken&gt;() &#123; public OAuth2AccessToken mapRow(ResultSet rs, int rowNum) throws SQLException &#123; return deserializeAccessToken(rs.getBytes(2)); &#125; &#125;, extractTokenKey(tokenValue)); &#125; //异常情况 catch (EmptyResultDataAccessException e) &#123; if (LOG.isInfoEnabled()) &#123; LOG.info(\"Failed to find access token for token \" + tokenValue); &#125; &#125; catch (IllegalArgumentException e) &#123; LOG.warn(\"Failed to deserialize access token for \" + tokenValue, e); //不合法则移除 removeAccessToken(tokenValue); &#125; return accessToken; &#125; ... //提取TokenKey方法 protected String extractTokenKey(String value) &#123; if (value == null) &#123; return null; &#125; MessageDigest digest; try &#123; //MD5 digest = MessageDigest.getInstance(\"MD5\"); &#125; catch (NoSuchAlgorithmException e) &#123; throw new IllegalStateException(\"MD5 algorithm not available. Fatal (should be in the JDK).\"); &#125; try &#123; byte[] bytes = digest.digest(value.getBytes(\"UTF-8\")); return String.format(\"%032x\", new BigInteger(1, bytes)); &#125; catch (UnsupportedEncodingException e) &#123; throw new IllegalStateException(\"UTF-8 encoding not available. Fatal (should be in the JDK).\"); &#125; &#125;&#125; readAccessToken()检索出该token值的完整信息。上述代码比较简单，涉及到的逻辑也不复杂，此处简单讲解。下图为debug token校验的变量信息，读者可以自己动手操作下，截图仅供参考。 至于后面的步骤，loadAuthentication()为特定的access token 加载credentials。得到的credentials 与token作为convertAccessToken()参数，得到校验token的response。 5. API级别权限校验笔者项目目前都是基于Web的权限验证，之前遗留的一个巨大的单体应用系统正在逐渐拆分，然而当前又不能完全拆分完善。为了同时兼容新旧服务，尽量减少对业务系统的入侵，实现微服务的统一性和独立性。笔者根据业务业务场景，尝试在Auth处做操作权限校验。首先想到的是资源服务器配置ResourceServer，如： 12http.authorizeRequests().antMatchers(&quot;/order/**&quot;).access(&quot;#oauth2.hasScope(&apos;select&apos;) and hasRole(&apos;ROLE_USER&apos;)&quot;) 这样做需要将每个操作接口的API权限控制放在各个不同的业务服务，每个服务在接收到请求后，需要先从Auth服务取出该token 对应的role和scope等权限信息。这个方法肯定是可行的，但是由于项目鉴权的粒度更细，而且暂时不想大动原有系统，在加上之前网关设计，网关调用Auth服务校验token合法性，所以最后决定在Auth系统调用中，把这些校验一起解决完。 文章开头资源服务器的配置代码可以看出，对于所有的资源并没有做拦截，因为网关处是调用Auth系统的相关endpoint，并不是所有的请求url都会经过一遍Auth系统，所以对于所有的资源，在Auth系统中，定义需要鉴权接口所需要的API权限，然后根据上下文进行匹配。这是采用的第二种方式，也是笔者目前采用的方法。当然这种方式的弊端也很明显，一旦并发量大，网关还要耗时在调用Auth系统的鉴权上，TPS势必要下降很多，对于一些不需要鉴权的服务接口也会引起不可用。另外一点是，对于某些特殊权限的接口，需要的上下文信息很多，可能并不能完全覆盖，对于此，笔者的解决是分两方面：一是尽量将这些特殊情况进行分类，某一类的情况统一解决；二是将严苛的校验降低，对于上下文校验失败的直接拒绝，而通过的，对于某些接口，在接口内进行操作之前，对特殊的地方还要再次进行校验。 上面在讲endpoint有提到这边对源码进行了改写。CheckTokenEntity是自定义的DTO，这这个类中定义了鉴权需要的上下文，这里是指能校验操作权限的最小集合，如URI、roleId、affairId等等。另外定义了CheckPermissions接口，其方法checkPermission(CheckTokenEntity checkTokenEntity)返回了check的结果。而其具体实现类则定义在Auth系统中。笔者项目中调用的实例如下： 12345678910111213141516171819@Componentpublic class CustomCheckPermission implements CheckPermissions &#123; @Autowired private PermissionService permissionService; @Override public boolean checkPermission(CheckTokenEntity checkTokenEntity) &#123; String url = checkTokenEntity.getUri(); Long affairId = checkTokenEntity.getAffairId(); Long roleId = checkTokenEntity.getRoleId(); //校验 if (StringUtils.isEmpty(url) || affairId &lt;= 0 || roleId &lt;= 0) &#123; return true; &#125; else &#123; return permissionService.checkPermission(url, affairId, roleId); &#125; &#125;&#125; 关于jar包spring-cloud-starter-oauth2中的具体修改内容，大家可以看下文末笔者的GitHub项目。通过自定义CustomCheckPermission，覆写checkPermission()方法，大家也可以对自己业务的操作权限进行校验，非常灵活。这边涉及到具体业务，笔者在项目中只提供接口，具体的实现需要读者自行完成。 6. 总结本文相对来说比较简单，主要讲解了token以及API级别的鉴权。token的合法性认证很常规，Auth系统对于API级别的鉴权是结合自身业务需要和现状进行的设计。这两块的校验都前置到Auth系统中，优缺点在上面的小节也有讲述。最后，架构设计根据自己的需求和现状，笔者的解决思路仅供参考。 本文的源码地址：GitHub：https://github.com/keets2012/Auth-service码云： https://gitee.com/keets/Auth-Service 参考 微服务API级权限的技术架构 spring-security-oauth Spring-Security Docs 相关阅读认证鉴权与API权限控制在微服务架构中的设计与实现（一）认证鉴权与API权限控制在微服务架构中的设计与实现（二）","categories":[{"name":"Security","slug":"Security","permalink":"http://blueskykong.com/categories/Security/"}],"tags":[{"name":"OAuth2","slug":"OAuth2","permalink":"http://blueskykong.com/tags/OAuth2/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"http://blueskykong.com/tags/Spring-Security/"}]},{"title":"认证鉴权与API权限控制在微服务架构中的设计与实现（二）","slug":"security2","date":"2017-10-21T16:00:00.000Z","updated":"2017-12-21T08:30:33.000Z","comments":true,"path":"2017/10/22/security2/","link":"","permalink":"http://blueskykong.com/2017/10/22/security2/","excerpt":"引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第二篇，本文重点讲解用户身份的认证与token发放的具体实现。本文篇幅较长，对涉及到的大部分代码进行了分析，可收藏于闲暇时间阅读，欢迎订阅本系列文章。","text":"引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第二篇，本文重点讲解用户身份的认证与token发放的具体实现。本文篇幅较长，对涉及到的大部分代码进行了分析，可收藏于闲暇时间阅读，欢迎订阅本系列文章。 1. 系统概览在上一篇 认证鉴权与API权限控制在微服务架构中的设计与实现（一）介绍了该项目的背景以及技术调研与最后选型，并且对于最终实现的endpoint执行结果进行展示。对系统架构虽然有提到，但是并未列出详细流程图。在笔者的应用场景中，Auth系统与网关进行结合。在网关出配置相应的端点信息，如登录系统申请token授权，校验check_token等端点。 下图为网关与Auth系统结合的流程图，网关系统的具体实现细节在后面另写文章介绍。（此处流程图的绘制中，笔者使用极简的语言描述，各位同学轻喷😆！） 上图展示了系统登录的简单流程，其中的细节有省略，用户信息的合法性校验实际是调用用户系统。大体流程是这样，客户端请求到达网关之后，根据网关识别的请求登录端点，转发到Auth系统，将用户的信息进行校验。 另一方面是对于一般请求的校验。一些不需要权限的公开接口，在网关处配置好，请求到达网关后，匹配了路径将会直接放行。如果需要对该请求进行校验，会将该请求的相关验证信息截取，以及API权限校验所需的上下文信息（笔者项目对于一些操作进行权限前置验证，下一篇章会讲到），调用Auth系统，校验成功后进行路由转发。 这篇文章就重点讲解我们在第一篇文章中提到的用户身份的认证与token发放。这个也主要包含两个方面： 用户合法性的认证 获取到授权的token 2. 配置与类图2.1 AuthorizationServer主要配置关于AuthorizationServer和ResourceServer的配置在上一篇文章已经列出。AuthorizationServer主要是继承了AuthorizationServerConfigurerAdapter，覆写了其实现接口的三个方法： 1234567891011121314//对应于配置AuthorizationServer安全认证的相关信息，创建ClientCredentialsTokenEndpointFilter核心过滤器@Overridepublic void configure(AuthorizationServerSecurityConfigurer security) throws Exception &#123; &#125;//配置OAuth2的客户端相关信息@Overridepublic void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123;&#125;//配置身份认证器，配置认证方式，TokenStore，TokenGranter，OAuth2RequestFactory@Overridepublic void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123;&#125; 2.2 主要Authentication类的类图 主要的验证方法authenticate(Authentication authentication)在接口AuthenticationManager中，其实现类有ProviderManager，有上图可以看出ProviderManager又依赖于AuthenticationProvider接口，其定义了一个List&lt;AuthenticationProvider&gt;全局变量。笔者这边实现了该接口的实现类CustomAuthenticationProvider。自定义一个provider，并在GlobalAuthenticationConfigurerAdapter中配置好改自定义的校验provider，覆写configure()方法。 123456789101112@Configurationpublic class AuthenticationManagerConfig extends GlobalAuthenticationConfigurerAdapter &#123; @Autowired CustomAuthenticationProvider customAuthenticationProvider; @Override public void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.authenticationProvider(customAuthenticationProvider);//使用自定义的AuthenticationProvider &#125;&#125; AuthenticationManagerBuilder是用来创建AuthenticationManager，允许自定义提供多种方式的AuthenticationProvider，比如LDAP、基于JDBC等等。 3. 认证与授权token下面讲解认证与授权token主要的类与接口。 3.1 内置端点TokenEndpointSpring-Security-Oauth2的提供的jar包中内置了与token相关的基础端点。本文认证与授权token与/oauth/token有关，其处理的接口类为TokenEndpoint。下面我们来看一下对于认证与授权token流程的具体处理过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@FrameworkEndpointpublic class TokenEndpoint extends AbstractEndpoint &#123; ... @RequestMapping(value = \"/oauth/token\", method=RequestMethod.POST) public ResponseEntity&lt;OAuth2AccessToken&gt; postAccessToken(Principal principal, @RequestParam Map&lt;String, String&gt; parameters) throws HttpRequestMethodNotSupportedException &#123; //首先对client信息进行校验 if (!(principal instanceof Authentication)) &#123; throw new InsufficientAuthenticationException( \"There is no client authentication. Try adding an appropriate authentication filter.\"); &#125; String clientId = getClientId(principal); //根据请求中的clientId，加载client的具体信息 ClientDetails authenticatedClient = getClientDetailsService().loadClientByClientId(clientId); TokenRequest tokenRequest = getOAuth2RequestFactory().createTokenRequest(parameters, authenticatedClient); ... //验证scope域范围 if (authenticatedClient != null) &#123; oAuth2RequestValidator.validateScope(tokenRequest, authenticatedClient); &#125; //授权方式不能为空 if (!StringUtils.hasText(tokenRequest.getGrantType())) &#123; throw new InvalidRequestException(\"Missing grant type\"); &#125; //token endpoint不支持Implicit模式 if (tokenRequest.getGrantType().equals(\"implicit\")) &#123; throw new InvalidGrantException(\"Implicit grant type not supported from token endpoint\"); &#125; ... //进入CompositeTokenGranter，匹配授权模式，然后进行password模式的身份验证和token的发放 OAuth2AccessToken token = getTokenGranter().grant(tokenRequest.getGrantType(), tokenRequest); if (token == null) &#123; throw new UnsupportedGrantTypeException(\"Unsupported grant type: \" + tokenRequest.getGrantType()); &#125; return getResponse(token); &#125; ...&#125; 上面给代码进行了注释，读者感兴趣可以看看。接口处理的主要流程就是对authentication信息进行检查是否合法，不合法直接抛出异常，然后对请求的GrantType进行处理，根据GrantType，进行password模式的身份验证和token的发放。下面我们来看下TokenGranter的类图。 可以看出TokenGranter的实现类CompositeTokenGranter中有一个List&lt;TokenGranter&gt;，对应五种GrantType的实际授权实现。这边涉及到的getTokenGranter()，代码也列下： 123456789101112131415161718192021public class CompositeTokenGranter implements TokenGranter &#123; //GrantType的集合，有五种，之前有讲 private final List&lt;TokenGranter&gt; tokenGranters; public CompositeTokenGranter(List&lt;TokenGranter&gt; tokenGranters) &#123; this.tokenGranters = new ArrayList&lt;TokenGranter&gt;(tokenGranters); &#125; //遍历list，匹配到相应的grantType就进行处理 public OAuth2AccessToken grant(String grantType, TokenRequest tokenRequest) &#123; for (TokenGranter granter : tokenGranters) &#123; OAuth2AccessToken grant = granter.grant(grantType, tokenRequest); if (grant!=null) &#123; return grant; &#125; &#125; return null; &#125; ...&#125; 本次请求是使用的password模式，随后进入其GrantType具体的处理流程，下面是grant()方法。 1234567891011121314151617181920212223242526public OAuth2AccessToken grant(String grantType, TokenRequest tokenRequest) &#123; if (!this.grantType.equals(grantType)) &#123; return null; &#125; String clientId = tokenRequest.getClientId(); //加载clientId对应的ClientDetails，为了下一步的验证 ClientDetails client = clientDetailsService.loadClientByClientId(clientId); //再次验证clientId是否拥有该grantType模式，安全 validateGrantType(grantType, client); //获取token return getAccessToken(client, tokenRequest);&#125;protected OAuth2AccessToken getAccessToken(ClientDetails client, TokenRequest tokenRequest) &#123;//进入创建token之前，进行身份验证 return tokenServices.createAccessToken(getOAuth2Authentication(client, tokenRequest));&#125;protected OAuth2Authentication getOAuth2Authentication(ClientDetails client, TokenRequest tokenRequest) &#123;//身份验证 OAuth2Request storedOAuth2Request = requestFactory.createOAuth2Request(client, tokenRequest); return new OAuth2Authentication(storedOAuth2Request, null);&#125; 上面一段代码是grant()方法具体的实现细节。GrantType匹配到其对应的grant()后，先进行基本的验证确保安全，然后进入主流程，就是下面小节要讲的验证身份和发放token。 3.2 自定义的验证类CustomAuthenticationProviderCustomAuthenticationProvider中定义了验证方法的具体实现。其具体实现如下所示。 1234567891011121314151617181920212223242526//主要的自定义验证方法@Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; String username = authentication.getName(); String password = (String) authentication.getCredentials(); Map data = (Map) authentication.getDetails(); String clientId = (String) data.get(\"client\"); Assert.hasText(clientId,\"clientId must have value\" ); String type = (String) data.get(\"type\"); //通过调用user服务，校验用户信息 Map map = userClient.checkUsernameAndPassword(getUserServicePostObject(username, password, type)); //校验返回的信息，不正确则抛出异常，授权失败 String userId = (String) map.get(\"userId\"); if (StringUtils.isBlank(userId)) &#123; String errorCode = (String) map.get(\"code\"); throw new BadCredentialsException(errorCode); &#125; CustomUserDetails customUserDetails = buildCustomUserDetails(username, password, userId, clientId); return new CustomAuthenticationToken(customUserDetails); &#125; //构造一个CustomUserDetails，简单，略去 private CustomUserDetails buildCustomUserDetails(String username, String password, String userId, String clientId) &#123; &#125;//构造一个请求userService的map，内容略 private Map&lt;String, String&gt; getUserServicePostObject(String username, String password, String type) &#123; &#125; authenticate()最后返回构造的自定义CustomAuthenticationToken，在CustomAuthenticationToken中，将boolean authenticated设为true，user信息验证成功。这边传入的参数CustomUserDetails与token生成有关，作为payload中的信息，下面会讲到。 12345678910//继承抽象类AbstractAuthenticationTokenpublic class CustomAuthenticationToken extends AbstractAuthenticationToken &#123; private CustomUserDetails userDetails; public CustomAuthenticationToken(CustomUserDetails userDetails) &#123; super(null); this.userDetails = userDetails; super.setAuthenticated(true); &#125; ...&#125; 而AbstractAuthenticationToken实现了接口Authentication和CredentialsContainer，里面的具体信息读者可以自己看下源码。 3.3 关于JWT用户信息校验完成之后，下一步则是要对该用户进行授权。在讲具体的授权之前，先补充下关于JWT Token的相关知识点。 Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准(RFC 7519)。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 从上面的描述可知JWT的定义，这边读者可以对比下token的认证和传统的session认证的区别。推荐一篇文章什么是 JWT – JSON WEB TOKEN，笔者这边就不详细扩展讲了，只是简单介绍下其构成。 JWT包含三部分：header头部、payload信息、signature签名。下面以上一篇生成好的access_token为例介绍。 headerjwt的头部承载两部分信息，一是声明类型，这里是jwt；二是声明加密的算法 通常直接使用 HMAC SHA256。第一部分一般固定为： 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 playload存放的有效信息，这些有效信息包含三个部分、标准中注册的声明、公共的声明、私有的声明。这边笔者额外添加的信息为X-KEETS-UserId和X-KEETS-ClientId。读者可根据实际项目需要进行定制。最后playload经过base64编码后的结果为： 1eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ signaturejwt的第三部分是一个签证信息，这个签证信息由三部分组成：header (base64后的)、payload (base64后的)、secret。关于secret，细心的读者可能会发现之前的配置里面有具体设置。前两部分连接组成的字符串，通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。第三部分结果为： 15ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo 至于具体应用方法，可以参见第一篇文章中构建的/logout端点。 3.3 自定义的AuthorizationTokenServices现在到了为用户创建token，这边主要与自定义的接口AuthorizationServerTokenServices有关。AuthorizationServerTokenServices主要有如下三个方法： 1234567//创建tokenOAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException;//刷新tokenOAuth2AccessToken refreshAccessToken(String refreshToken, TokenRequest tokenRequest) throws AuthenticationException;//获取tokenOAuth2AccessToken getAccessToken(OAuth2Authentication authentication); 由于篇幅限制，笔者这边仅对createAccessToken()的实现方法进行分析，其他的方法实现，读者可以下关注笔者的GitHub项目。 1234567891011121314151617181920212223242526272829303132public class CustomAuthorizationTokenServices implements AuthorizationServerTokenServices, ConsumerTokenServices &#123; ... public OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException &#123; //通过TokenStore，获取现存的AccessToken OAuth2AccessToken existingAccessToken = tokenStore.getAccessToken(authentication); OAuth2RefreshToken refreshToken; //移除已有的AccessToken和refreshToken if (existingAccessToken != null) &#123; if (existingAccessToken.getRefreshToken() != null) &#123; refreshToken = existingAccessToken.getRefreshToken(); // The token store could remove the refresh token when the // access token is removed, but we want to be sure tokenStore.removeRefreshToken(refreshToken); &#125; tokenStore.removeAccessToken(existingAccessToken); &#125; //recreate a refreshToken refreshToken = createRefreshToken(authentication); OAuth2AccessToken accessToken = createAccessToken(authentication, refreshToken); if (accessToken != null) &#123; tokenStore.storeAccessToken(accessToken, authentication); &#125; refreshToken = accessToken.getRefreshToken(); if (refreshToken != null) &#123; tokenStore.storeRefreshToken(refreshToken, authentication); &#125; return accessToken; &#125; ...&#125; 这边具体的实现在上面有注释，基本没有改写多少，读者此处可以参阅源码。createAccessToken()还调用了两个私有方法，分别创建accessToken和refreshToken。创建accessToken，需要基于refreshToken。此处可以自定义设置token的时效长度，accessToken创建实现如下： 1234567891011121314151617private int refreshTokenValiditySeconds = 60 * 60 * 24 * 30; // default 30 days. private int accessTokenValiditySeconds = 60 * 60 * 12; // default 12 hours. private OAuth2AccessToken createAccessToken(OAuth2Authentication authentication, OAuth2RefreshToken refreshToken) &#123; //对应tokenId，存储的标识 DefaultOAuth2AccessToken token = new DefaultOAuth2AccessToken(UUID.randomUUID().toString()); int validitySeconds = getAccessTokenValiditySeconds(authentication.getOAuth2Request()); if (validitySeconds &gt; 0) &#123; token.setExpiration(new Date(System.currentTimeMillis() + (validitySeconds * 1000L))); &#125; token.setRefreshToken(refreshToken); //scope对应作用范围 token.setScope(authentication.getOAuth2Request().getScope());//上一节介绍的自定义TokenEnhancer，这边使用 return accessTokenEnhancer != null ? accessTokenEnhancer.enhance(token, authentication) : token; &#125; 既然提到TokenEnhancer，这边简单贴一下代码。 12345678910111213141516171819202122232425public class CustomTokenEnhancer extends JwtAccessTokenConverter &#123; private static final String TOKEN_SEG_USER_ID = \"X-KEETS-UserId\"; private static final String TOKEN_SEG_CLIENT = \"X-KEETS-ClientId\"; @Override public OAuth2AccessToken enhance(OAuth2AccessToken accessToken, OAuth2Authentication authentication) &#123; CustomUserDetails userDetails = (CustomUserDetails) authentication.getPrincipal(); Map&lt;String, Object&gt; info = new HashMap&lt;&gt;(); //从自定义的userDetails中取出UserId info.put(TOKEN_SEG_USER_ID, userDetails.getUserId()); DefaultOAuth2AccessToken customAccessToken = new DefaultOAuth2AccessToken(accessToken); customAccessToken.setAdditionalInformation(info); OAuth2AccessToken enhancedToken = super.enhance(customAccessToken, authentication); //设置ClientId enhancedToken.getAdditionalInformation().put(TOKEN_SEG_CLIENT, userDetails.getClientId()); return enhancedToken; &#125;&#125; 自此，用户身份校验与发放授权token结束。最终成功返回的结果为: 12345678910&#123; &quot;access_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ.5ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeE&quot;, &quot;expires_in&quot;: 43195, &quot;scope&quot;: &quot;all&quot;, &quot;X-KEETS-UserId&quot;: &quot;d6448c24-3c4c-4b80-8372-c2d61868f8c6&quot;, &quot;jti&quot;: &quot;bad72b19-d9f3-4902-affa-0430e7db79ed&quot;, &quot;X-KEETS-ClientId&quot;: &quot;frontend&quot;&#125; 4. 总结本文开头给出了Auth系统概述，画出了简要的登录和校验的流程图，方便读者能对系统的实现有个大概的了解。然后主要讲解了用户身份的认证与token发放的具体实现。对于其中主要的类和接口进行了分析与讲解。下一篇文章主要讲解token的鉴定和API级别的上下文权限校验。 本文的源码地址：GitHub：https://github.com/keets2012/Auth-service码云： https://gitee.com/keets/Auth-Service 参考 什么是 JWT – JSON WEB TOKEN Re：从零开始的Spring Security OAuth2（二） spring-security-oauth 相关阅读认证鉴权与API权限控制在微服务架构中的设计与实现（一）","categories":[{"name":"Security","slug":"Security","permalink":"http://blueskykong.com/categories/Security/"}],"tags":[{"name":"OAuth2","slug":"OAuth2","permalink":"http://blueskykong.com/tags/OAuth2/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"http://blueskykong.com/tags/Spring-Security/"}]},{"title":"认证鉴权与API权限控制在微服务架构中的设计与实现（一）","slug":"security1","date":"2017-10-18T16:00:00.000Z","updated":"2018-02-12T07:56:17.000Z","comments":true,"path":"2017/10/19/security1/","link":"","permalink":"http://blueskykong.com/2017/10/19/security1/","excerpt":"引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第一篇，本系列预计四篇文章讲解微服务下的认证鉴权与API权限控制的实现。 1. 背景最近在做权限相关服务的开发，在系统微服务化后，原有的单体应用是基于session的安全权限方式，不能满足现有的微服务架构的认证与鉴权需求。微服务架构下，一个应用会被拆分成若干个微应用，每个微应用都需要对访问进行鉴权，每个微应用都需要明确当前访问用户以及其权限。尤其当访问来源不只是浏览器，还包括其他服务的调用时，单体应用架构下的鉴权方式就不是特别合适了。在微服务架构下，要考虑外部应用接入的场景、用户–服务的鉴权、服务–服务的鉴权等多种鉴权场景。比如用户A访问User Service，A如果未登录，则首先需要登录，请求获取授权token。获取token之后，A将携带着token去请求访问某个文件，这样就需要对A的身份进行校验，并且A可以访问该文件。为了适应架构的变化、需求的变化，auth权限模块被单独出来作为一个基础的微服务系统，为其他业务service提供服务。","text":"引言： 本文系《认证鉴权与API权限控制在微服务架构中的设计与实现》系列的第一篇，本系列预计四篇文章讲解微服务下的认证鉴权与API权限控制的实现。 1. 背景最近在做权限相关服务的开发，在系统微服务化后，原有的单体应用是基于session的安全权限方式，不能满足现有的微服务架构的认证与鉴权需求。微服务架构下，一个应用会被拆分成若干个微应用，每个微应用都需要对访问进行鉴权，每个微应用都需要明确当前访问用户以及其权限。尤其当访问来源不只是浏览器，还包括其他服务的调用时，单体应用架构下的鉴权方式就不是特别合适了。在微服务架构下，要考虑外部应用接入的场景、用户–服务的鉴权、服务–服务的鉴权等多种鉴权场景。比如用户A访问User Service，A如果未登录，则首先需要登录，请求获取授权token。获取token之后，A将携带着token去请求访问某个文件，这样就需要对A的身份进行校验，并且A可以访问该文件。为了适应架构的变化、需求的变化，auth权限模块被单独出来作为一个基础的微服务系统，为其他业务service提供服务。 2. 系统架构的变更单体应用架构到分布式架构，简化的权限部分变化如下面两图所示。（1）单体应用简化版架构图：（2）分布式应用简化版架构图： 分布式架构，特别是微服务架构的优点是可以清晰的划分出业务逻辑来，让每个微服务承担职责单一的功能，毕竟越简单的东西越稳定。 但是，微服务也带来了很多的问题。比如完成一个业务操作，需要跨很多个微服务的调用，那么如何用权限系统去控制用户对不同微服务的调用，对我们来说是个挑战。当业务微服务的调用接入权限系统后，不能拖累它们的吞吐量，当权限系统出现问题后，不能阻塞它们的业务调用进度，当然更不能改变业务逻辑。新的业务微服务快速接入权限系统相对容易把控，那么对于公司已有的微服务，如何能不改动它们的架构方式的前提下，快速接入，对我们来说，也是一大挑战。 3. 技术方案这主要包括两方面需求：其一是认证与鉴权，对于请求的用户身份的授权以及合法性鉴权；其二是API级别的操作权限控制，这个在第一点之后，当鉴定完用户身份合法之后，对于该用户的某个具体请求是否具有该操作执行权限进行校验。 3.1 认证与鉴权对于第一个需求，笔者调查了一些实现方案： 分布式Session方案分布式会话方案原理主要是将关于用户认证的信息存储在共享存储中，且通常由用户会话作为 key 来实现的简单分布式哈希映射。当用户访问微服务时，用户数据可以从共享存储中获取。在某些场景下，这种方案很不错，用户登录状态是不透明的。同时也是一个高可用且可扩展的解决方案。这种方案的缺点在于共享存储需要一定保护机制，因此需要通过安全链接来访问，这时解决方案的实现就通常具有相当高的复杂性了。 基于OAuth2 Token方案随着 Restful API、微服务的兴起，基于Token的认证现在已经越来越普遍。Token和Session ID 不同，并非只是一个 key。Token 一般会包含用户的相关信息，通过验证 Token 就可以完成身份校验。用户输入登录信息，发送到身份认证服务进行认证。AuthorizationServer验证登录信息是否正确，返回用户基础信息、权限范围、有效时间等信息，客户端存储接口。用户将 Token 放在 HTTP 请求头中，发起相关 API 调用。被调用的微服务，验证Token。ResourceServer返回相关资源和数据。 这边选用了第二种方案，基于OAuth2 Token认证的好处如下： 服务端无状态：Token 机制在服务端不需要存储 session 信息，因为 Token 自身包含了所有用户的相关信息。 性能较好，因为在验证 Token 时不用再去访问数据库或者远程服务进行权限校验，自然可以提升不少性能。 现在很多应用都是同时面向移动端和web端，OAuth2 Token机制可以支持移动设备。 OAuth2与Spring Security结合使用，有提供很多开箱即用的功能，大多特性都可以通过配置灵活的变更。 最后一点，也很重要，Spring Security OAuth2的文档写得较为详细。 oauth2根据使用场景不同，分成了4种模式： 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 对于上述oauth2四种模式不熟的同学，可以自行百度oauth2，阮一峰的文章有解释。常使用的是password模式和client模式。 3.2 操作权限控制对于第二个需求，笔者主要看了Spring Security和Shiro。 ShiroShiro是一个强大而灵活的开源安全框架，能够非常清晰的处理认证、授权、管理会话以及密码加密。Shiro很容易入手，上手快控制粒度可糙可细。自由度高，Shiro既能配合Spring使用也可以单独使用。 Spring SecuritySpring社区生态很强大。除了不能脱离Spring，Spring Security具有Shiro所有的功能。而且Spring Security对Oauth、OpenID也有支持,Shiro则需要自己手动实现。Spring Security的权限细粒度更高。但是Spring Security太过复杂。 看了下网上的评论，貌似一边倒向Shiro。大部分人提出的Spring Security问题就是比较复杂难懂，文档太长。不管是Shiro还是Spring Security，其实现都是基于过滤器，对于自定义实现过滤器，我想对于很多开发者并不是很难，但是这需要团队花费时间与封装可用的jar包出来，对于后期维护和升级，以及功能的扩展。很多中小型公司并不一定具有这样的时间和人力投入这件事。笔者综合评估了下复杂性与所要实现的权限需求，以及上一个需求调研的结果，既然Spring Security功能足够强大且稳定，最终选择了Spring Security。 4. 系统架构4.1 组件Auth系统的最终使用组件如下： 123OAuth2.0 JWT TokenSpring SecuritySpring boot 4.2 步骤主要步骤为： 配置资源服务器和认证服务器 配置Spring Security 上述步骤比较笼统，对于前面小节提到的需求，属于Auth系统的主要内容，笔者后面会另写文章对应讲解。 4.3 endpoint提供的endpoint： 1234567/oauth/token?grant_type=password #请求授权token/oauth/token?grant_type=refresh_token #刷新token/oauth/check_token #校验token/logout #注销token及权限相关信息 4.4 maven依赖主要的jar包，pom.xml文件如下： 12345678910111213141516171819202122232425262728293031323334&lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt; &lt;version&gt;1.2.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;version&gt;1.2.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; 4.5 AuthorizationServer配置文件AuthorizationServer配置主要是覆写如下的三个方法，分别针对endpoints、clients、security配置。 1234567891011121314151617181920@Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &#123; security.tokenKeyAccess(\"permitAll()\").checkTokenAccess(\"isAuthenticated()\"); &#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; //配置客户端认证 clients.withClientDetails(clientDetailsService(dataSource)); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; //配置token的数据源、自定义的tokenServices等信息 endpoints.authenticationManager(authenticationManager) .tokenStore(tokenStore(dataSource)) .tokenServices(authorizationServerTokenServices()) .accessTokenConverter(accessTokenConverter()) .exceptionTranslator(webResponseExceptionTranslator); &#125; 4.6 ResourceServer配置资源服务器的配置，覆写了默认的配置。为了支持logout，这边自定义了一个CustomLogoutHandler并且将logoutSuccessHandler指定为返回http状态的HttpStatusReturningLogoutSuccessHandler。 1234567891011121314@Override public void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .requestMatchers().antMatchers(\"/**\") .and().authorizeRequests() .antMatchers(\"/**\").permitAll() .anyRequest().authenticated() .and().logout() .logoutUrl(\"/logout\") .clearAuthentication(true) .logoutSuccessHandler(new HttpStatusReturningLogoutSuccessHandler()) .addLogoutHandler(customLogoutHandler()); 4.7 执行endpoint 首先执行获取授权的endpoint。 123456789101112method: post url: http://localhost:12000/oauth/token?grant_type=passwordheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=, Content-Type: application/x-www-form-urlencoded&#125;body:&#123; username: keets, password: ***&#125; 上述构造了一个post请求，具体请求写得很详细。username和password是客户端提供给服务器进行校验用户身份信息。header里面的Authorization是存放的clientId和clientSecret经过编码的字符串。返回结果如下： 12345678910&#123; &quot;access_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ.5ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeE&quot;, &quot;expires_in&quot;: 43195, &quot;scope&quot;: &quot;all&quot;, &quot;X-KEETS-UserId&quot;: &quot;d6448c24-3c4c-4b80-8372-c2d61868f8c6&quot;, &quot;jti&quot;: &quot;bad72b19-d9f3-4902-affa-0430e7db79ed&quot;, &quot;X-KEETS-ClientId&quot;: &quot;frontend&quot;&#125; 可以看到在用户名密码通过校验后，客户端收到了授权服务器的response，主要包括access token、refresh token。并且表明token的类型为bearer，过期时间expires_in。笔者在jwt token中加入了自定义的info为UserId和ClientId。 2.鉴权的endpoint 1234567891011method: post url: http://localhost:12000/oauth/check_tokenheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=, Content-Type: application/x-www-form-urlencoded&#125;body:&#123; token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsImV4cCI6MTUwODQ0Nzc1NiwidXNlcl9uYW1lIjoia2VldHMiLCJqdGkiOiJiYWQ3MmIxOS1kOWYzLTQ5MDItYWZmYS0wNDMwZTdkYjc5ZWQiLCJjbGllbnRfaWQiOiJmcm9udGVuZCIsInNjb3BlIjpbImFsbCJdfQ.5ZNVN8TLavgpWy8KZQKArcbj7ItJLLaY1zBRaAgMjdo&#125; 上面即为check_token请求的详细信息。需要注意的是，笔者将刚刚授权的token放在了body里面，这边可以有多种方法，此处不扩展。 123456789101112&#123; &quot;X-KEETS-UserId&quot;: &quot;d6448c24-3c4c-4b80-8372-c2d61868f8c6&quot;, &quot;user_name&quot;: &quot;keets&quot;, &quot;scope&quot;: [ &quot;all&quot; ], &quot;active&quot;: true, &quot;exp&quot;: 1508447756, &quot;X-KEETS-ClientId&quot;: &quot;frontend&quot;, &quot;jti&quot;: &quot;bad72b19-d9f3-4902-affa-0430e7db79ed&quot;, &quot;client_id&quot;: &quot;frontend&quot;&#125; 校验token合法后，返回的response如上所示。在response中也是展示了相应的token中的基本信息。 3.刷新token由于token的时效一般不会很长，而refresh token一般周期会很长，为了不影响用户的体验，可以使用refresh token去动态的刷新token。 123456method: post url: http://localhost:12000/oauth/token?grant_type=refresh_token&amp;refresh_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLUtFRVRTLVVzZXJJZCI6ImQ2NDQ4YzI0LTNjNGMtNGI4MC04MzcyLWMyZDYxODY4ZjhjNiIsInVzZXJfbmFtZSI6ImtlZXRzIiwic2NvcGUiOlsiYWxsIl0sImF0aSI6ImJhZDcyYjE5LWQ5ZjMtNDkwMi1hZmZhLTA0MzBlN2RiNzllZCIsImV4cCI6MTUxMDk5NjU1NiwianRpIjoiYWE0MWY1MjctODE3YS00N2UyLWFhOTgtZjNlMDZmNmY0NTZlIiwiY2xpZW50X2lkIjoiZnJvbnRlbmQifQ.mICT1-lxOAqOU9M-Ud7wZBb4tTux6OQWouQJ2nn1DeEheader:&#123; Authorization: Basic ZnJvbnRlbmQ6ZnJvbnRlbmQ=&#125; 其response和/oauth/token得到正常的相应是一样的，此处不再列出。 4.注销token 123456method: geturl: http://localhost:9000/logoutheader:&#123; Authorization: bearereyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1MDgzMzkwNTQsIlgtU0lNVS1Vc2VySWQiOiIwOGFhMTYxYi1lYjI3LTQ2NjAtYjA1MC1lMDc5YTJiODBhODMiLCJ1c2VyX25hbWUiOiJrZWV0cyIsImp0aSI6IjJhNTQ4NjY2LTRjNzEtNGEzNi1hZmY0LTMwZTI1Mjc0ZjQxZSIsImNsaWVudF9pZCI6ImZyb250ZW5kIiwic2NvcGUiOlsibWVua29yIl19.rA-U2iXnjH0AdPaGuvSEJH3bTth6AT3oQrGsKIams30&#125; 注销成功则会返回200，注销端点主要是将token和SecurityContextHolder进行清空。 5. 总结本文是《认证鉴权与API权限控制在微服务架构中的设计与实现》系列文章的总述，从遇到的问题着手，介绍了项目的背景。通过调研现有的技术，并结合当前项目的实际，确定了技术选型。最后对于系统的最终的实现进行展示。后面将从实现的细节，讲解本系统的实现。敬请期待后续文章。 参考 理解OAuth 2.0 微服务API级权限的技术架构 微服务架构下的安全认证与鉴权","categories":[{"name":"Security","slug":"Security","permalink":"http://blueskykong.com/categories/Security/"}],"tags":[{"name":"OAuth2","slug":"OAuth2","permalink":"http://blueskykong.com/tags/OAuth2/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"http://blueskykong.com/tags/Spring-Security/"}]},{"title":"消息中间件NSQ深入与实践","slug":"nsq","date":"2017-10-07T16:00:00.000Z","updated":"2017-11-14T02:36:27.000Z","comments":true,"path":"2017/10/08/nsq/","link":"","permalink":"http://blueskykong.com/2017/10/08/nsq/","excerpt":"","text":"1. 介绍最近在研究一些消息中间件，常用的MQ如RabbitMQ,ActiveMQ,Kafka等。NSQ是一个基于Go语言的分布式实时消息平台，它基于MIT开源协议发布，由bitly公司开源出来的一款简单易用的消息中间件。官方和第三方还为NSQ开发了众多客户端功能库，如官方提供的基于HTTP的nsqd、Go客户端go-nsq、Python客户端pynsq、基于Node.js的JavaScript客户端nsqjs、异步C客户端libnsq、Java客户端nsq-java以及基于各种语言的众多第三方客户端功能库。 1.1 Features1). DistributedNSQ提供了分布式的，去中心化，且没有单点故障的拓扑结构，稳定的消息传输发布保障，能够具有高容错和HA（高可用）特性。2). Scalable易于扩展NSQ支持水平扩展，没有中心化的brokers。内置的发现服务简化了在集群中增加节点。同时支持pub-sub和load-balanced 的消息分发。3). Ops FriendlyNSQ非常容易配置和部署，生来就绑定了一个管理界面。二进制包没有运行时依赖。官方有Docker image。4.Integrated高度集成官方的 Go 和 Python库都有提供。而且为大多数语言提供了库。 1.2 组件 Topic ：一个topic就是程序发布消息的一个逻辑键，当程序第一次发布消息时就会创建topic。 Channels ：channel与消费者相关，是消费者之间的负载均衡，channel在某种意义上来说是一个“队列”。每当一个发布者发送一条消息到一个topic，消息会被复制到所有消费者连接的channel上，消费者通过这个特殊的channel读取消息，实际上，在消费者第一次订阅时就会创建channel。Channel会将消息进行排列，如果没有消费者读取消息，消息首先会在内存中排队，当量太大时就会被保存到磁盘中。 Messages：消息构成了我们数据流的中坚力量，消费者可以选择结束消息，表明它们正在被正常处理，或者重新将他们排队待到后面再进行处理。每个消息包含传递尝试的次数，当消息传递超过一定的阀值次数时，我们应该放弃这些消息，或者作为额外消息进行处理。 nsqd：nsqd 是一个守护进程，负责接收，排队，投递消息给客户端。它可以独立运行，不过通常它是由 nsqlookupd 实例所在集群配置的（它在这能声明 topics 和 channels，以便大家能找到）。 nsqlookupd：nsqlookupd 是守护进程负责管理拓扑信息。客户端通过查询 nsqlookupd 来发现指定话题（topic）的生产者，并且 nsqd 节点广播话题（topic）和通道（channel）信息。有两个接口：TCP 接口，nsqd 用它来广播。HTTP 接口，客户端用它来发现和管理。 nsqadmin：nsqadmin 是一套 WEB UI，用来汇集集群的实时统计，并执行不同的管理任务。 常用工具类： nsq_to _file：消费指定的话题（topic）/通道（channel），并写到文件中，有选择的滚动和/或压缩文件。 nsq_to _http：消费指定的话题（topic）/通道（channel）和执行 HTTP requests (GET/POST) 到指定的端点。 nsq_to _nsq：消费者指定的话题/通道和重发布消息到目的地 nsqd 通过 TCP。 1.3 拓扑结构NSQ推荐通过他们相应的nsqd实例使用协同定位发布者，这意味着即使面对网络分区，消息也会被保存在本地，直到它们被一个消费者读取。更重要的是，发布者不必去发现其他的nsqd节点，他们总是可以向本地实例发布消息。 首先，一个发布者向它的本地nsqd发送消息，要做到这点，首先要先打开一个连接，然后发送一个包含topic和消息主体的发布命令，在这种情况下，我们将消息发布到事件topic上以分散到我们不同的worker中。事件topic会复制这些消息并且在每一个连接topic的channel上进行排队，在我们的案例中，有三个channel，它们其中之一作为档案channel。消费者会获取这些消息并且上传到S3。 每个channel的消息都会进行排队，直到一个worker把他们消费，如果此队列超出了内存限制，消息将会被写入到磁盘中。Nsqd节点首先会向nsqlookup广播他们的位置信息，一旦它们注册成功，worker将会从nsqlookup服务器节点上发现所有包含事件topic的nsqd节点。 然后每个worker向每个nsqd主机进行订阅操作，用于表明worker已经准备好接受消息了。这里我们不需要一个完整的连通图，但我们必须要保证每个单独的nsqd实例拥有足够的消费者去消费它们的消息，否则channel会被队列堆着。 2. Internals2.1 消息传递担保NSQ 保证消息将交付至少一次，虽然消息可能是重复的。消费者应该关注到这一点，删除重复数据或执行idempotent等操作。这个担保是作为协议和工作流的一部分，工作原理如下（假设客户端成功连接并订阅一个话题）：1）客户表示已经准备好接收消息2）NSQ 发送一条消息，并暂时将数据存储在本地（在 re-queue 或 timeout）3）客户端回复 FIN（结束）或 REQ（重新排队）分别指示成功或失败。如果客户端没有回复, NSQ 会在设定的时间超时，自动重新排队消息这确保了消息丢失唯一可能的情况是不正常结束 nsqd 进程。在这种情况下，这是在内存中的任何信息（或任何缓冲未刷新到磁盘）都将丢失。如何防止消息丢失是最重要的，即使是这个意外情况可以得到缓解。一种解决方案是构成冗余 nsqd对（在不同的主机上）接收消息的相同部分的副本。因为你实现的消费者是幂等的，以两倍时间处理这些消息不会对下游造成影响，并使得系统能够承受任何单一节点故障而不会丢失信息。 2.2 简化配置和管理单个 nsqd 实例被设计成可以同时处理多个数据流。流被称为“话题”和话题有 1 个或多个“通道”。每个通道都接收到一个话题中所有消息的拷贝。在实践中，一个通道映射到下行服务消费一个话题。话题和通道都没有预先配置。话题由第一次发布消息到命名的话题或第一次通过订阅一个命名话题来创建。通道被第一次订阅到指定的通道创建。话题和通道的所有缓冲的数据相互独立，防止缓慢消费者造成对其他通道的积压（同样适用于话题级别）。一个通道一般会有多个客户端连接。假设所有已连接的客户端处于准备接收消息的状态，每个消息将被传递到一个随机的客户端。nsqlookupd，它提供了一个目录服务，消费者可以查找到提供他们感兴趣订阅话题的 nsqd 地址 。在配置方面，把消费者与生产者解耦开（它们都分别只需要知道哪里去连接 nsqlookupd 的共同实例，而不是对方），降低复杂性和维护。在更底的层面，每个 nsqd 有一个与 nsqlookupd 的长期 TCP 连接，定期推动其状态。这个数据被 nsqlookupd 用于给消费者通知 nsqd 地址。对于消费者来说，一个暴露的 HTTP /lookup 接口用于轮询。为话题引入一个新的消费者，只需启动一个配置了 nsqlookup 实例地址的 NSQ 客户端。无需为添加任何新的消费者或生产者更改配置，大大降低了开销和复杂性。 2.3 消除单点故障NSQ被设计以分布的方式被使用。nsqd 客户端（通过 TCP ）连接到指定话题的所有生产者实例。没有中间人，没有消息代理，也没有单点故障。这种拓扑结构消除单链，聚合，反馈。相反，你的消费者直接访问所有生产者。从技术上讲，哪个客户端连接到哪个 NSQ 不重要，只要有足够的消费者连接到所有生产者，以满足大量的消息，保证所有东西最终将被处理。对于 nsqlookupd，高可用性是通过运行多个实例来实现。他们不直接相互通信和数据被认为是最终一致。消费者轮询所有的配置的 nsqlookupd 实例和合并 response。失败的，无法访问的，或以其他方式故障的节点不会让系统陷于停顿。 2.4 效率对于数据的协议，通过推送数据到客户端最大限度地提高性能和吞吐量的，而不是等待客户端拉数据。这个概念，称之为 RDY 状态，基本上是客户端流量控制的一种形式。当客户端连接到 nsqd 和并订阅到一个通道时，它被放置在一个 RDY 为 0 状态。这意味着，还没有信息被发送到客户端。当客户端已准备好接收消息发送，更新它的命令 RDY 状态到它准备处理的数量，比如 100。无需任何额外的指令，当 100 条消息可用时，将被传递到客户端（服务器端为那个客户端每次递减 RDY 计数）。客户端库的被设计成在 RDY 数达到配置 max-in-flight 的 25% 发送一个命令来更新 RDY 计数（并适当考虑连接到多个 nsqd 情况下，适当地分配）。 2.5 心跳和超时NSQ 的 TCP 协议是面向 push 的。在建立连接，握手，和订阅后，消费者被放置在一个为 0 的 RDY 状态。当消费者准备好接收消息，它更新的 RDY 状态到准备接收消息的数量。NSQ 客户端库不断在幕后管理，消息控制流的结果。每隔一段时间，nsqd 将发送一个心跳线连接。客户端可以配置心跳之间的间隔，但 nsqd 会期待一个回应在它发送下一个心掉之前。组合应用级别的心跳和 RDY 状态，避免头阻塞现象，也可能使心跳无用（即，如果消费者是在后面的处理消息流的接收缓冲区中，操作系统将被填满，堵心跳）为了保证进度，所有的网络 IO 时间上限势必与配置的心跳间隔相关联。这意味着，你可以从字面上拔掉之间的网络连接 nsqd 和消费者，它会检测并正确处理错误。当检测到一个致命错误，客户端连接被强制关闭。在传输中的消息会超时而重新排队等待传递到另一个消费者。最后，错误会被记录并累计到各种内部指标。 2.6 分布式因为NSQ没有在守护程序之间共享信息，所以它从一开始就是为了分布式操作而生。个别的机器可以随便宕机随便启动而不会影响到系统的其余部分，消息发布者可以在本地发布，即使面对网络分区。这种“分布式优先”的设计理念意味着NSQ基本上可以永远不断地扩展，需要更高的吞吐量？那就添加更多的nsqd吧。唯一的共享状态就是保存在lookup节点上，甚至它们不需要全局视图，配置某些nsqd注册到某些lookup节点上这是很简单的配置，唯一关键的地方就是消费者可以通过lookup节点获取所有完整的节点集。清晰的故障事件——NSQ在组件内建立了一套明确关于可能导致故障的的故障权衡机制，这对消息传递和恢复都有意义。虽然它们可能不像Kafka系统那样提供严格的保证级别，但NSQ简单的操作使故障情况非常明显。 2.7 no replication不像其他的队列组件，NSQ并没有提供任何形式的复制和集群，也正是这点让它能够如此简单地运行，但它确实对于一些高保证性高可靠性的消息发布没有足够的保证。我们可以通过降低文件同步的时间来部分避免，只需通过一个标志配置，通过EBS支持我们的队列。但是这样仍然存在一个消息被发布后马上死亡，丢失了有效的写入的情况。 2.8 没有严格的顺序虽然Kafka由一个有序的日志构成，但NSQ不是。消息可以在任何时间以任何顺序进入队列。在我们使用的案例中，这通常没有关系，因为所有的数据都被加上了时间戳，但它并不适合需要严格顺序的情况。 2.9 无数据重复删除功能NSQ对于超时系统，它使用了心跳检测机制去测试消费者是否存活还是死亡。很多原因会导致我们的consumer无法完成心跳检测，所以在consumer中必须有一个单独的步骤确保幂等性。 3. 实践安装过程本文将nsq集群具体的安装过程略去，大家可以自行参考官网，比较简单。这部分介绍下笔者实验的拓扑，以及nsqadmin的相关信息。 3.1 拓扑结构 实验采用3台NSQD服务，2台LOOKUPD服务。采用官方推荐的拓扑，消息发布的服务和NSQD在一台主机。一共5台机器。NSQ基本没有配置文件，配置通过命令行指定参数。主要命令如下:LOOKUPD命令 1bin/nsqlookupd NSQD命令 1bin/nsqd --lookupd-tcp-address=172.16.30.254:4160 -broadcast-address=172.16.30.254 1bin/nsqadmin --lookupd-http-address=172.16.30.254:4161 工具类，消费后存储到本地文件。 1bin/nsq_to_file --topic=newtest --channel=test --output-dir=/tmp --lookupd-http-address=172.16.30.254:4161 发布一条消息1curl -d 'hello world 5' 'http://172.16.30.254:4151/put?topic=test' 3.2 nsqadmin对Streams的详细信息进行查看，包括NSQD节点，具体的channel，队列中的消息数，连接数等信息。 列出所有的NSQD节点: 消息的统计: lookup主机的列表: 4. 总结NSQ基本核心就是简单性，是一个简单的队列，这意味着它很容易进行故障推理和很容易发现bug。消费者可以自行处理故障事件而不会影响系统剩下的其余部分。 事实上，简单性是我们决定使用NSQ的首要因素，这方便与我们的许多其他软件一起维护，通过引入队列使我们得到了堪称完美的表现，通过队列甚至让我们增加了几个数量级的吞吐量。越来越多的consumer需要一套严格可靠性和顺序性保障，这已经超过了NSQ提供的简单功能。 结合我们的业务系统来看，对于我们所需要传输的发票消息，相对比较敏感，无法容忍某个nsqd宕机，或者磁盘无法使用的情况，该节点堆积的消息无法找回。这是我们没有选择该消息中间件的主要原因。简单性和可靠性似乎并不能完全满足。相比Kafka，ops肩负起更多负责的运营。另一方面，它拥有一个可复制的、有序的日志可以提供给我们更好的服务。但对于其他适合NSQ的consumer，它为我们服务的相当好，我们期待着继续巩固它的坚实的基础。 ps: 本文首发于笔者的csdn博客，此处将其加入个人的博客。 参考 NSQ：分布式的实时消息平台 NSQ - NYC Golang Meetup NSQ Docs","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blueskykong.com/categories/中间件/"}],"tags":[{"name":"Cluster","slug":"Cluster","permalink":"http://blueskykong.com/tags/Cluster/"},{"name":"mq","slug":"mq","permalink":"http://blueskykong.com/tags/mq/"}]},{"title":"Lombok使用与原理","slug":"lombok","date":"2017-10-05T16:00:00.000Z","updated":"2018-01-28T15:10:35.000Z","comments":true,"path":"2017/10/06/lombok/","link":"","permalink":"http://blueskykong.com/2017/10/06/lombok/","excerpt":"","text":"1. Lombok简介首先Lombok是一款Java IDE的应用工具插件，一个可以通过简单的注解形式来帮助我们简化消除一些必须有但显得很臃肿的Java代码的工具，比如属性的构造器、getter、setter、equals、hashcode、toString方法。结合IDE，通过使用对应的注解，可以在编译源码的时候生成对应的方法。官方地址：https://projectlombok.org/。 虽然上述的那些常用方法IDE都能生成，但是lombok更加简洁与方便，能够达到的效果就是在源码中不需要写一些通用的方法，但是在编译生成的字节码文件中会帮我们生成这些方法，这就是lombok的神奇作用。 2. 安装2.1 插件安装笔者主要使用的IDE是Intellij idea，编译器需要在 1preference-&gt;plugins-&gt;Browse repositories 搜索lombok，然后安装plugins，需要稍等片刻。笔者截图已经安装好。 2.2 添加jar包在项目中添加lombok的jar包，笔者用的是maven，所以在pom文件中添加了如下的依赖。gradle使用见官网。 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.16&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3. 使用lombok主要通过注解起作用，详细的注解见Lombok features。 With Lombok: 12345678910111213import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.io.Serializable;@Data@AllArgsConstructorpublic class UserEntity implements Serializable &#123; private long userId; private String userName; private String sex;&#125; 编译后： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import java.beans.ConstructorProperties;import java.io.Serializable;public class UserEntity implements Serializable &#123; private long userId; private String userName; private String sex; public long getUserId() &#123; return this.userId; &#125; public String getUserName() &#123; return this.userName; &#125; public String getSex() &#123; return this.sex; &#125; public void setUserId(long userId) &#123; this.userId = userId; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public boolean equals(Object o) &#123; if(o == this) &#123; return true; &#125; else if(!(o instanceof UserEntity)) &#123; return false; &#125; else &#123; UserEntity other = (UserEntity)o; if(!other.canEqual(this)) &#123; return false; &#125; else if(this.getUserId() != other.getUserId()) &#123; return false; &#125; else &#123; Object this$userName = this.getUserName(); Object other$userName = other.getUserName(); if(this$userName == null) &#123; if(other$userName != null) &#123; return false; &#125; &#125; else if(!this$userName.equals(other$userName)) &#123; return false; &#125; Object this$sex = this.getSex(); Object other$sex = other.getSex(); if(this$sex == null) &#123; if(other$sex != null) &#123; return false; &#125; &#125; else if(!this$sex.equals(other$sex)) &#123; return false; &#125; return true; &#125; &#125; &#125; protected boolean canEqual(Object other) &#123; return other instanceof UserEntity; &#125; public int hashCode() &#123; int PRIME = true; int result = 1; long $userId = this.getUserId(); int result = result * 59 + (int)($userId &gt;&gt;&gt; 32 ^ $userId); Object $userName = this.getUserName(); result = result * 59 + ($userName == null?43:$userName.hashCode()); Object $sex = this.getSex(); result = result * 59 + ($sex == null?43:$sex.hashCode()); return result; &#125; public String toString() &#123; return \"UserEntity(userId=\" + this.getUserId() + \", userName=\" + this.getUserName() + \", sex=\" + this.getSex() + \")\"; &#125; @ConstructorProperties(&#123;\"userId\", \"userName\", \"sex\"&#125;) public UserEntity(long userId, String userName, String sex) &#123; this.userId = userId; this.userName = userName; this.sex = sex; &#125;&#125; 这边介绍笔者经常使用到的注解。 val，用在局部变量前面，相当于将变量声明为final @Value用在类上，是@Data的不可变形式，相当于为属性添加final声明，只提供getter方法，而不提供setter方法 @Data@ToString, @EqualsAndHashCode, 所有属性的@Getter, 所有non-final属性的@Setter和@RequiredArgsConstructor的组合，通常情况下，我们使用这个注解就足够了。 @NoArgsConstructor无参构造器 @AllArgsConstructor全参构造器 @ToString 生成toString方法，默认情况下，会输出类名、所有属性，属性会按照顺序输出，以逗号分割。 @EqualsAndHashCode默认情况下，会使用所有非瞬态(non-transient)和非静态(non-static)字段来生成equals和hascode方法，也可以指定具体使用哪些属性。 @Getter / @Setter上面已经说过，一般用@data就不用额外加这个注解了。可以作用在类上和属性上，放在类上，会对所有的非静态(non-static)属性生成Getter/Setter方法，放在属性上，会对该属性生成Getter/Setter方法。并可以指定Getter/Setter方法的访问级别。 @NonNull，给方法参数增加这个注解会自动在方法内对该参数进行是否为空的校验，如果为空，则抛出NPE（NullPointerException） @Cleanup自动管理资源，用在局部变量之前，在当前变量范围内即将执行完毕退出之前会自动清理资源，自动生成try-finally这样的代码来关闭流 @Log根据不同的注解生成不同类型的log对象，但是实例名称都是log，有7种可选实现类： 1). @Log4j 1private static final org.apache.log4j.Logger log = org.apache.log4j.Logger.getLogger(LogExample.class); 2). @Log4j2 1private static final org.apache.logging.log4j.Logger log = org.apache.logging.log4j.LogManager.getLogger(LogExample.class); 3). @Slf4j 1private static final org.slf4j.Logger log = org.slf4j.LoggerFactory.getLogger(LogExample.class); 4). @XSlf4j 1private static final org.slf4j.ext.XLogger log = org.slf4j.ext.XLoggerFactory.getXLogger(LogExample.class); 5). @CommonsLog 1private static final org.apache.commons.logging.Log log = org.apache.commons.logging.LogFactory.getLog(LogExample.class); 6). @JBossLog 1private static final org.jboss.logging.Logger log = org.jboss.logging.Logger.getLogger(LogExample.class); 7). @Log private static final java.util.logging.Logger log = java.util.logging.Logger.getLogger(LogExample.class.getName()); 默认情况下，logger的名字将会是被@Log注解的那个类的名字。当然这也可以被个性化命名，通过topic参数，如@XSlf4j(topic=&quot;reporting&quot;)。 4. 原理lombok 主要通过注解生效，自jdk5引入注解，由两种解析方式。第一种是运行时解析，@Retention(RetentionPolicy.RUNTIME), 定义注解的保留策略，这样可以通过反射拿到该注解。另一种是编译时解析，有两种机制。 Annotation Processing Tool，apt自JDK5产生，JDK7已标记为过期，不推荐使用，JDK8中已彻底删除，自JDK6开始，可以使用Pluggable Annotation Processing API来替换它，apt被替换主要有2点原因。api都在com.sun.mirror非标准包下，还有就是没有集成到javac中，需要额外运行。 Pluggable Annotation Processing APIlombok使用这种方式实现，基于JSR 269，自JDK6加入，作为apt的替代方案，它解决了apt的两个问题，javac在执行的时候会调用实现了该API的程序，这样我们就可以对编译器做一些增强，这时javac执行的过程如下： 5. 总结这篇文章主要讲解了lombok的入门与使用。介绍了一些常用的lombok注解，大大简化了我们的开发工作和代码的简洁性。当然，lombok不支持多种参数构造器的重载，工具毕竟是工具，我感觉并不会有非常完美适合每个人的工具。最后，我个人还是很推荐这款插件的，毕竟我很懒，😆。 参考 Lombok Docs Java奇淫巧技之Lombok","categories":[{"name":"Utils","slug":"Utils","permalink":"http://blueskykong.com/categories/Utils/"}],"tags":[{"name":"Lombok","slug":"Lombok","permalink":"http://blueskykong.com/tags/Lombok/"}]},{"title":"Redis Cluster深入与实践","slug":"rediscluster","date":"2017-09-28T16:00:00.000Z","updated":"2017-11-14T02:36:51.000Z","comments":true,"path":"2017/09/29/rediscluster/","link":"","permalink":"http://blueskykong.com/2017/09/29/rediscluster/","excerpt":"","text":"1. redis介绍www.redis.ioredis是一个基于内存的K-V存储数据库。支持存储的类型有string,list,set,zset(sorted set),hash等。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。redis支持各种不同方式的排序。保证效率的情况下，数据缓存在内存中。同时redis提供了持久化策略，不同的策略触发同步到磁盘或者把修改操作写入追加的记录文件，在此基础上实现了master-slave。 它是一个高性能的存储系统，能支持超过 100K+ 每秒的读写频率。同时还支持消息的发布/订阅，从而让你在构建高性能消息队列系统时多了另一种选择。 Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。 2. 主从redis支持master-slave模式，一主多从，redis server可以设置另外多个redis server为slave，从机同步主机的数据。配置后，读写分离，主机负责读写服务，从机只负责读。减轻主机的压力。redis实现的是最终会一致性，具体选择强一致性还是弱一致性，取决于业务场景。redis 主从同步有两种方式（或者所两个阶段）：全同步和部分同步。 主从刚刚连接的时候，进行全同步；全同步结束后，进行部分同步。当然，如果有需要，slave 在任何时候都可以发起全同步。redis 策略是，无论如何，首先会尝试进行部分同步，如不成功，要求从机进行全同步，并启动 BGSAVE……BGSAVE 结束后，传输 RDB 文件；如果成功，允许从机进行部分同步，并传输积压空间中的数据。简单来说，主从同步就是 RDB 文件的上传下载；主机有小部分的数据修改，就把修改记录传播给每个从机。 3. redis集群主从模式存在的问题是，master宕机之后，从机只能读，不可写，不能保证高可用。redis集群技术是构建高性能网站架构的重要手段，试想在网站承受高并发访问压力的同时，还需要从海量数据中查询出满足条件的数据，并快速响应，我们必然想到的是将数据进行切片，把数据根据某种规则放入多个不同的服务器节点，来降低单节点服务器的压力。 Redis Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。节点之间使用gossip协议传播信息以及发现新节点。 Redis 集群是一个分布式（distributed）、容错（fault-tolerant）的 Redis 实现，集群可以使用的功能是普通单机 Redis 所能使用的功能的一个子集（subset）。 Redis 集群中不存在中心（central）节点或者代理（proxy）节点，集群的其中一个主要设计目标是达到线性可扩展性（linear scalability）。 Redis 集群为了保证一致性（consistency）而牺牲了一部分容错性：系统会在保证对网络断线（net split）和节点失效（node failure）具有有限（limited）抵抗力的前提下，尽可能地保持数据的一致性。 4. 安装部署redis安装较为简单，官网下载压缩包解压。集群模式需要ruby的编译环境，集群最小的配置为3台master，小于3则启动集群报错。redis版本：3.2.4 4.1 主从模式拓扑图 主从模式采用一主三从，主从都配置auth认证，读写分离。主要实验的动作：1）多个app 同时写，测定写速率；2）多个app 同时写，同时有读的进程，测定读写速率；3）master主机宕机，app依然进行读写。 4.2 cluster拓扑图如下 集群模式采用四主四从，也是采用读写分离。主要实验的动作：1）有一个master宕机，观察日志，新的slave成为master；2）master宕机后，重新启动，master成为slave；3）集群全部宕机，redis主机重启，数据未丢失。 5. 原理5.1 一致性filesnapshot:默认redis是会以快照的形式将数据持久化到磁盘,在配置文件中的格式是：save N M表示在N秒之内，redis至少发生M次修改则redis抓快照到磁盘。 工作原理：当redis需要做持久化时，redis会fork一个子进程；子进程将数据写到磁盘上一个临时RDB文件中；当子进程完成写临时文件后，将原来的RDB替换掉，这样的好处就是可以copy-on-write。 Append-only：filesnapshotting方法在redis异常死掉时， 最近的数据会丢失（丢失数据的多少视你save策略的配置），所以这是它最大的缺点，当业务量很大时，丢失的数据是很多的。Append-only方法可 以做到全部数据不丢失，但redis的性能就要差些。AOF就可以做到全程持久化，只需要在配置文件中开启（默认是no），appendonly yes开启AOF之后，redis每执行一个修改数据的命令，都会把它添加到aof文件中，当redis重启时，将会读取AOF文件进行“重放”以恢复到 redis关闭前的最后时刻。 AOF文件刷新的方式，有三种，参考配置参数appendfsync ： appendfsync always每提交一个修改命令都调用fsync刷新到AOF文件，非常非常慢，但也非常安全； appendfsync everysec每秒钟都调用fsync刷新到AOF文件，很快，但可能会丢失一秒以内的数据； appendfsync no依靠OS进行刷新，redis不主动刷新AOF，这样最快，但安全性就差。默认并推荐每秒刷新，这样在速度和安全上都做到了兼顾。 Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力。因此我们可以将Redis的Replication架构视为图结构。 Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求。 Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据。 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成。即便如此，系统的伸缩性还是得到了很大的提高。 Master可以将数据保存操作交给Slaves完成，从而避免了在Master中要有独立的进程来完成此操作。Redis在master是非阻塞模式，也就是说在slave执行数据同步的时候，master是可以接受客户端的请求的，并不影响同步数据的一致性，然而在slave端是阻塞模式的，slave在同步master数据时，并不能够响应客户端的查询。 5.2 Replication的工作原理(1)Slave服务器连接到Master服务器。(2)Slave服务器发送SYCN命令。(3)Master服务器备份数据库到.rdb文件。(4)Master服务器把.rdb文件传输给Slave服务器。(5)Slave服务器把.rdb文件数据导入到数据库中。 在Slave启动并连接到Master之后，它将主动发送一个SYNC命令。此后Master将启动后台存盘进程，同时收集所有接收到的用于修改数据集 的命令，在后台进程执行完毕后，Master将传送整个数据库文件到Slave，以完成一次完全同步。而Slave服务器在接收到数据库文件数据之后将其 存盘并加载到内存中。此后，Master继续将所有已经收集到的修改命令，和新的修改命令依次传送给Slaves，Slave将在本次执行这些数据修改命令，从而达到最终的数据同步。如果Master和Slave之间的链接出现断连现象，Slave可以自动重连Master，但是在连接成功之后，一次完全同步将被自动执行。 5.3 一致性哈希集群要实现的目的是要将不同的 key 分散放置到不同的 redis 节点，这里我们需要一个规则或者算法，通常的做法是获取 key 的哈希值，然后根据节点数来求模，但这种做法有其明显的弊端，当我们需要增加或减少一个节点时，会造成大量的 key 无法命中，这种比例是相当高的，所以就有人提出了一致性哈希的概念。一致性哈希有四个重要特征： 均衡性：也有人把它定义为平衡性，是指哈希的结果能够尽可能分布到所有的节点中去，这样可以有效的利用每个节点上的资源。 单调性：对于单调性有很多翻译让我非常的不解，而我想要的是当节点数量变化时哈希的结果应尽可能的保护已分配的内容不会被重新分派到新的节点。 分散性和负载：这两个其实是差不多的意思，就是要求一致性哈希算法对 key 哈希应尽可能的避免重复。 Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。 使用哈希槽的好处就在于可以方便的添加或移除节点。 当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了； 当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了； 当设置了主从关系后，slave 在第一次连接或者重新连接 master 时，slave 都会发送一条同步指令给 master； master 接到指令后，开始启动后台保存进程保存数据，接着收集所有的数据修改指令。后台保存完了，master 就把这份数据发送给 slave，slave 先把数据保存到磁盘，然后把它加载到内存中，master 接着就把收集的数据修改指令一行一行的发给 slave，slave 接收到之后重新执行该指令，这样就实现了数据同步。 slave 在与 master 失去联系后，自动的重新连接。如果 master 收到了多个 slave 的同步请求，它会执行单个后台保存来为所有的 slave 服务。 5.4 节点失效检测以下是节点失效检查的实现方法： 当一个节点向另一个节点发送 PING 命令，但是目标节点未能在给定的时限内返回 PING 命令的回复时，那么发送命令的节点会将目标节点标记为PFAIL （possible failure，可能已失效）。 等待 PING 命令回复的时限称为“节点超时时限（node timeout）”，是一个节点选项（node-wise setting）。 每次当节点对其他节点发送 PING 命令的时候，它都会随机地广播三个它所知道的节点的信息，这些信息里面的其中一项就是说明节点是否已经被标记为 PFAIL 或者 FAIL 。 当节点接收到其他节点发来的信息时，它会记下那些被其他节点标记为失效的节点。这称为失效报告（failure report）。 如果节点已经将某个节点标记为 PFAIL ，并且根据节点所收到的失效报告显式，集群中的大部分其他主节点也认为那个节点进入了失效状态，那么节点会将那个失效节点的状态标记为 FAIL 。 一旦某个节点被标记为 FAIL ，关于这个节点已失效的信息就会被广播到整个集群，所有接收到这条信息的节点都会将失效节点标记为 FAIL 。 简单来说，一个节点要将另一个节点标记为失效，必须先询问其他节点的意见，并且得到大部分主节点的同意才行。因为过期的失效报告会被移除，所以主节点要将某个节点标记为 FAIL 的话，必须以最近接收到的失效报告作为根据。在以下两种情况中，节点的 FAIL 状态会被移除： 如果被标记为 FAIL 的是从节点，那么当这个节点重新上线时， FAIL 标记就会被移除。保持（retaning）从节点的 FAIL 状态是没有意义的，因为它不处理任何槽，一个从节点是否处于 FAIL 状态，决定了这个从节点在有需要时能否被提升为主节点。 如果一个主节点被打上 FAIL 标记之后，经过了节点超时时限的四倍时间，再加上十秒钟之后，针对这个主节点的槽的故障转移操作仍未完成，并且这个主节点已经重新上线的话，那么移除对这个节点的 FAIL 标记。 在第二种情况中，如果故障转移未能顺利完成，并且主节点重新上线，那么集群就继续使用原来的主节点，从而免去管理员介入的必要。 5.5 从节点选举一旦某个主节点进入 FAIL 状态，如果这个主节点有一个或多个从节点存在，那么其中一个从节点会被升级为新的主节点，而其他从节点则会开始对这个新的主节点进行复制。新的主节点由已下线主节点属下的所有从节点中自行选举产生，以下是选举的条件： 这个节点是已下线主节点的从节点。 已下线主节点负责处理的槽数量非空。 从节点的数据被认为是可靠的，也即是，主从节点之间的复制连接（replication link）的断线时长不能超过节点超时时限（node timeout）乘以REDIS_CLUSTER_SLAVE_VALIDITY_MULT 常量得出的积。 如果一个从节点满足了以上的所有条件，那么这个从节点将向集群中的其他主节点发送授权请求，询问它们，是否允许自己（从节点）升级为新的主节点。如果发送授权请求的从节点满足以下属性，那么主节点将向从节点返回 FAILOVER_AUTH_GRANTED 授权，同意从节点的升级要求： 发送授权请求的是一个从节点，并且它所属的主节点处于 FAIL 状态。 在已下线主节点的所有从节点中，这个从节点的节点 ID 在排序中是最小的。 从节点处于正常的运行状态：它没有被标记为 FAIL 状态，也没有被标记为 PFAIL 状态。 一旦某个从节点在给定的时限内得到大部分主节点的授权，它就会开始执行以下故障转移操作： 通过 PONG 数据包（packet）告知其他节点，这个节点现在是主节点了。 通过 PONG 数据包告知其他节点，这个节点是一个已升级的从节点（promoted slave）。 接管（claiming）所有由已下线主节点负责处理的哈希槽。 显式地向所有节点广播一个 PONG 数据包，加速其他节点识别这个节点的进度，而不是等待定时的 PING / PONG 数据包。 所有其他节点都会根据新的主节点对配置进行相应的更新，特别地： a. 所有被新的主节点接管的槽会被更新。 b. 已下线主节点的所有从节点会察觉到 PROMOTED 标志，并开始对新的主节点进行复制。 c.如果已下线的主节点重新回到上线状态，那么它会察觉到 PROMOTED 标志，并将自身调整为现任主节点的从节点。 在集群的生命周期中，如果一个带有 PROMOTED 标识的主节点因为某些原因转变成了从节点，那么该节点将丢失它所带有的 PROMOTED 标识。 6. 总结Redis集群具有高可用，易于迁移，存取速度快等特点。也可以作为消息队列使用，支持pub/sub模式，具体优缺点总结如下：首先优点: redis 在主节点下线后，从节点会自动提升为主节点，提供服务 redis 宕机节点恢复后，自动会添加到集群中，变成从节点 动态扩展和删除节点，rehash slot的分配，基于桶的数据分布方式大大降低了迁移成本，只需将数据桶从一个Redis Node迁移到另一个Redis Node即可完成迁移。 Redis Cluster使用异步复制。 其缺点为: 由于redis的复制使用异步机制，在自动故障转移的过程中，集群可能会丢失写命令。然而 redis 几乎是同时执行(将命令恢复发送给客户端，以及将命令复制到从节点)这两个操作，所以实际中，命令丢失的窗口非常小。 普通的主从模式支持auth加密认证，虽然比较弱，但写或者读都要通过密码验证，cluster对密码支持不太友好，如果对集群设置密码，那么requirepass和masterauth都需要设置，否则发生主从切换时，就会遇到授权问题，可以模拟并观察日志。 参考资料： www.redis.io redis-cluster研究和使用 Redis Cluster 3.0搭建与使用","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blueskykong.com/categories/中间件/"}],"tags":[{"name":"mq","slug":"mq","permalink":"http://blueskykong.com/tags/mq/"},{"name":"redis","slug":"redis","permalink":"http://blueskykong.com/tags/redis/"}]},{"title":"由Consul谈到Raft","slug":"raft","date":"2017-09-25T08:06:59.000Z","updated":"2017-11-14T02:38:14.000Z","comments":true,"path":"2017/09/25/raft/","link":"","permalink":"http://blueskykong.com/2017/09/25/raft/","excerpt":"","text":"在前一篇文章consul配置与实战中，介绍了consul的一些内幕及consul配置相关，并对项目中的一些实际配置进行展示。这篇文章重点介绍consul中所涉及到的一致性算法raft。 1. 背景分布式系统的一致性是相当重要的，即为CAP理论中的C(Consistency)。一致性又可以分为强一致性和最终一致性。这篇文章重点讨论强一致性算法raft。 Lamport发表Paxos一致性算法从90年提出到现在已经有二十几年了，直到2006年Google的三篇论文初现“云”的端倪，其中的Chubby Lock服务使用Paxos作为Chubby Cell中的一致性算法，Paxos的人气从此一路狂飙。而Paxos流程太过于繁杂实现起来也比较复杂，虽然现在很广泛使用的Zookeeper也是基于Paxos算法来实现，但是Zookeeper使用的ZAB（Zookeeper Atomic Broadcast）协议对Paxos进行了很多的改进与优化，复杂性是制约他发展的一个重要原因。Raft的设计初衷就是易于理解性。 Raft是斯坦福的Diego Ongaro、John Ousterhout两个人以易懂（Understandability）为目标设计的一致性算法，在2013年发布了论文：《In Search of an Understandable Consensus Algorithm》 从2013年发布到现在不过只有两年，到现在已经有了十多种语言的Raft算法实现框架，较为出名的有etcd。 2. Raft详解强调的是易懂（Understandability），Raft和Paxos一样只要保证n/2+1节点正常就能够提供服务；众所周知但问题较为复杂时可以把问题分解为几个小问题来处理，Raft也使用了分而治之的思想把算法流程分为三个子问题：选举（Leader election）、日志复制（Log replication）、安全性（Safety）三个子问题。 2.1 raft基本概念 states 一个raft集群拥有多个server，通常会有5台，这样可以允许系统中两台server宕机。在任何情况下，所有的server只有如下三种状态之一： Leader，负责Client交互和log复制，同一时刻系统中最多存在1个 Follower，被动响应请求RPC，从不主动发起请求RPC Candidate，由Follower向Leader转换的中间状态 在正常的操作流程中，集群中有且只有一个server，其他所有的server都是follower。follower是被动的，他们只是被动地相应Candidate和leader的请求。。leader处理所有的客户端请求，follower自己不处理而是转发给leader。第三种状态是Candidate，用来选举一个新的leader。 Terms Raft将时间划分成任意的长度周期。Terms可以理解为逻辑周期，用连续的整数表示。在分布式环境中，时间同步很重要，同时是一个难题。在Raft中使用了一个可以理解为周期（任期）的概念，用Term作为一个周期，每个Term都是一个连续递增的编号，每一轮选举都是一个Term周期，在一个Term中只能产生一个Leader。 每个term伴随着一次election，一个或多个Candidate试图成为leader，如上图的状态转换。如果某个Candidate赢得了这次election，它将升级为剩余server的leader。在某些election的情形中，会产生耗票（Split Votes）的结果 ，即投票结果无效，随后一次新的term开始。raft确保在某个term至多有一个leader。 如上图所示，时间被划分成多个terms，每个term随着一次election。election完成后，一个leader节点管理整个集群，直至这个term结束。有些election失败了，未能产生一个leader。 2.2 Leader election所有节点都是以follower启动。一个最小的 Raft 集群需要三个参与者，这样才可能投出多数票。初始状态 都是 Follower，然后发起选举这时有三种可能情形发生。如果每方都投给了自己，结果没有任何一方获得多数票。之后每个参与方随机休息一阵（Election Timeout）重新发起投票直到一方获得多数票。这里的关键就是随机 timeout，最先从timeout中恢复发起投票的一方向还在 timeout 中的另外两方请求投票，这时它们就只能投给对方了，很快达成一致。Raft的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为Follower某个节点定时器触发选举后Term递增，状态由Follower转为Candidate，向其他节点发起RequestVote RPC请求，这时候有三种可能的情况发生： 1.该RequestVote请求接收到n/2+1（过半数）个节点的投票，从Candidate转为Leader，向其他节点发送heartBeat以保持Leader的正常运转。 2.在此期间如果收到其他节点发送过来的AppendEntries RPC请求，如该节点的Term大则当前节点转为Follower，否则保持Candidate拒绝该请求。 3.Election timeout发生则Term递增，重新发起选举。 在一个Term期间每个节点只能投票一次，所以当有多个Candidate存在时就会出现每个Candidate发起的选举都存在接收到的投票数都不过半的问题，这时每个Candidate都将Term递增、重启定时器并重新发起选举，由于每个节点中定时器的时间都是随机的，所以就不会多次存在有多个Candidate同时发起投票的问题。 引用一张网上的图片，比较形象，如下图。 2.3 Log replication日志复制主要是用于保证节点的一致性，这阶段所做的操作也是为了保证一致性与高可用性；当Leader选举出来后便开始负责客户端的请求，所有事务（更新操作）请求都必须先经过Leader处理，这些事务请求或说成命令也就是这里说的日志，我们都知道要保证节点的一致性就要保证每个节点都按顺序执行相同的操作序列，日志复制（Log Replication）就是为了保证执行相同的操作序列所做的工作；在Raft中当接收到客户端的日志（事务请求）后先把该日志追加到本地的Log中，然后通过heartbeat把该Entry同步给其他Follower，Follower接收到日志后记录日志然后向Leader发送ACK，当Leader收到大多数（n/2+1）Follower的ACK信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个heartbeat中Leader将通知所有的Follower将该日志存储在自己的本地磁盘中。 上图中，当leader选出来之后，follower的logs场景很可能出现在上图中。follower有可能丢失entries、有未提交的entries、有额外的entries等等场景。Raft中，leader通过强制followers复制自己的logs来处理不一致。这意味着，在follower中logs冲突的entries将会被leader logs中的覆写。 2.4 Safety安全性是用于保证每个节点都执行相同序列的安全机制，如当某个Follower在当前Leader commit Log时变得不可用了，稍后可能该Follower又会倍选举为Leader，这时新Leader可能会用新的Log覆盖先前已committed的Log，这就是导致节点执行不同序列；Safety就是用于保证选举出来的Leader一定包含先前 commited Log的机制； Election Safety每个Term只能选举出一个Leader，假设某个Term同时选举产生两个LeaderA和LeaderB，根据选举过程定义，A和B必须同时获得超过半数节点的投票，至少存在节点N同时给予A和B投票，因此矛盾。 Leader Completeness这里所说的完整性是指Leader日志的完整性，当Log在Term1被Commit后，那么以后Term2、Term3…等的Leader必须包含该Log；Raft在选举阶段就使用Term的判断用于保证完整性：当请求投票的该Candidate的Term较大或Term相同Index更大则投票，否则拒绝该请求； Leader Append-OnlyLeader从不“重写”或者“删除”本地Log，仅仅“追加”本地Log。Raft算法中Leader权威至高无上，当Follower和Leader产生分歧的时候，永远是Leader去覆盖修正Follower。 Log Matching如果两个节点上的日志项拥有相同的Index和Term，那么这两个节点[0, Index]范围内的Log完全一致。 State Machine Safety一旦某个server将某个日志项应用于本地状态机，以后所有server对于该偏移都将应用相同日志项。 3. 总结本文主要讲解了Raft算法的基本概念，以及算法中涉及到的leader选举，日志同步，安全性。Raft是以易理解性作为其设计的一个目标，对于一个学习的新手来说，确实比Paxos易于理解很多。虽然 Raft 的论文比 Paxos 简单版论文容易读，论文依然有很多地方需要深刻体会与理解，笔者也还是搞了好几天。 参考 Raft Animate Demo Raft Paper Raft Website Raft 为什么是更易理解的分布式一致性算法 Raft一致性算法","categories":[{"name":"算法","slug":"算法","permalink":"http://blueskykong.com/categories/算法/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://blueskykong.com/tags/consul/"},{"name":"Cluster","slug":"Cluster","permalink":"http://blueskykong.com/tags/Cluster/"},{"name":"Consensus","slug":"Consensus","permalink":"http://blueskykong.com/tags/Consensus/"}]},{"title":"consul配置与实战","slug":"consul","date":"2017-09-15T16:00:00.000Z","updated":"2017-11-14T02:38:31.000Z","comments":true,"path":"2017/09/16/consul/","link":"","permalink":"http://blueskykong.com/2017/09/16/consul/","excerpt":"","text":"上一篇提到，项目用的分布式服务发现与注册组件是consul，这篇文章主要来讲下consul组件在项目中的应用以及相关介绍。本文以官方文档为主要参考consul文档。 1. consul介绍consul是一个服务管理软件，主要功能如下： 支持多数据中心下，分布式高可用的，服务发现和配置共享。 consul支持健康检查，允许存储键值对。 一致性协议采用Raft算法,用来保证服务的高可用。 成员管理和消息广播采用GOSSIP协议，支持ACL访问控制。 1.1 服务注册与发现服务注册是一个服务将其位置信息在“中心注册节点”注册的过程。该服务一般会将它的主机IP地址以及端口号进行注册，有时也会有服务访问的认证信息，使用协议，版本号，以及关于环境的一些细节信息。而服务发现可以让一个应用或者组件发现其运行环境以及其它应用或组件的信息。用户配置一个服务发现工具就可以将实际容器跟运行配置分离开。常见配置信息包括：ip、端口号、名称等。 在传统情况下，当出现服务存在于多个主机节点上时，都会使用静态配置的方法来实现服务信息的注册。而当在一个复杂的系统里，需要较强的可扩展性时，服务被频繁替换时，为避免服务中断，动态的服务注册和发现就很重要。服务注册与发现的组件有很多，如Zookeeper、Etcd等。既可用于服务间的协调，同时又可用于服务的注册。 1.2 Consensus Protocol - Raft Consul使用Consensus协议Raft提供一致性（Consistency）。本文只是简单介绍在consul中的一致性，后面专门一篇写raft。 首先，Raft是一种基于Paxos的Consensus算法。相比于Paxos，Raft设计采用了较少的状态，并且是一种更简单、更易于理解的算法。只有Server节点参与Raft，且是peer set的一员。所有的Client节点只是转发请求到Server。这种设计的考虑是，当更多的成员加入到peer set中时，quorum的规模也会增加。可能会导致性能问题是等待quorum个节点log entry。 启动Consul时，单个consul节点需要以bootstrap模式运行，该模式运行自我选举为leader。一旦Leader被选出来，其他Server可以添加Peer set中，保持一致性和安全性。最终一些Server添加到集群，bootstrap模式需要禁用。 因为所有Server都是Peer set中的成员，它们都知道谁是Leader。当一个RPC请求到达某个非Leader Server节点，请求就会被转发到Leader。如果RPC是一种query类型，这意味着它是只读的，Leader会基于FSM当前生成相应的结果，如果RPC是一种transaction类型，即修改状态，Leader产生一个新的日志条目，并基于Raft算法进行管理。一旦日志条目应用于有限状态机，transaction完成。 由于Raft的replication性质，性能对网络延迟是非常敏感的。为此，每个数据中心选择独立的Leader和维护一个不关联的peer set。数据按照数据中心进行划分，所以每个Leader只负责在相应数据中心的数据。当接收到一个远程数据中心的请求时，请求会被转发到相应的Leader。这种设计在不牺牲一致性的情况实现较低延迟交易和更高的可用性。虽然所有日志副本的写入都是基于Raft，读取更灵活。但为了支持开发人员可能需要的各种权衡，Consul支持3种不同的一致性模式。 Default，Raft采用Leader租赁模式，提供了一个时间窗口，在该时间段内，Leader角色是稳定的。 consistent，无条件一致性 stale，这种模式允许在任何Server节点执行读取操作，无论它是不是Leader。 1.3 Group Membership Protocol - GossipConsul使用gossip协议管理成员关系、广播消息到整个集群。详情可参考Serf library。 Consul利用两个不同的gossip pool。局域网(LAN Pool)和广域网(WAN Pool)。 每个Consul数据中心都有一个包含所有成员（Server和Client）的LAN gossip pool。LAN Pool有如下几个目的： 首先，成员关系允许Client自动发现Server节点，减少所需的配置量。 其次，分布式故障检测允许的故障检测的工作在某几个Server几点执行，而不是集中整个集群所有节点上。 最后，gossip允许可靠和快速的事件广播，如Leader选举。 WAN Pool是全局唯一的，无论属于哪一个数据中心，所有Server应该加入到WAN Pool。由WAN Pool提供会员信息让Server可节电执行跨数据中心的请求。集成中故障检测允许Consul妥善处理整个数据中心失去连接，或在远程数据中心只是单个的Server节点。所有这些功能都是通过利用Serf提供。从用户角度来看，它是作为一个嵌入式库提供这些功能。但其被Consul屏蔽，用户无需关心。作为开发人员可以去了解这个库是如何利用。 1.4 Session会话上一篇文章snowflake升级版全局id生成中使用到了consul的KV存储。Consul提供session会话机制，可以用于构建分布式锁。session可以绑定到节点、健康检查、KV数据，目的是提供细粒度锁。KV存储和会话的集成是使用会话的主要场景。必须在使用之前创建一个会话，然后使用它的ID。KV API支持acquire和release操作，acquire操作类似CAS操作，只有当锁空闲时才会返回成功。当成功时，某个normal标识会更新，也会递增LockIndex，当然也会更新session的信息。如果在acquire操作时，与session相关的锁已经持有，那么LockIndex就不会递增，但是key值会更新，这就允许锁的当前持有者无需重新获得锁就可以更新key的内容。 一旦获得锁，所需要经release操作来释放（使用相同的session）。Release操作也类似于CAS操作。如果给定的session无效，那么请求会失败。需要特别注意的是，无需经过session的创建者，lock也是可以被释放的。这种设计是允许操作者干预来终止会话，在需要的时候。如上所述，会话无效也将导致所有被持有的锁被释放或删除。当锁被释放时，LockIndex不会变化，但是session会被清空，并且ModifyIndex递增。这些语义允许元组（Key，LockIndex，Session）作为一个独特的“序列”。这个序列可以被传递和用于验证请求是否属于当前的锁持有者。因为每次acquire 都会导致LockIndex递增，即使同一会话中重新获取锁，该序列能够检测到陈旧的请求。同样，如果会话失效，相应的LockIndex将为空。要清楚的是，这种锁系统是纯粹的咨询。并不是强制Client必须获取锁再能执行操作作。任何客户端都可以在未获得锁的情况下读取、写入和删除Key操作。它不是Consul用于保护系统的方法。 2. consul架构上面介绍了consul的技术内幕。现在来讲讲consul的架构。 拆解开这个体系，从每一个组件开始了解。首先，可以看到有两个数据中心，分别标记为“one”和“two”。Consul是支持多数据中心一流，并且是常用业务场景。 每个数据中心都是由Server和client组成。建议有3~5台Server，基于故障处理和性能的平衡之策。如果增加越多的机器，则Consensus会越来越慢。对client没有限制，可以很容易地扩展到成千上万或数万。同一个数据中心的所有节点都要加入Gossip协议。这意味着gossip pool包含给定数据中心的所有节点。有以下目的：首先，没有必要为client配置服务器地址参数；发现是自动完成的。第二，节点故障检测的工作不是放置在服务器上，而是分布式的。这使故障检测比心跳机制更可扩展性。第三，可用来作为消息层通知重要的事件，如leader选举。 每个数据中心的服务器都是属于一个Raft peer。这意味着，他们一起工作，选出一个的Leader，Leader server是有额外的职责。负责处理所有的查询和事务。事务也必须通过Consensus协议复制到所有的伙伴。由于这一要求，当非Leader Server接收到一个RPC请求，会转发到集群的leader。 Server节点也是作为WAN gossip pool的一部分。这个pool是与LAN gossip pool是不同的，它为具有更高延迟的网络响应做了优化，并且可能包括其他consul集群的server节点。设计WANpool的目的是让数据中心能够以low-touch的方式发现彼此。将一个新的数据中心加入现有的WAN Gossip是很容易的。因为池中的所有Server都是可控制的，这也使跨数据中心的要求。当一个Serfer接收到不同的数据中心的要求时，它把这个请求转发给相应数据中心的任一Server。然后，接收到请求的Server可能会转发给Leader。多个数据中心之间是低耦合，但由于故障检测、连接缓存复用、跨数据中心要求快速和可靠的响应。 3. consul部署3.1 docker安装docker安装很简单，笔者这边是基于docker-compose的配置文件，只需要本地安装好docker和docker-compose，docker-compose.yml如下： 12345678version: '3'services: consul: image: consul ports: - \"8500:8500\" - \"8600:8600\" - \"8300:8300\" 拉取consul得最新image，进行端口映射，暴露对外的端口8500，8300. 3.2 软件安装 从官网下载罪行的consul安装包，https://www.consul.io/downloads.html。 解压consul_0.6.4_darwin_amd64.zip。 将解压后的二进制文件consul拷贝到/usr/local/bin下。 写配置文件。服务注册的配置文件如下: 12345678910111213141516&#123; &quot;service&quot;: &#123; &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [&quot;master&quot;], &quot;address&quot;: &quot;1192.168.1.100&quot;, &quot;port&quot;: 8000, &quot;enableTagOverride&quot;: false, &quot;check&quot;: &#123; &quot;id&quot;: &quot;redis&quot;, &quot;name&quot;: &quot;redis on port 8000&quot;, &quot;tcp&quot;: &quot;localhost:8000&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125; &#125;&#125; 如上配置注册了Redis的8000端口，并带有tcp的health check。 节点的配置文件： 12345678910111213141516&#123; \"datacenter\": \"east-cn\", \"data_dir\": \"/opt/consul\", \"log_level\": \"INFO\", \"node_name\": \"redis\", \"server\": true, \"addresses\": &#123; \"https\": \"192.168.1.100\" &#125;, \"ports\": &#123; \"https\": 0 &#125;, \"ui\": true, \"retry-join\": []&#125; 当加载配置选项时，consul是按照词典顺序从所有配置文件或目录中加载。比如，a.json会先于e.json处理。后面设定的配置选项会合并到前面的配置集合中，如果存在重复的配置选项则会覆盖。当然，在某些情况下，比如事件处理程序，后面处理程序会追加到现有的配置选项中，形成事件处理程序列表。 3.3 启动具体启动文档见configuration。如: consul agent -server -config-dir /etc/consul.d -bind=192.168.1.100 -config-dir /etc/consul.d config-dir需要加载的配置文件目录，consul将加载目录下所有后缀为“.json”的文件，加载顺序为字母顺序，文件中配置选项合并方式如config-file。该参数可以多次配置。目录中的子目录是不会加载的。 data-dir此目录是为Agent存放state数据的。是所有Agent需要的，该目录应该存放在持久存储中（reboot不会丢失），对于server角色的Agent是很关键的,需要记录集群状态。并且该目录是支持文件锁。 server设置Agent是server模式还是client模式。Consul agent有两种运行模式：Server和Client。这里的Server和Client只是Consul集群层面的区分，与搭建在Cluster之上 的应用服务无关。Consule Server模式agent节点用于采用raft算法维护Consul集群的状态，官方建议每个Consul Cluster至少有3个或以上的运行在Server mode的Agent，Client节点不限。 其他常用的还有： client将绑定到client接口的地址，可以是HTTP、DNS、RPC服务器。默认为“127.0.0.1”，只允许回路连接。RPC地址会被其他的consul命令使用，比如consul members，查询agent列表 node节点在集群的名字，在集群中必须是唯一的。默认为节点的Hostname。 bootstrap设置服务是否为“bootstrap”模式。如果数据中心只有1个server agent，那么需要设置该参数。从技术上来讲，处于bootstrap模式的服务器是可以选择自己作为Raft Leader的。在consul集群中，只有一个节点可以配置该参数，如果有多个参数配置该参数，那么难以保证一致性。 bind用于集群内部通信的IP地址，与集群中其他节点互连可通。默认为“0.0.0.0”，consul将使用第一个有效的私有IPv4地址。如果指定“[::]”，consul将使用第一个有效的公共IPv6地址。使用TCP和UDP通信。注意防火墙，避免无法通信。 3.4 结果在开启了&quot;ui&quot;: trueserver主机上，如http://192.168.1.100:8500/ui查看注册中心的服务。demo ui如下： 4. 总结本文介绍了consul的一些内幕及consul配置相关，并对项目中的一些实际配置进行展示。希望能够帮助大家对consul相关的知识有所了解，并对于入门配置consul和实际应用有所知道。个人认为，consul原理还是简单易懂的，集群的配置也不复杂，安利大家使用。后面会再写一篇介绍Spring cloud中集成和使用consul组件作为注册与发现中心。 参考文献consul文档consul中文翻译","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blueskykong.com/categories/中间件/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://blueskykong.com/tags/consul/"},{"name":"cluster","slug":"cluster","permalink":"http://blueskykong.com/tags/cluster/"}]},{"title":"snowflake升级版全局id生成","slug":"snowflake","date":"2017-09-08T16:00:00.000Z","updated":"2017-12-24T08:37:31.000Z","comments":true,"path":"2017/09/09/snowflake/","link":"","permalink":"http://blueskykong.com/2017/09/09/snowflake/","excerpt":"","text":"1. 背景分布式系统或者微服务架构基本都采用了分库分表的设计，全局唯一id生成的需求变得很迫切。传统的单体应用，使用单库，数据库中自增id可以很方便实现。分库之后，首先需要分库键，分库键必然不能重复，所以传统的做法并不能满足需求。概括下来，那业务系统对ID号的要求有哪些呢？ 1.全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。2.趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。3.单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。4.信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。 其中第3和第4点是互斥的。除了功能性需求，还有性能和可靠性的需求： 平均延迟和TP999延迟都要尽可能低； 可用性5个9； 高QPS。 2. 进阶历程自从项目从单体应用拆分成微服务架构后，对全局id部分做了些摸索。 2.1 uuid刚开始拆分业务，id主键都是使用uuid字符串。UUID(Universally Unique Identifier)的标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符。类似这样的字符串：dc5adf0a-d531-11e5-95aa-3c15c2d22392。128位，根本不用担心不够用。生成的方法也很简单： 1UUID userId = UUID.randomUUID(); uuid全球唯一，本地生成，没有网络消耗，产生的性能绝对可以满足。其缺点也是显而易见的，比较占地方，和INT类型相比，存储一个UUID要花费更多的空间。使用UUID后，URL显得冗长，不够友好。ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用： MySQL官方有明确的建议主键要尽量越短越好，36个字符长度的UUID不符合要求。 对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。 2.2 数据库生成以MySQL举例，利用给字段设置auto_increment_increment和auto_increment_offset来保证ID自增，每次业务使用下列SQL读写MySQL得到ID号。参考了Leaf的实现思想: id server每次批量从数据库取号段，本地缓存这个号段，并且设置阈值，当达到0.8（已用与号段容量的比值），自动去获取一个新的号段，更新本地缓存的号段。 id client，即具体的调用服务实例，在本地也做一个缓存，实现和id server的缓存差不多，这样做的目的是为了减轻id服务端的压力，同时减少了rpc调用的网络消耗。 以上方案，其缺点是： 号段存在浪费，无论哪个客户端还是服务端重启都会浪费号段。 号段是直接自增，不够随机，对外暴露信息过多。 DB宕机会造成整个系统不可用。虽然在DB宕机之后，利用缓存还能进行短暂供号，但是数据库的依赖还是很重。Leaf采用的一般做法是高可用容灾: 采用一主两从的方式，同时分机房部署，Master和Slave之间采用半同步方式同步数据。同时使用DBProxy做主从切换。当然这种方案在一些情况会退化成异步模式，甚至在非常极端情况下仍然会造成数据不一致的情况，但是出现的概率非常小。 3. snowflake方案3.1 介绍考虑到上述方案的缺陷，笔者调查了其他的生成方案，snowflake就是其中一种方案。趋势递增和不够随机的问题，在snowflake完全可以解决，Snowflake ID有64bits长，由以下三部分组成： 第一位为0，不用。 timestamp—41bits,精确到ms，那就意味着其可以表示长达(2^41-1)/(1000360024*365)=139.5年，另外使用者可以自己定义一个开始纪元（epoch)，然后用(当前时间-开始纪元）算出time，这表示在time这个部分在140年的时间里是不会重复的，官方文档在这里写成了41bits，应该是写错了。另外，这里用time还有一个很重要的原因，就是可以直接更具time进行排序，对于twitter这种更新频繁的应用，时间排序就显得尤为重要了。 machine id—10bits,该部分其实由datacenterId和workerId两部分组成，这两部分是在配置文件中指明的。 datacenterId，方便搭建多个生成uid的service，并保证uid不重复，比如在datacenter0将机器0，1，2组成了一个生成uid的service，而datacenter1此时也需要一个生成uid的service，从本中心获取uid显然是最快最方便的，那么它可以在自己中心搭建，只要保证datacenterId唯一。如果没有datacenterId，即用10bits，那么在搭建一个新的service前必须知道目前已经在用的id，否则不能保证生成的id唯一，比如搭建的两个uid service中都有machine id为100的机器，如果其server时间相同，那么产生相同id的情况不可避免。 workerId是实际server机器的代号，最大到32，同一个datacenter下的workerId是不能重复的。它会被注册到consul上，确保workerId未被其他机器占用，并将host:port值存入，注册成功后就可以对外提供服务了。 sequence id —12bits,该id可以表示4096个数字，它是在time相同的情况下，递增该值直到为0，即一个循环结束，此时便只能等到下一个ms到来，一般情况下4096/ms的请求是不太可能出现的，所以足够使用了。 3.2 实现思路snowflake方案，id服务端生成，不依赖DB，既能保证性能，且生成的id足够随机。每一毫秒，一台worker可以生成4096个id，如果超过，会阻塞到下一毫秒生成。对于那些并发量很大的系统来说,显然是不够的, 那么这个时候就是通过datacenterId和workerId来做区分,这两个ID,分别是5bit,共10bit,最大值是1024(0-1023)个, 在这种情况下,snowflake一毫秒理论上最大能够生成的ID数量是约42W个,这是一个非常大的基数了,理论上能够满足绝大多数系统的并发量。 该方案依赖于系统时钟，需要考虑时钟回拨的问题。本地缓存上一次请求的lastTimestamp，一个线程过来获取id时，首先校验当前时间是否小于上一次ID生成的时间戳。如果小于说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！如此可以解决运行中，系统时钟被修改的问题。 另一种情况是，server服务启动时，系统的时间被回拨（虽然比较极端，还是列在考虑中），这样有可能与之前生成的id冲突，全局不唯一。这边解决方法是利用项目的服务发现与注册组件consul，在consul集群存储最新的lastTimestamp，key为对应的machine-id。consul的一致性基于raft算法，并利用Gossip协议： Consul uses a gossip protocol to manage membership and broadcast messages to the cluster. All of this is provided through the use of the Serf library. 具体的协议算法，可以参考Gossip。每次server实例启动时，实例化id生成bean的时候，会首先校验当前时间与consul集群中该worker对应的lastTimestamp大小，如果当前时间偏小，则抛出异常，服务启动失败并报警。 笔者项目暂时未分data center，所以machine-id部分都是以服务实例的workid代替。workid可以从配置中心获取，也可以本地配置。简化的系统架构部署图如下： consul集群这边作为提供naming service和kv存储的组件，每个服务部署后注册到consul集群，至于consul集群相关的信息，以及consul成员的一致性相关，后面单独一篇文章详细介绍。 请求id生成流程图如下： 服务实例启动的流程图见上文，此处不画出了。这边需要强调的是，服务注册与发现组件consul。部署时每个服务实例都会注册到一个consul agent（一般是本机），consul agent连接到consul集群，通过gossip协议进行广播信息，所以如果连接的consul agent进程不幸挂掉（大多为系统宕机），在进程重启后，还是能迅速获取到集群中存储的该workid的lastTimestamp，针对该workid，如果系统时间回拨小于lastTimestamp，Generator启动时会报警。而对于大于lastTimestamp的情况，可能系统时钟还是相对回拨，我们姑且可以认为对全局id没有影响。 实例化时，进行校验： 123456789public IdServiceImpl(long workerId, ConsulClient consulClient) &#123; if (workerId &gt; idMeta.MAX_ID || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", idMeta.MAX_ID)); &#125; this.workerId = workerId; this.consulClient = consulClient; validateStoredTimestamp(); log.info(\"worker starting. timestamp left shift &#123;&#125;, worker id bits &#123;&#125;, sequence bits &#123;&#125;, workerid &#123;&#125;\", idMeta.TIMESTAMP_LEFT_SHIFT_BITS, idMeta.ID_BITS, idMeta.SEQUENCE_BITS, workerId);&#125; 校验函数： 123456789101112131415/** * checks for timestamp by workerId when server starts. * if server starts for the first time, just let it go and log warns. * if current timestamp is smaller than the value stored in consul server, throw exception. */private void validateStoredTimestamp() &#123; long current = timeGen(); Response&lt;GetValue&gt; keyValueResponse = consulClient.getKVValue(String.valueOf(workerId)); if (keyValueResponse.getValue() != null) &#123; lastTimestamp = Long.parseLong(keyValueResponse.getValue().getDecodedValue()); validateTimestamp(current, lastTimestamp, Periods.START); &#125; else &#123; log.warn(String.format(\"clock in consul is null. Generator works as for the 1st time.\")); &#125;&#125; validateTimestamp: 123456789101112/** * 如果当前时间戳小于上一次ID生成的时间戳，说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！！！ * * @param lastTimestamp 上一次ID生成的时间戳 * @param timestamp 当前时间戳 */ private void validateTimestamp(long timestamp, long lastTimestamp, Periods period) &#123; if (timestamp &lt; lastTimestamp) &#123; log.error(String.format(\"clock is moving backwards. Rejecting requests until %d.\", lastTimestamp)); throw new IllegalStateException(String.format(\"Clock moved backwards in %s. Refusing to generate id for %d milliseconds\", period, lastTimestamp - timestamp)); &#125; &#125; 获取id方法： 123456789101112131415161718192021222324252627/** * 生成ID（线程安全） * * @return id */ public synchronized long genId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟被修改过，回退在上一次ID生成时间之前应当抛出异常！！！ validateTimestamp(timestamp, lastTimestamp, Periods.RUNNING); //如果是同一时间生成的，则进行毫秒内sequence生成 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; IdMeta.SEQUENCE_MASK; //溢出处理 if (sequence == 0) &#123;//阻塞到下一毫秒,获得新时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123;//时间戳改变，毫秒内sequence重置 sequence = 0L; &#125; //上次生成ID时间截 lastTimestamp = timestamp; consulClient.setKVValue(String.valueOf(workerId), String.valueOf(lastTimestamp)); //移位并通过或运算组成64位ID return ((timestamp - idMeta.START_TIME) &lt;&lt; idMeta.TIMESTAMP_LEFT_SHIFT_BITS) | (workerId &lt;&lt; idMeta.ID_SHIFT_BITS) | sequence; &#125; 4. 总结这篇文章和大家分享了笔者项目中全局id生成服务的演进过程。当前的方案可以满足笔者当前项目的需求，至于分data-center（同一个机房优先调用），需要结合rpc调用进一步做处理，所以这块后续可以继续完善。欢迎大家提出建议。 本文的源码地址：GitHub：https://github.com/keets2012/snowflake-id-generator码云： https://gitee.com/keets/snowflake-id-generator 参考： www.consul.io leaf Twitter的分布式自增ID算法snowflake (Java版)","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://blueskykong.com/tags/Spring-Boot/"},{"name":"snowflake","slug":"snowflake","permalink":"http://blueskykong.com/tags/snowflake/"}]},{"title":"深入ThreadLocal","slug":"ThreadLocal","date":"2017-09-03T16:00:00.000Z","updated":"2018-01-18T01:28:42.000Z","comments":true,"path":"2017/09/04/ThreadLocal/","link":"","permalink":"http://blueskykong.com/2017/09/04/ThreadLocal/","excerpt":"","text":"ThreadLocal主要是提供线程内部的局部变量，在每个线程内随时随地可取，隔离其他线程。 1. ThreadLocal接口1.1 ThreadLocal类接口很简单，只有4个方法，我们先来了解一下： void set(Object value)设置当前线程的线程局部变量的值。 public Object get()该方法返回当前线程所对应的线程局部变量。 public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。 protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。 1.2 使用ThreadLocal123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ThreadTest &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;()&#123; protected Long initialValue() &#123; return Thread.currentThread().getId(); &#125; &#125;; ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;()&#123;; protected String initialValue() &#123; return Thread.currentThread().getName(); &#125; &#125;; public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final ThreadTest test = new ThreadTest(); //test.set(); System.out.println(\"main.getLong: \" + test.getLong()); System.out.println(\"main.getString: \" + test.getString()); Thread thread1 = new Thread() &#123; public void run() &#123; //test.set(); System.out.println(\"Thread.getLong: \" + test.getLong()); System.out.println(\"Thread.getString: \" + test.getString()); &#125; &#125;; thread1.start(); thread1.join(); &#125;&#125; 以上demo覆写了initialValue()方法，或者调用set方法，否则会报空指针异常。在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。 2. ThreadLocalMapThreadLocalMap的Entry继承了WeakReference，并且使用ThreadLocal作为键值。 1. 实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的； 2. 为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal； 3. 在进行get之前，必须先set，否则会报空指针异常； 2.1 方法分析1). JDK8的ThreadLocal的get方法的源码 123456789101112131415161718192021/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local */public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 2). getMap 12345678910/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 3). setInitialValue 12345678910111213141516/** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; get方法的流程是这样的： 1.首先获取当前线程 2.根据当前线程获取一个Map 3.如果获取的Map不为空，则在Map中以ThreadLocal的引用作为key来在Map中获取对应的value e，否则转到5 4.如果e不为null，则返回e.value，否则转到5 5.Map为空或者e为空，则通过initialValue函数获取初始值value，然后用ThreadLocal的引用和value作为firstKey和firstValue创建一个新的Map 每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正需要存储的Object。 3. WeakReference关于内存泄露： ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：ThreadLocal Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 主要看下getEntryAfterMiss函数： 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null; &#125; ThreadLocalMap的getEntry函数的流程： 首先从ThreadLocal的直接索引位置(通过ThreadLocal.threadLocalHashCode &amp; (len-1)运算得到)获取Entry e，如果e不为null并且key相同则返回e； 如果e为null或者key不一致则向下一个位置查询，如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry，否则，如果key值为null，则擦除该位置的Entry，否则继续向下一个位置查询 在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。仔细研究代码可以发现，set操作也有类似的思想，将key为null的这些Entry都删除，防止内存泄露。 但是光这样还是不够的，上面的设计思路依赖一个前提条件：要调用ThreadLocalMap的genEntry函数或者set函数。这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的remove函数，手动删除不再需要的ThreadLocal，防止内存泄露。所以JDK建议将ThreadLocal变量定义成private static的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。 参考：ThreadLocal和synchronized的区别Java并发编程：深入剖析ThreadLocal","categories":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/categories/java/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"http://blueskykong.com/tags/Thread/"},{"name":"Java","slug":"Java","permalink":"http://blueskykong.com/tags/Java/"}]},{"title":"自制Jersey-Swagger的spring-boot-starter","slug":"spring-boot-starter-swaggerforjersey","date":"2017-09-01T16:00:00.000Z","updated":"2017-12-14T02:17:15.000Z","comments":true,"path":"2017/09/02/spring-boot-starter-swaggerforjersey/","link":"","permalink":"http://blueskykong.com/2017/09/02/spring-boot-starter-swaggerforjersey/","excerpt":"","text":"Spring Boot的自动化配置特性来实现快速的将swagger2引入spring boot应用来生成jersey的API文档，简化原生使用swagger2的整合代码。 版本基础 Spring Boot：1.5.x swagger-jersey2-jaxrs：2.7.x Jersey 2 如何使用在该项目的帮助下，我们的Spring Boot可以轻松的引入swagger2，主需要做下面两个步骤： 在pom.xml中引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.blueskykong&lt;/groupId&gt; &lt;artifactId&gt;jersey-starter-swagger&lt;/artifactId&gt; &lt;version&gt;1.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在应用主类中增加@EnableSwagger2Doc注解 123456789@EnableSwagger2Doc@SpringBootApplicationpublic class Bootstrap &#123; public static void main(String[] args) &#123; SpringApplication.run(Bootstrap.class, args); &#125;&#125; JerseyConfig 中增加1234@PostConstructpublic void init() &#123; this.register(ApiListingResource.class, SwaggerSerializers.class);&#125; 默认情况下就能产生所有当前jersey加载的请求映射文档。 参数配置更细致的配置内容参考如下： 配置示例1234567891011swagger: enabled: true title: spring-boot-starter-swagger config-id: demo-mvc version: v2 license: Apache License, Version 2.0 licenseUrl: https://www.apache.org/licenses/LICENSE-2.0.html termsOfServiceUrl: http://git.oschina.net/keets/jersey-starter-swagger contact: keets base-path: /** resource-package: cn.keets.demo 配置说明默认配置12345678910- swagger.enabled=是否开启 // todo 实现线上关闭功能- swagger.title=标题- swagger.description=描述- swagger.version=版本- swagger.license=许可证- swagger.licenseUrl=许可证URL- swagger.termsOfServiceUrl=服务条款URL- swagger.contact=维护人- swagger.resource-package=swagger扫描的基础包，默认：全扫描- swagger.base-path=需要处理的基础URL规则，默认：/** swagger ui未包含在项目中，大家可以自己部署静态文件，通过静态文件解析json 如下图所示： 项目git地址：http://git.oschina.net/keets/jersey-starter-swaggerdemo git地址：http://git.oschina.net/keets/spring-boot-samples/tree/master/demo-jersey-starter 参考：spring-boot-starter-swagger 1.3.0.RELEASE：新增对JSR-303的支持和host的配置","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Jersey","slug":"Jersey","permalink":"http://blueskykong.com/tags/Jersey/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://blueskykong.com/tags/Spring-Boot/"},{"name":"starter","slug":"starter","permalink":"http://blueskykong.com/tags/starter/"},{"name":"swagger","slug":"swagger","permalink":"http://blueskykong.com/tags/swagger/"}]},{"title":"Restful Layer of SpringMVC vs Jersey","slug":"Jerseyvsspringmvc","date":"2017-08-29T16:00:00.000Z","updated":"2017-11-16T07:15:06.000Z","comments":true,"path":"2017/08/30/Jerseyvsspringmvc/","link":"","permalink":"http://blueskykong.com/2017/08/30/Jerseyvsspringmvc/","excerpt":"","text":"笔者项目实现前后端剥离，服务端对外提供restful接口。REST逐渐成为影响Web框架、Web协议与Web应用设计的重要概念。现在有越来越多的公司希望能以简单而又贴合Web架构本身的方式公开Web API，因此REST变得越来越重要也就不足为奇了。使用Ajax进行通信的富浏览器端也在朝这个目标不断迈进。这个架构原则提升了万维网的可伸缩性，无论何种应用都能从该原则中受益无穷。SpringMVC和Jersey都可以为你提供restful风格的接口。本文将介绍SpringMVC中的REST特性并与Jersey进行对比。 1. REST基础概念 在REST中的一切都被认为是一种资源。 每个资源由URI标识。 使用统一的接口。处理资源使用POST，GET，PUT，DELETE操作类似创建，读取，更新和删除（CRUD）操作。 无状态。每个请求是一个独立的请求。从客户端到服务器的每个请求都必须包含所有必要的信息，以便于理解。 通信都是通过展现。例如XML，JSON。 2. Jersey与SpringMVCJAX-RS（JSR 311）指的是Java API for RESTful Web Services，Roy Fielding也参与了JAX-RS的制订，他在自己的博士论文中定义了REST。对于那些想要构建RESTful Web Services的开发者来说，JAX-RS给出了不同于JAX-WS（JSR-224）的另一种解决方案。目前共有4种JAX-RS实现，所有这些实现都支持Spring，Jersey则是JAX-RS的参考实现。 有必要指出JAX-RS的目标是Web Services开发（这与HTML Web应用不同）而Spring MVC的目标则是Web应用开发。Spring 3为Web应用与Web Services增加了广泛的REST支持，但本文则关注于与Web Services开发相关的特性。我觉得这种方式更有助于在JAX-RS的上下文中讨论Spring MVC。 要说明的第二点是我们将要讨论的REST特性是Spring Framework的一部分，也是现有的Spring MVC编程模型的延续，因此，并没有所谓的“Spring REST framework”这种概念，有的只是Spring和Spring MVC。这意味着如果你有一个Spring应用的话，你既可以使用Spring MVC创建HTML Web层，也可以创建RESTful Web Services层。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"REST","slug":"REST","permalink":"http://blueskykong.com/tags/REST/"},{"name":"Jersey","slug":"Jersey","permalink":"http://blueskykong.com/tags/Jersey/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://blueskykong.com/tags/Spring-Boot/"}]},{"title":"mac下快速进入当前目录iterm2","slug":"mac快捷键","date":"2017-08-27T16:00:00.000Z","updated":"2018-01-19T12:13:03.000Z","comments":true,"path":"2017/08/28/mac快捷键/","link":"","permalink":"http://blueskykong.com/2017/08/28/mac快捷键/","excerpt":"","text":"win环境下，有直接在文件浏览的地址上，直接输入cmd，即可打开cmd命令框。笔者在macOS下，也想实现这样的功能，网上查了一下，可以成功实践。 1. 添加服务1git clone https://github.com/peterldowns/iterm2-finder-tools.git 进入 iterm2-finder-tools文件夹，运行iTerm.workflow。安装服务栏。 2. 使用服务在工作文件夹上右键，弹出窗口中找到服务一栏，将鼠标放置其上，在弹出窗口中找到 Open iTerm一栏，单击即可。 3. 添加快捷键服务-&gt;偏好设置-&gt;快捷键 笔者设置了control+command+L。大家可以根据自己的喜好进行设置快捷键。 参考： Mac在Finder中当前目录下打开iTerm2","categories":[{"name":"Utils","slug":"Utils","permalink":"http://blueskykong.com/categories/Utils/"}],"tags":[{"name":"mac","slug":"mac","permalink":"http://blueskykong.com/tags/mac/"},{"name":"utils","slug":"utils","permalink":"http://blueskykong.com/tags/utils/"}]},{"title":"HTTP 2实际应用","slug":"http2应用","date":"2017-08-26T16:00:00.000Z","updated":"2018-02-04T13:41:12.000Z","comments":true,"path":"2017/08/27/http2应用/","link":"","permalink":"http://blueskykong.com/2017/08/27/http2应用/","excerpt":"","text":"1. 背景介绍1.1 需要解决的问题本文来源于项目需要，项目所使用微服务框架为Spring Cloud，微服务之间的调用基于HTTP 1.X协议，上一篇文章 HTTPS vs HTTP 1.1 vs HTTP 2，介绍了http2 和http1.1的相关知识，也列出了http1.1局限性，链路不能复用、数据不加密、头信息过多等等。为此，笔者在想能不能将feign client的调用基于http2协议，做了如下调研。 HTTP/2 源自 SPDY/2。SPDY 系列协议由谷歌开发，于 2009 年公开。它的设计目标是降低 50% 的页面加载时间。当下很多著名的互联网公司，例如百度、淘宝、UPYUN 都在自己的网站或 APP 中采用了 SPDY 系列协议（当前最新版本是 SPDY/3.1），因为它对性能的提升是显而易见的。主流的浏览器（谷歌、火狐、Opera）也都早已经支持 SPDY，它已经成为了工业标准，HTTP Working-Group 最终决定以 SPDY/2 为基础，开发 HTTP/2。2013年8月，进行首次测试，诞生的时间很晚，笔者搜索了网上关于http2实践的相关信息，发现并不多。 1.2 关于项目介绍Spring Cloud是笔者项目采用的微服务框架，具体介绍见Spring Cloud。Spring Cloud是基于Spring Boot开发的组合框架，Spring Boot内置的容器是Tomcat，笔者的项目一般都会exclude Tomcat的引用，使用的是Jetty容器。所以搜索的主题词就变成了 jetty http2。 2. 调研结果大部分的人习惯于将Tomcat运行在8080端口，再用Apache server在前面提供https。这样做是因为简单且验证过的方法。使用http2 ，你将被迫使用https，这样就不用部署Apache (or nginx)。 2.1 服务端 Currently Jetty and undertow are the only servers in Spring Boot that support HTTP/2.Jetty has booked some progress and this repository shows an excellent example. In my opinion it’s still too much custom code, but they’re getting there.The next candidate is undertow. It seems almost too easy, but it works. Because we use AJP in our current configuration it even means this HTTP/2 solution has less lines of code! 当前Spring Boot只有Jetty 和 undertow支持HTTP/2。 样例repo是一个很好的example。总得分为三步： update dependencies org.springframework.boot:spring-boot-starter-undertow org.mortbay.jetty.alpn:alpn-boot:8.1.8.v20160420 create a servlet container bean 1234567@Bean UndertowEmbeddedServletContainerFactory embeddedServletContainerFactory() &#123; UndertowEmbeddedServletContainerFactory factory = new UndertowEmbeddedServletContainerFactory(); factory.addBuilderCustomizers( builder -&gt; builder.setServerOption(UndertowOptions.ENABLE_HTTP2, true)); return factory; &#125; start your server with alpn为了启动服务，需要带上 -Xbootclasspath 参数来包括alpn 。因为alpn 有可能在jdk中没有。 1-Xbootclasspath/p:/home/harrie/.m2/repository/org/mortbay/jetty/alpn/alpn-boot/8.1.8.v20160420/alpn-boot-8.1.8.v20160420.jar 2.2 客户端 Currently Java HTTP/2 clients are scarce. According to this wiki Netty and OkHttp are the only two implementations supported by Spring. To switch HTTP-client in RestTemplate you have to call the constructor with a different ClientHttpRequestFactory (either Netty4ClientHttpRequestFactory or OkHttpClientHttpRequestFactory). 当前Java的http2的客户端也很少，Spring只有Netty and OkHttp支持。这边我们选用了OkHttp，因为OkHttp本来就有在feign client中内置。 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.3.0.RC1&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.3.0.RC1&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt; 2.3 浏览器对于HTTP/2的支持通过浏览器支持http2查看。 2.4 okhttp目前, Http/1.1在全世界大范围的使用中, 直接废弃跳到http/2肯定不现实. 不是每个用户的浏览器都支持http/2的, 也不是每个服务器都打算支持http/2的, 如果我们直接发送http/2格式的协议, 服务器又不支持, 那不是挂掉了! 总不能维护一个全世界的网站列表, 表示哪些支持http/2, 哪些不支持?为了解决这个问题, 从稍高层次上来说, 就是为了更方便地部署新协议, HTTP/1.1 引入了 Upgrade 机制. 这个机制在 RFC7230 的「6.7 Upgrade」这一节中有详细描述.简单说来, 就是先问下你支持http/2么? 如果你支持, 那么接下来我就用http/2和你聊天. 如果你不支持, 那么我还是用原来的http/1.1和你聊天. 客户端在请求头部中指定Connection和Upgrade两个字段发起 HTTP/1.1 协议升级. HTTP/2 的协议名称是 h2c, 代表 HTTP/2 ClearText. 如果服务端不同意升级或者不支持 Upgrade 所列出的协议，直接忽略即可（当成 HTTP/1.1 请求，以 HTTP/1.1 响应）. 如果服务端同意升级，那么需要这样响应 HTTP/1.1 101 Switching ProtocolsConnection: UpgradeUpgrade: h2c[ HTTP/2 connection … ] HTTP Upgrade 响应的状态码是 101，并且响应正文可以使用新协议定义的数据格式。 这样就可以完成从http/1.1升级到http/2了. 同样也可以从http/1.1升级到WebSocket.OkHttp使用了请求协议的协商升级, 无论是1.1还是2, 都先只以1.1来发送, 并在发送的信息头里包含协议升级字段. 接下来就看服务器是否支持协议升级了. OkHttp使用的协议升级字段是ALPN, 如果有兴趣, 可以更深入的查阅相关资料. 3. 总结总体看来，现在Spring boot 是可以支持HTTP/2 server和client。现有项目的api接口面向移动端和web端，web浏览器对于http2的支持在上文已经说明。 参考资料：OkHttp使用完全教程Spring Boot with HTTP/2 – Start a server and make REST calls as a clientHTTPS 与 HTTP2 协议分析","categories":[{"name":"Note","slug":"Note","permalink":"http://blueskykong.com/categories/Note/"}],"tags":[{"name":"HTTP2","slug":"HTTP2","permalink":"http://blueskykong.com/tags/HTTP2/"},{"name":"Java","slug":"Java","permalink":"http://blueskykong.com/tags/Java/"}]},{"title":"HTTPS vs HTTP 1.1 vs HTTP 2","slug":"HTTP2","date":"2017-08-26T03:06:59.000Z","updated":"2017-12-04T15:04:33.000Z","comments":true,"path":"2017/08/26/HTTP2/","link":"","permalink":"http://blueskykong.com/2017/08/26/HTTP2/","excerpt":"","text":"1. HTTPS协议原理分析1.1 需要解决的问题 身份验证:确保通信双方身份的真实性。 通信加密:通信的机密性、完整性依赖于算法与密钥，通信双方是如何选择算法与密钥的。 1.2相关概念 数字证书 CA（certification authority）:数字证书的签发机构。 HTTPS协议、SSL协议、TLS协议、握手协议的关系 HTTPS是Hypertext Transfer Protocol over Secure Socket Layer的缩写，即HTTP over SSL，可理解为基于SSL的HTTP协议。 HTTPS协议安全是由SSL协议（目前常用的，本文基于TLS 1.2进行分析）实现的。 SSL协议是一种记录协议，扩展性良好，可以很方便的添加子协议，而握手协议便是SSL协议的一个子协议。 TLS协议是SSL协议的后续版本，本文中涉及的SSL协议默认是TLS协议1.2版本。 HTTPS协议的安全性由SSL协议实现，当前使用的TLS协议1.2版本包含了四个核心子协议：握手协议、密钥配置切换协议、应用数据协议及报警协议。 1.3 握手协议握手协议的作用便是通信双方进行身份确认、协商安全连接各参数（加密算法、密钥等），确保双方身份真实并且协商的算法与密钥能够保证通信安全。协议交互图： ClientHello消息的作用是，将客户端可用于建立加密通道的参数集合，一次性发送给服务端。 ServerHello消息的作用是，在ClientHello参数集合中选择适合的参数，并将服务端用于建立加密通道的参数发送给客户端。 Certificate消息的作用是，将服务端证书的详细信息发送给客户端，供客户端进行服务端身份校验。 ServerKeyExchange消息的作用是，将需要服务端提供的密钥交换的额外参数，传给客户端。有的算法不需要额外参数，则ServerKeyExchange消息可不发送。 ServerHelloDone消息的作用是，通知客户端ServerHello阶段的数据均已发送完毕，等待客户端下一步消息。 ClientKeyExchange消息的作用是，将客户端需要为密钥交换提供的数据发送给服务端。 ChangeCipherSpec消息的作用，便是声明后续消息均采用密钥加密。在此消息后，我们在WireShark上便看不到明文信息了。 Finished消息的作用，是对握手阶段所有消息计算摘要，并发送给对方校验，避免通信过程中被中间人所篡改。 1.4 总结HTTPS如何保证通信安全，通过握手协议的介绍，我们已经有所了解。但是，在全面使用HTTPS前，我们还需要考虑一个众所周知的问题——HTTPS性能。相对HTTP协议来说，HTTPS协议建立数据通道的更加耗时，若直接部署到App中，势必降低数据传递的效率，间接影响用户体验。 2. HTTP 22.1 HTTP1.x协议随着互联网的快速发展，HTTP1.x协议得到了迅猛发展，但当App一个页面包含了数十个请求时，HTTP1.x协议的局限性便暴露了出来： 每个请求与响应需要单独建立链路进行请求(Connection字段能够解决部分问题)，浪费资源。 每个请求与响应都需要添加完整的头信息，应用数据传输效率较低。 默认没有进行加密，数据在传输过程中容易被监听与篡改。 2.2 HTTP 2介绍HTTP2正是为了解决HTTP1.x暴露出来的问题而诞生的。 说到HTTP2不得不提spdy。由于HTTP1.x暴露出来的问题，Google设计了全新的名为spdy的新协议。spdy在五层协议栈的TCP层与HTTP层引入了一个新的逻辑层以提高效率。spdy是一个中间层，对TCP层与HTTP层有很好的兼容，不需要修改HTTP层即可改善应用数据传输速度。spdy通过多路复用技术，使客户端与服务器只需要保持一条链接即可并发多次数据交互，提高了通信效率。而HTTP2便士基于spdy的思路开发的。通过流与帧概念的引入，继承了spdy的多路复用，并增加了一些实用特性。 新特性： 多路复用 压缩头信息 对请求划分优先级 支持服务端Push消息到客户端 HTTP2目前在实际使用中，只用于HTTPS协议场景下，通过握手阶段ClientHello与ServerHello的extension字段协商而来，所以目前HTTP2的使用场景，都是默认安全加密的。 查看了wiki发现： Netty and OkHttp are the only two implementations supported by Spring. 2.3 协议协商HTTP2协议的协商是在握手阶段进行的。 协商的方式是通过握手协议extension扩展字段进行扩展，新增Application Layer Protocol Negotiation字段进行协商。 在握手协议的ClientHello阶段，客户端将所支持的协议列表填入Application Layer Protocol Negotiation字段，供服务端进行挑选。 2.4 多路复用Multipexing在HTTP2中，同一域名下的请求，可通过同一条TCP链路进行传输，使多个请求不必单独建立链路，节省建立链路的开销。 为了达到这个目的，HTTP2提出了流与帧的概念，流代表请求与响应，而请求与响应具体的数据则包装为帧，对链路中传输的数据通过流ID与帧类型进行区分处理。下图是多路复用的抽象图，每个块代表一帧，而相同颜色的块则代表是同一个流。 归纳下okhttp的多路复用实现思路： 通过请求的Address与连接池中现有连接Address依次匹配，选出可用的Connection。 通过Http2xStream创建的FramedStream在发送了请求后，将FramedStream对象与StreamID的映射关系缓存到FramedConnection中。 收到消息后，FramedConnection解析帧信息，在Map中通过解析的StreamID选出缓存的FramedStream，并唤醒FramedStream进行Response的处理。 2.5 压缩头信息HTTP2为了解决HTTP1.x中头信息过大导致效率低下的问题，提出的解决方案便是压缩头部信息。具体的压缩方式，则引入了HPACK。 HPACK压缩算法是专门为HTTP2头部压缩服务的。为了达到压缩头部信息的目的，HPACK将头部字段缓存为索引，通过索引ID代表头部字段。客户端与服务端维护索引表，通信过程中尽可能采用索引进行通信，收到索引后查询索引表，才能解析出真正的头部信息。 HPACK索引表划分为动态索引表与静态索引表，动态索引表是HTTP2协议通信过程中两端动态维护的索引表，而静态索引表是硬编码进协议中的索引表。 作为分析HPACK压缩头信息的基础，需要先介绍HPACK对索引以及头部字符串的表示方式。 索引 索引以整型数字表示，由于HPACK需要考虑压缩与编解码问题，所以整型数字结构定义下图所示： 类别标识:通过类别标识进行HPACK类别分类，指导后续编解码操作，常见的有1，01，01000000等八个类别。 首字节低位整型:首字节排除类别标识的剩余位，用于表示低位整型。若数值大于剩余位所能表示的容量，则需要后续字节表示高位整型。 结束标识:表示此字节是否为整型解析终止字节。 高位整型:字节余下7bit，用于填充整型高位。","categories":[{"name":"Note","slug":"Note","permalink":"http://blueskykong.com/categories/Note/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"http://blueskykong.com/tags/HTTPS/"},{"name":"HTTP2","slug":"HTTP2","permalink":"http://blueskykong.com/tags/HTTP2/"}]},{"title":"mongodb 集群基础","slug":"mongodb集群基础","date":"2017-08-10T12:11:59.000Z","updated":"2017-11-14T02:42:40.000Z","comments":true,"path":"2017/08/10/mongodb集群基础/","link":"","permalink":"http://blueskykong.com/2017/08/10/mongodb集群基础/","excerpt":"","text":"1. MongoDB介绍 MongoDB 是一个可扩展的高性能,开源,模式自由,面向文档的数据库。 它使用 C++编写。MongoDB 包含一下特点: 面向集合的存储:适合存储对象及JSON形式的数据。 动态查询:Mongo 支持丰富的查询方式,查询指令使用 JSON 形式的标记,可轻易查询文档中内嵌的对象及数组。 完整的索引支持:包括文档内嵌对象及数组。Mongo 的查询优化器会分析查询表达式,并生成一个高效的查询计划。 查询监视:Mongo包含一个监控工具用于分析数据库操作性能。 复制及自动故障转移:Mongo 数据库支持服务器之间的数据复制,支持主-从模式及服务器之间的相互复制。复制的主要目的是提供冗余及自动故障转移。 高效的传统存储方式:支持二进制数据及大型对象(如:照片或图片)。 自动分片以支持云级别的伸缩性:自动分片功能支持水平的数据库集群,可动态添加额外的机器。 2.Replica Set集群当中包含了多份数据，保证主节点挂掉了，备节点能继续提供数据服务，提供的前提就是数据需要和主节点一致。 Mongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点。主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。 默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes，同时Java客户端提供了简单的配置方式，可以不必直接对数据库进行操作。 仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。我开始也不相信必须要有仲裁节点，但是自己也试过没仲裁节点的话，主节点挂了备节点还是备节点，所以咱们还是需要它的。 3.Sharding 和Replica Set类似，都需要一个仲裁节点，但是Sharding还需要配置节点和路由节点。 集群搭建方式首选Replica Set，只有真的是大数据，Sharding才能显现威力，毕竟备节点同步数据是需要时间的。Sharding可以将多片数据集中到路由节点上进行一些对比，然后将数据返回给客户端，但是效率还是比较低的说。 我自己有测试过，不过具体的机器配置已经不记得了。Replica Set的ips在数据达到1400w条时基本能达到1000左右，而Sharding在300w时已经下降到500ips了，两者的单位数据大小大概是10kb。大家在应用的时候还是多多做下性能测试，毕竟不像Redis有benchmark。 Mongodb现在用的还是比较多的，但是个人觉得配置太多了。我看官网都看了好多天，才把集群搭建的配置和注意要点弄明白。而且用过的人应该知道mongodb吃内存的问题，解决办法只能通过ulimit来控制内存使用量，但是如果控制不好的话，mongodb会挂掉 PS: 后面继续补充。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://blueskykong.com/categories/中间件/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://blueskykong.com/tags/MongoDB/"},{"name":"Cluster","slug":"Cluster","permalink":"http://blueskykong.com/tags/Cluster/"}]},{"title":"Spring Cloud 入门","slug":"spring-cloud","date":"2017-07-18T08:21:19.000Z","updated":"2017-11-14T02:44:58.000Z","comments":true,"path":"2017/07/18/spring-cloud/","link":"","permalink":"http://blueskykong.com/2017/07/18/spring-cloud/","excerpt":"","text":"1. 微服务架构微服务架构（Micro-Service Archeticture）是当下流行的架构风格，旨在通过将功能模块分解到各个独立的子系统中以实现解耦，它并没有一成不变的规定，而是需要根据业务来做设计[李贞昊,2017]。微服务架构中，每个微服务模块只是对简单、独立、明确的任务进行处理，通过REST API返回处理结果给外部。在微服务推广实践角度来看，微服务将整个系统进行拆分，拆分成更小的粒度，保持这些服务独立运行，应用容器化技术将微服务独立运行在容器中。过去设计架构时，是在内存中以参数或对象的方式实现粒度细化。微服务使用各个子服务控制模块的思想代替总线。不同的业务要求，服务控制模块至少包含服务的发布、注册、路由、代理功能。 2. vs 单体应用架构微服务架构模式相比于单体应用架构，有很多优势。 首先，巨大的单体式应用拆分为多个微服务，降低了复杂性。在具有之前单体应用功能的同时，单体应用被拆分为多个可管理的微服务。每个微服务都具有定义清楚的边界，使用远程过程调用（RPC）或者消息驱动API。拆分后的微服务模块，粒度小，很容易开发和维护。微服务架构模式降低了单体式编码的难度，并且功能提供了模块化的解决方案。 第二，微服务架构下，专门开发团队负责开发一个子服务。每个开发团队可以自主选择技术栈，提供API接口。当然，许多公司将技术栈统一，只提供特定选择的技术。然后，这种自由使得开发团队不需要被迫使用特定的那些技术，他们可以自由地选择适合该微服务的技术。甚至于，重构之前的代码也变得很便捷。 第三，每个微服务都是独立的部署。开发团队不再需要协调其它服务部署对本服务的影响。这样的特性大大加快了部署速度。微服务架构模式使得持续化部署成为可能。 最后，微服务架构模式使得每个微服务应用都可以被独立扩展。单体架构应用也可以横向扩展，即整个应用完整的复制到不同的节点。当应用的不同组件在扩展需求上存在差异时，微服务架构便体现出其优越性。通过在不同的基础设施之间实现扩展，这些服务能够有效地降低风险[陈春霞, 2016]。 3. Spring Cloud开源框架Spring Cloud是一个基于Spring Boot实现的云应用开发工具，它为基于JVM的云应用开发中的服务发现与注册、熔断机制、路由、全局锁、中心配置管理、控制总线、决策竞选、分布式会话和集群状态管理等操作提供了一种简单的开发方式[翟永超,2016]。Spring Cloud整体架构图如图1.1所示。 Spring Cloud整体架构中如下几个基础服务模块：微服务配置管理、API网关服务、服务发现与注册和消息总线模块。 spring-cloud-config，微服务配置管理，即为上图的config service服务模块，为服务端提供了分布式环境的中央配置支持。配置服务器为各应用的所有环境提供了一个中心化的外部配置。它完成了对服务端Spring-Env和配置源抽象的映射，所以config服务不仅适用于Spring框架构建的应用，也可以使用在其他语言的应用程序。作为一个应用，可以通过部署管道来进行测试或者投入生产，分别为这些环境创建配置，并且在需要迁移环境的时候获取对应的配置来运行。 API网关，本系统使用netflix的zuul框架，作为系统的统一入口，具有负载均衡、服务路由、服务过滤等功能。 服务发现与注册有多种开源组件支持，比如zookeeper、etcd、netflix公司的Eureka，以及本系统使用的Consul。服务发现是一个服务将其地址信息在中心注册节点进行注册的过程。该服务一般会将它的主机IP地址以及端口号进行注册，具体还会包括认证信息、使用协议、版本号等信息，以及关于应用服务环境的细节信息。一个应用服务或者组件通过服务发现可以掌握其运行环境以及其它应用服务或组件的信息。用户配置一个服务发现工具之后，就可以将实际容器与运行配置分离开。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://blueskykong.com/categories/微服务/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blueskykong.com/tags/Spring-Cloud/"}]},{"title":"浅析REST与HTTP","slug":"REST与HTTP","date":"2017-07-09T16:00:00.000Z","updated":"2018-01-13T13:12:45.000Z","comments":true,"path":"2017/07/10/REST与HTTP/","link":"","permalink":"http://blueskykong.com/2017/07/10/REST与HTTP/","excerpt":"","text":"幂等性Methods can also have the property of &quot;idempotence&quot; in that (aside from error or expiration issues) the side-effects of N &gt; 0 identical requests is the same as for a single request. 安全操作与幂指相等特性（Safety /Idempotence）HTTP 的 GET、HEAD 请求本质上应该是安全的调用，即：GET、HEAD 调用不会有任何的副作用，不会造成服务器端状态的改变。对于服务器来说，客户端对某一 URI 做 n 次的 GET、HAED 调用，其状态与没有做调用是一样的，不会发生任何的改变。 HTTP 的 PUT、DELTE 调用，具有幂指相等特性 , 即：客户端对某一 URI 做 n 次的 PUT、DELTE 调用，其效果与做一次的调用是一样的。HTTP 的 GET、HEAD 方法也具有幂指相等特性。HTTP 这些标准方法在原则上保证你的分布式系统具有这些特性，以帮助构建更加健壮的分布式系统。 当然作为设计的基础，几个必须的原则还是要遵守的： 当标准合理的时候遵守标准。 API应该对程序员友好，并且在浏览器地址栏容易输入。 API应该简单，直观，容易使用的同时优雅。 API应该具有足够的灵活性来支持上层ui。 API设计权衡上述几个原则。 HTTPhttp请求由三部分组成，分别是：请求行、消息报头、请求正文. http 1.1/2 http://www.blogjava.net/yongboy/archive/2015/03/23/423751.html HTTP/1.1，HTTP客户端无法重试非幂等请求，尤其在错误发生的时候，由于无法检测错误性质这会对重试带来不利的影响。 HTTP/2不允许使用连接特定头部字段 新增的5个头部 推送机制的一些特性需求 RST_STREAM等帧标志位的使用","categories":[{"name":"Note","slug":"Note","permalink":"http://blueskykong.com/categories/Note/"}],"tags":[{"name":"REST","slug":"REST","permalink":"http://blueskykong.com/tags/REST/"},{"name":"HTTP","slug":"HTTP","permalink":"http://blueskykong.com/tags/HTTP/"}]},{"title":"Java异步编程接口：Callable和Future源码解析","slug":"callable-future-analyze","date":"2017-05-25T16:00:00.000Z","updated":"2018-02-28T09:38:24.000Z","comments":true,"path":"2017/05/26/callable-future-analyze/","link":"","permalink":"http://blueskykong.com/2017/05/26/callable-future-analyze/","excerpt":"","text":"在上一篇Java异步编程接口：Callable和Future中介绍了异步编程经常使用的Callable、Future以及FutureTask，并给出了应用示例。本文主要在上一篇的基础应用基础上，深入源码分析实现原理。本文基于JDK8。 异步接口Callable接口许多任务实际上都是存在延迟的计算，对于这些任务，Callable是一种更好的抽象：它会返回一个值，并可能抛出一个异常。Callable接口： 1234public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 该接口中唯一的方法call()返回的类型就是传递进来的V类型。 Runnable和Callable描述的都是抽象的计算任务。这些任务通常是有生命周期的。 Future接口1234567891011121314public interface Future&lt;V&gt; &#123; //取消任务， boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; Executor执行的任务有4个生命周期阶段：创建、提交、开始和完成。由于有些任务可能要执行很长时间，因此通常希望可以取消这些任务。在Executor框架中，已提交但尚未开始的任务可以取消，对于已经开始执行的任务，只有当它们响应中断时才能取消。 实际上Future提供了三种功能：判断任务是否完成、中断任务和获取任务执行结果。 如何实现异步在不阻塞当前线程的情况下计算，那么必然需要另外的线程去执行具体的业务逻辑，上面代码中可以看到，是把Callable放入了线程池中，等待执行，并且立刻返回futrue。可以猜想下，需要从Future中得到Callable的结果，那么Future的引用必然会被两个线程共享，一个线程执行完成后改变Future的状态位并唤醒挂起在get上的线程，到底是不是这样呢？ ExecutorService接口中定义了submit()用以提交任务，在AbstractExecutorService中的源码如下： 123456789101112131415public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; &#125; 可以看到Callable任务被包装成了RunnableFuture对象，通过了线程池的execute方法提交任务并且立刻返回对象本身，而线程池是接受Runnable，RunnableFuture继承了Runnable。 1234public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 设置计算的结果到Future中，除非任务被取消。可以看到，newTaskFor返回的是FutureTask，构造函数的参数为Callable任务。我们具体看一下FutureTask的实现，不过可以肯定的是该类实现了RunnableFuture接口。 FutureTaskFutureTask被生产者和消费者共享，生产者运行run()方法计算结果，消费者通过get方法获取结果，那么必然就需要通知，如何通知呢，肯定是状态位变化，并唤醒线程。 123456789101112131415private volatile int state;//在构建FutureTask时设置，同时也表示内部成员callable已成功赋值private static final int NEW = 0;//woker thread在处理task时设定的中间状态private static final int COMPLETING = 1;//当设置result结果完成后，FutureTask处于该状态，代表过程结果private static final int NORMAL = 2;//task执行过程出现异常，此时结果设值为exception,也是final stateprivate static final int EXCEPTIONAL = 3;//表明task被cancelprivate static final int CANCELLED = 4;//中间状态，task运行过程中被interrupt时，设置的中间状态private static final int INTERRUPTING = 5;//中断完毕的最终状态private static final int INTERRUPTED = 6; state初始化为NEW。只有在set, setException和cancel方法中state才可以转变为终态。在任务完成期间，state的值可能为COMPLETING或INTERRUPTING。 state存在可能的四种状态变化如下： 1234NEW -&gt; COMPLETING -&gt; NORMALNEW -&gt; COMPLETING -&gt; EXCEPTIONALNEW -&gt; CANCELLEDNEW -&gt; INTERRUPTING -&gt; INTERRUPTED Task的状态变化FutureTask有两个构造函数，分别接受Callable和Runnable作为创建任务的参数。 123456public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125; 12345public FutureTask(Runnable runnable, V result) &#123; //result，成功计算后返回的结果类型 this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable &#125; 此时将state设置为初始态NEW。这里注意Runnable是怎样转换为Callable的，看下Executors.callable(runnable, result)的具体实现： 123456789101112131415161718public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125;static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; &#125;&#125; 上面实现可以看出通过Callable的call方法调用Runnable的run方法，把传入的 T result 作为callable的返回结果。 当创建完一个Task通常会提交给Executors来执行，当然也可以使用Thread来执行，Thread的start()方法会调用Task的run()方法。 1234567891011121314151617181920212223242526272829303132public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; &#125; 首先判断任务的状态，如果任务状态不是new，说明任务状态已经改变。可能是上面4种可能变化的一种，比如caller调用了cancel，此时状态为Interrupting, 也说明了上面的cancel方法，task没运行时，就interrupt, task得不到运行，总是返回。如果状态是new, 判断runner是否为null, 如果为null, 则把当前执行任务的线程赋值给runner，如果runner不为null, 说明已经有线程在执行，返回。此处使用cas（使用compareAndSwap能够保证原子性）来赋值worker thread是保证多个线程同时提交同一个FutureTask时，确保该FutureTask的run只被调用一次， 如果想运行多次，使用runAndReset()方法。 接着开始执行任务，如果要执行的任务不为空，并且state为New就执行，可以看到这里调用了Callable的call方法。如果执行成功则set结果，如果出现异常则setException,最后把runner设为null。看一下set方法的实现： 1234567protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125; 如果现在的状态是NEW就把状态设置成COMPLETING，然后设置成NORMAL。这个执行流程的状态变化就是： NEW-&gt;COMPLETING-&gt;NORMAL。最后执行finishCompletion方法： 12345678910111213141516171819202122private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint &#125; 该方法将会解除所有阻塞的worker thread， 调用done()方法，将成员变量callable设为null。 等待的线程如何挂起get()方法的线程，看一下具体实现： 123456public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; 首先判断FutureTask的状态是否为完成状态，如果是完成状态，说明已经执行过set或setException方法，返回report(s): 12345678private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x);&#125; 可以看到，如果FutureTask的状态是NORMAL, 即正确执行了set方法，get方法直接返回处理的结果， 如果是取消状态，即执行了setException，则抛出CancellationException异常。如果get时,FutureTask的状态为未完成状态，则调用awaitDone方法进行阻塞。awaitDone(): 123456789101112131415161718192021222324252627282930313233343536private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else LockSupport.park(this); &#125;&#125; awaitDone方法可以看成是不断轮询查看FutureTask的状态。在get阻塞期间： 如果执行get的线程被中断，则移除FutureTask的所有阻塞队列中的线程（waiters）,并抛出中断异常； 如果FutureTask的状态转换为完成状态（正常完成或取消），则返回完成状态； 如果FutureTask的状态变为COMPLETING, 则说明正在set结果，此时让线程等一等； 如果FutureTask的状态为初始态NEW，则将当前线程加入到FutureTask的阻塞线程中去； 如果get方法没有设置超时时间，则阻塞当前调用get线程；如果设置了超时时间，则判断是否达到超时时间，如果到达，则移除FutureTask的所有阻塞列队中的线程，并返回此时FutureTask的状态，如果未到达时间，则在剩下的时间内继续阻塞当前线程。 总结本文主要讲了Java异步接口的实现原理。从我们的猜想开始，在不阻塞当前线程的情况下计算，那么必然需要另外的线程去执行具体的业务逻辑，从具体应用时可以看到，是把Callable放入了线程池中，等待执行，并且立刻返回futrue。现在需要从Future中得到Callable的结果，那么Future的引用必然会被两个线程共享，一个线程执行完成后改变Future的状态位并唤醒挂起在get上的线程。由ExecutorService的提交任务，逐步分析到FutureTask中状态位的设置以及状态的变化，最后分析了get()方法获取计算结果时，在FutureTask中如何挂起并最终返回计算结果。 参考 Callable异步原理简析 Callable、Future和FutureTask原理解析 JDK8 API","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://blueskykong.com/categories/并发编程/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/tags/java/"}]},{"title":"并发Lock之ReentrantLock实现原理","slug":"reenterlock","date":"2017-05-21T16:00:00.000Z","updated":"2018-01-30T07:59:10.000Z","comments":true,"path":"2017/05/22/reenterlock/","link":"","permalink":"http://blueskykong.com/2017/05/22/reenterlock/","excerpt":"","text":"我们在之前介绍了并发编程的锁机制：synchronized和lock，lock接口的重要实现类是可重入锁ReentrantLock。而上一篇并发Lock之AQS（AbstractQueuedSynchronizer）详解介绍了AQS，谈到ReentrantLock，不得不谈抽象类AbstractQueuedSynchronizer（AQS）。AQS定义了一套多线程访问共享资源的同步器框架，ReentrantLock的实现依赖于该同步器。本文在介绍过AQS，结合其具体的实现类ReentrantLock分析实现原理。 ReentrantLock类图 ReentrantLock实现了Lock接口，内部有三个内部类，Sync、NonfairSync、FairSync，Sync是一个抽象类型，它继承AbstractQueuedSynchronizer，这个AbstractQueuedSynchronizer是一个模板类，它实现了许多和锁相关的功能，并提供了钩子方法供用户实现，比如tryAcquire，tryRelease等。Sync实现了AbstractQueuedSynchronizer的tryRelease方法。NonfairSync和FairSync两个类继承自Sync，实现了lock方法，公平抢占和非公平抢占针对tryAcquire有不同的实现。本文重点介绍ReentrantLock默认的实现，即非公平锁的获取锁和释放锁的实现。 非公平锁的lock方法lock方法 在初始化ReentrantLock的时候，如果我们不传参数，那么默认使用非公平锁，也就是NonfairSync。 123public ReentrantLock() &#123; sync = new NonfairSync(); &#125; 当我们调用ReentrantLock的lock方法的时候，实际上是调用了NonfairSync的lock方法，这个方法先用CAS操作，去尝试抢占该锁。如果成功，就把当前线程设置在这个锁上，表示抢占成功。如果失败，则调用acquire模板方法，等待抢占。代码如下： 123456789101112static final class NonfairSync extends Sync &#123; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 上面调用acquire(1)实际上使用的是AbstractQueuedSynchronizer的acquire方法，它是一套锁抢占的模板，总体原理是先去尝试获取锁，如果没有获取成功，就在CLH队列中增加一个当前线程的节点，表示等待抢占。然后进入CLH队列的抢占模式，进入的时候也会去执行一次获取锁的操作，如果还是获取不到，就调用LockSupport.park将当前线程挂起。那么当前线程什么时候会被唤醒呢？当持有锁的那个线程调用unlock的时候，会将CLH队列的头节点的下一个节点上的线程唤醒，调用的是LockSupport.unpark方法。acquire代码比较简单，具体如下： 1234public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; acquire方法内部先使用tryAcquire这个钩子方法去尝试再次获取锁，这个方法在NonfairSync这个类中其实就是使用了nonfairTryAcquire，具体实现原理是先比较当前锁的状态是否是0，如果是0，则尝试去原子抢占这个锁（设置状态为1，然后把当前线程设置成独占线程），如果当前锁的状态不是0，就去比较当前线程和占用锁的线程是不是一个线程，如果是，会去增加状态变量的值，从这里看出可重入锁之所以可重入，就是同一个线程可以反复使用它占用的锁。如果以上两种情况都不通过，则返回失败false。代码如下： 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; tryAcquire一旦返回false，就会则进入acquireQueued流程，也就是基于CLH队列的抢占模式 首先，在CLH锁队列尾部增加一个等待节点，这个节点保存了当前线程，通过调用addWaiter实现，这里需要考虑初始化的情况，在第一个等待节点进入的时候，需要初始化一个头节点然后把当前节点加入到尾部，后续则直接在尾部加入节点就行了。 1234567891011121314151617181920212223242526272829303132private Node addWaiter(Node mode) &#123; // 初始化一个节点，这个节点保存当前线程 Node node = new Node(Thread.currentThread(), mode); // 当CLH队列不为空的视乎，直接在队列尾部插入一个节点 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 当CLH队列为空的时候，调用enq方法初始化队列 enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // 初始化节点，头尾都指向一个空节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123;// 考虑并发初始化 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 将节点增加到CLH队列后，进入acquireQueued方法。 首先，外层是一个无限for循环，如果当前节点是头节点的下个节点，并且通过tryAcquire获取到了锁，说明头节点已经释放了锁，当前线程是被头节点那个线程唤醒的，这时候就可以将当前节点设置成头节点，并且将failed标记设置成false，然后返回。至于上一个节点，它的next变量被设置为null，在下次GC的时候会清理掉。 如果本次循环没有获取到锁，就进入线程挂起阶段，也就是shouldParkAfterFailedAcquire这个方法。 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 如果尝试获取锁失败，就会进入shouldParkAfterFailedAcquire方法，会判断当前线程是否挂起，如果前一个节点已经是SIGNAL状态，则当前线程需要挂起。如果前一个节点是取消状态，则需要将取消节点从队列移除。如果前一个节点状态是其他状态，则尝试设置成SIGNAL状态，并返回不需要挂起，从而进行第二次抢占。完成上面的事后进入挂起阶段。 1234567891011121314151617private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) // return true; if (ws &gt; 0) &#123; // do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 当进入挂起阶段，会进入parkAndCheckInterrupt方法，则会调用LockSupport.park(this)将当前线程挂起。 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 非公平锁的unlock方法 调用unlock方法，其实是直接调用AbstractQueuedSynchronizer的release操作。 123public void unlock() &#123; sync.release(1);&#125; 进入release方法，内部先尝试tryRelease操作,主要是去除锁的独占线程，然后将状态减一，这里减一主要是考虑到可重入锁可能自身会多次占用锁，只有当状态变成0，才表示完全释放了锁。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 一旦tryRelease成功，则将CHL队列的头节点的状态设置为0，然后唤醒下一个非取消的节点线程。 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; 一旦下一个节点的线程被唤醒，被唤醒的线程就会进入acquireQueued代码流程中，去获取锁。 1234567891011121314private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; tryLock 在ReetrantLock的tryLock(long timeout, TimeUnit unit)提供了超时获取锁的功能。它的语义是在指定的时间内如果获取到锁就返回true，获取不到则返回false。这种机制避免了线程无限期的等待锁释放。 1234 public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125; 具体看一下内部类里面的方法tryAcquireNanos： 1234567 public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 如果线程被中断了，那么直接抛出InterruptedException。如果未中断，先尝试获取锁，获取成功就直接返回，获取失败则进入doAcquireNanos。tryAcquire我们已经看过，这里重点看一下doAcquireNanos做了什么。 12345678910111213141516171819202122232425262728293031323334353637383940private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; // 起始时间 long lastTime = System.nanoTime(); // 线程入队 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; // 又是自旋! for (;;) &#123; // 获取前驱节点 final Node p = node.predecessor(); // 如果前驱是头节点并且占用锁成功,则将当前节点变成头结点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; // 如果已经超时,返回false if (nanosTimeout &lt;= 0) return false; // 超时时间未到,且需要挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) // 阻塞当前线程直到超时时间到期 LockSupport.parkNanos(this, nanosTimeout); long now = System.nanoTime(); // 更新nanosTimeout nanosTimeout -= now - lastTime; lastTime = now; if (Thread.interrupted()) //相应中断 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; doAcquireNanos的流程简述为：线程先入等待队列，然后开始自旋，尝试获取锁，获取成功就返回，失败则在队列里找一个安全点把自己挂起直到超时时间过期。这里为什么还需要循环呢？因为当前线程节点的前驱状态可能不是SIGNAL，那么在当前这一轮循环中线程不会被挂起，然后更新超时时间，开始新一轮的尝试。 总结ReentrantLock是可重入的锁，其内部使用的就是独占模式的AQS。公平锁和非公平锁不同之处在于，公平锁在获取锁的时候，不会先去检查state状态，而是直接执行aqcuire(1)。公平锁多了hasQueuePredecessors这个方法，这个方法用于判断CHL队列中是否有节点，对于公平锁，如果CHL队列有节点，则新进入竞争的线程一定要在CHL上排队，而非公平锁则是无视CHL队列中的节点，直接进行竞争抢占，这就有可能导致CHL队列上的节点永远获取不到锁，这就是非公平锁之所以不公平的原因，这里不再赘述。 参考 Java中可重入锁ReentrantLock原理剖析 ReentrantLock实现原理","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://blueskykong.com/categories/并发编程/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/tags/java/"}]},{"title":"Java异步编程接口：Callable和Future","slug":"callable-future","date":"2017-05-19T16:00:00.000Z","updated":"2018-02-27T02:39:49.000Z","comments":true,"path":"2017/05/20/callable-future/","link":"","permalink":"http://blueskykong.com/2017/05/20/callable-future/","excerpt":"","text":"本文主要讲解平时开发中常用的异步编程的接口：Callable和Future。 创建线程的2种方式，一种是直接继承Thread，另外一种就是实现Runnable接口。这2种方式都有一个缺陷就是：在执行完任务之后无法获取执行结果。如果需要获取执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦。自从Java 1.5开始，就提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果。 CallableCallable接口的定义如下： 1234public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; Callable中定义了 call() 方法计算结果，或者当不能执行的时候抛出异常，可以看到返回值的类型是通过传入的泛型决定。 Callable并不像Runnable那样通过Thread的start方法就能启动实现类的run方法，所以它通常利用ExecutorService的submit方法去启动call方法自执行任务，而ExecutorService的submit又返回一个Future类型的结果，因此Callable通常也与Future一起使用 123456ExecutorService pool = Executors.newCachedThreadPool(); Future&lt;String&gt; future = pool.submit(new Callable &#123; public void call()&#123; //your operations &#125; &#125;); vs RunnableRunnable与Callable不同点： Runnable不返回任务执行结果，Callable可返回任务执行结果； Callable在任务无法计算结果时抛出异常，而Runnable不能； Callable支持泛型，Runnable不支持； Runnable任务可直接由Thread的start方法或ExecutorService的submit方法去执行。 FutureFuture保存异步计算的结果,可以在我们执行任务时去做其他工作，并提供了以下几个方法： 123456789101112public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; cancel(boolean mayInterruptIfRunning)：试图取消执行的任务，参数为true时直接中断正在执行的任务，否则直到当前任务执行完成，成功取消后返回true，否则返回false isCancel()：判断任务是否在正常执行完前被取消的，如果是则返回true isDone()：判断任务是否已完成 get()：等待计算结果的返回，如果计算被取消了则抛出 get(long timeout,TimeUtil unit)：设定计算结果的返回时间，如果在规定时间内没有返回计算结果则抛出TimeOutException 使用Future的好处： 获取任务的结果，判断任务是否完成，中断任务 Future的get方法很好的替代的了Thread.join或Thread,join(long millis) Future的get方法可以判断程序代码(任务)的执行是否超时 FutureTaskFutureTask实现了RunnableFuture&lt;V&gt;接口，关于该接口看一下其定义： 1234public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; RunnableFuture同时继承了Runnable和Future，接口中定义的run方法，将计算的结果设置到Future除非计算被取消。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 FutureTask可以直接提交给Executor执行，当然也可以调用线程直接执行FutureTask.run()。 FutureTask是一个可取消的异步计算，FutureTask 实现了Future的基本方法，提供start和cancel 操作，可以查询计算是否已经完成，并且可以获取计算的结果。结果只可以在计算完成之后获取，get方法会阻塞当计算没有完成的时候，一旦计算已经完成， 那么计算就不能再次启动或是取消。 使用示例示例场景：有一个耗时的操作，操作完后会返回一个结果（不管是正常结果还是异常），程序如果想拥有比较好的性能不可能由线程去等待操作的完成，而是应该采用listener模式。jdk并发包里的Future代表了未来的某个结果，当我们向线程池中提交任务的时候会返回该对象。提交一个Callable对象给线程池时，将得到一个Future对象，并且它和传入的Callable有相同的结果类型声明。 1234567891011121314151617181920212223242526272829303132333435public class FutureTest &#123; public static void main(String[] args) throws Throwable, ExecutionException &#123; ExecutorService executor = Executors.newFixedThreadPool(2); //Java8 的lambada表达式，参数为Callable&lt;T&gt; task Future&lt;String&gt; f = executor.submit(() -&gt; &#123; System.out.println(\"task started!\"); Thread.sleep(1000); return \"worker task finished!\"; &#125;); System.out.println(\"Future is ready: \" + f.isDone()); //此处阻塞main线程 System.out.println(f.get()); executor.shutdown(); System.out.println(\"main thread is finished！\"); &#125; //FutureTask的写法 public static void test() throws Throwable, ExecutionException &#123; FutureTask&lt;String&gt; f = new FutureTask&lt;&gt;(() -&gt; &#123; System.out.println(\"task started!\"); Thread.sleep(1000); return \"worker task finished!\"; &#125;); Thread thread = new Thread(f); thread.start(); System.out.println(\"Future is ready: \" + f.isDone()); //此处阻塞main线程 System.out.println(f.get()); System.out.println(\"main thread is finished！\"); &#125;&#125; 运行结果如下： 1234Future is ready: falsetask started!worker task finished!main thread is finished！ 如果想获得耗时操作的结果，可以通过get方法获取，但是该方法会阻塞当前线程，我们可以在做完剩下的某些工作的时候调用get方法试图去获取结果，也可以调用非阻塞的方法isDone来确定操作是否完成。过程如下： Future代表了线程执行完以后的结果，可以通过future获得执行的结果。但是jdk1.8之前的Future不支持，并不能实现真正的异步，需要阻塞的获取结果，或者不断的轮询。通常我们希望当线程执行完一些耗时的任务后，能够自动的通知我们结果，很遗憾这在原生jdk1.8之前 是不支持的，但是我们可以通过第三方的库实现真正的异步回调。如Guava何Netty中都有提供，读者可以自己进行扩展，下面我们看一下JDK8中的实现。 Java8 CompletableFuture 虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果。 CompletableFuture类实现了CompletionStage和Future接口，所以你还是可以像以前一样通过阻塞或者轮询的方式获得结果，尽管这种方式不推荐使用。这里使用CompletableFuture实现异步的操作. 12345678910111213141516171819202122232425public class Java8PromiseTest &#123; public static void main(String[] args) throws Throwable, ExecutionException &#123; ExecutorService executor = Executors.newFixedThreadPool(2); //jdk1.8，通过调用给定的Supplier，异步完成executor中的task CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(\"task started!\"); try &#123; //模拟耗时操作 Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return \"worker task is finished!\"; &#125;, executor); //采用lambada的实现方式 future.thenAccept(e -&gt; &#123; System.out.printf(\"%s ok\", e); executor.shutdown(); &#125;); System.out.println(\"main thread is finished！\"); &#125;&#125; 运行结果如下： 123task started!main thread is finished！worker task is finished! ok supplyAsync方法以Supplier函数式接口类型为参数,CompletableFuture的计算结果类型为U。thenAccept方法是CompletableFuture提供的一种处理结果的方法，只对结果执行Action,而不返回新的计算值，因此计算值为Void。 总结本文主要介绍了异步编程经常使用的Callable、Future以及FutureTask。运行Callable任务可以拿到一个Future对象，Future 表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并获取计算的结果。计算完成后只能使用 get 方法来获取结果，如果线程没有执行完，Future.get()方法可能会阻塞当前线程的执行；如果线程出现异常，Future.get()会抛出异常。取消由cancel 方法来执行。isDone确定任务是正常完成还是被取消了。一旦计算完成，就不能再取消计算。如果为了可取消性而使用 Future 但又不提供可用的结果，则可以声明Future&lt;?&gt; 形式类型、并返回 null 作为底层任务的结果。 参考 java异步编程 Java并发编程：Callable、Future和FutureTask","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://blueskykong.com/categories/并发编程/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/tags/java/"}]},{"title":"并发Lock之AQS（AbstractQueuedSynchronizer）详解","slug":"aqs","date":"2017-05-17T16:00:00.000Z","updated":"2018-01-30T05:20:16.000Z","comments":true,"path":"2017/05/18/aqs/","link":"","permalink":"http://blueskykong.com/2017/05/18/aqs/","excerpt":"","text":"1. J.U.C的lock包结构上一篇文章讲了并发编程的锁机制：synchronized和lock，主要介绍了Java并发编程中常用的锁机制。Lock是一个接口，而synchronized是Java中的关键字，synchronized是基于jvm实现。Lock锁可以被中断，支持定时锁等。Lock的实现类，可重入锁ReentrantLock，我们有讲到其具体用法。而谈到ReentrantLock，不得不谈抽象类AbstractQueuedSynchronizer（AQS）。抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock、ThreadPoolExecutor。 2. AQS介绍AQS是一个抽象类，主是是以继承的方式使用。AQS本身是没有实现任何同步接口的，它仅仅只是定义了同步状态的获取和释放的方法来供自定义的同步组件的使用。AQS抽象类包含如下几个方法： AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。共享模式时只用 Sync Queue, 独占模式有时只用 Sync Queue, 但若涉及 Condition, 则还有 Condition Queue。在子类的 tryAcquire, tryAcquireShared 中实现公平与非公平的区分。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。 整个 AQS 分为以下几部分: Node 节点， 用于存放获取线程的节点， 存在于 Sync Queue, Condition Queue, 这些节点主要的区分在于 waitStatus 的值(下面会详细叙述) Condition Queue， 这个队列是用于独占模式中，只有用到 Condition.awaitXX 时才会将 node加到 tail 上(PS: 在使用 Condition的前提是已经获取 Lock) Sync Queue， 独占共享的模式中均会使用到的存放 Node 的 CLH queue(主要特点是队列中总有一个 dummy 节点，后继节点获取锁的条件由前继节点决定，前继节点在释放 lock 时会唤醒sleep中的后继节点) ConditionObject，用于独占的模式，主要是线程释放lock，加入Condition Queue， 并进行相应的 signal 操作 独占的获取lock (acquire release) 例如 ReentrantLock。 共享的获取lock (acquireShared releaseShared)。 例如 ReeantrantReadWriteLock, Semaphore, CountDownLatch 下面我们具体来分析一下AQS实现的源码。 3. 内部类 NodeNode 节点是代表获取lock的线程, 存在于 Condition Queue, Sync Queue 里面， 而其主要就是 nextWaiter (标记共享还是独占),waitStatus 标记node的状态。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081static final class Node &#123; /** 标识节点是否是 共享的节点(这样的节点只存在于 Sync Queue 里面) */ static final Node SHARED = new Node(); //独占模式 static final Node EXCLUSIVE = null; /** * CANCELLED 说明节点已经 取消获取 lock 了(一般是由于 interrupt 或 timeout 导致的) * 很多时候是在 cancelAcquire 里面进行设置这个标识 */ static final int CANCELLED = 1; /** * SIGNAL 标识当前节点的后继节点需要唤醒(PS: 这个通常是在 独占模式下使用, 在共享模式下有时用 PROPAGATE) */ static final int SIGNAL = -1; //当前节点在 Condition Queue 里面 static final int CONDITION = -2; /** * 当前节点获取到 lock 或进行 release lock 时, 共享模式的最终状态是 PROPAGATE(PS: 有可能共享模式的节点变成 PROPAGATE 之前就被其后继节点抢占 head 节点, 而从Sync Queue中被踢出掉) */ static final int PROPAGATE = -3; volatile int waitStatus; /** * 节点在 Sync Queue 里面时的前继节点(主要来进行 skip CANCELLED 的节点) * 注意: 根据 addWaiter方法: * 1. prev节点在队列里面, 则 prev != null 肯定成立 * 2. prev != null 成立, 不一定 node 就在 Sync Queue 里面 */ volatile Node prev; /** * Node 在 Sync Queue 里面的后继节点, 主要是在release lock 时进行后继节点的唤醒 * 而后继节点在前继节点上打上 SIGNAL 标识, 来提醒他 release lock 时需要唤醒 */ volatile Node next; //获取 lock 的引用 volatile Thread thread; /** * 作用分成两种: * 1. 在 Sync Queue 里面, nextWaiter用来判断节点是 共享模式, 还是独占模式 * 2. 在 Condition queue 里面, 节点主要是链接且后继节点 (Condition queue是一个单向的, 不支持并发的 list) */ Node nextWaiter; // 当前节点是否是共享模式 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 获取 node 的前继节点 final Node predecessor() throws NullPointerException&#123; Node p = prev; if(p == null)&#123; throw new NullPointerException(); &#125;else&#123; return p; &#125; &#125; Node()&#123; // Used to establish initial head or SHARED marker &#125; // 初始化 Node 用于 Sync Queue 里面 Node(Thread thread, Node mode)&#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; //初始化 Node 用于 Condition Queue 里面 Node(Thread thread, int waitStatus)&#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; waitStatus的状态变化: 线程刚入 Sync Queue 里面, 发现独占锁被其他人获取, 则将其前继节点标记为 SIGNAL, 然后再尝试获取一下锁(调用 tryAcquire 方法) 若调用 tryAcquire 方法获取失败, 则判断一下是否前继节点被标记为 SIGNAL, 若是的话 直接 block(block前会确保前继节点被标记为SIGNAL, 因为前继节点在进行释放锁时根据是否标记为 SIGNAL 来决定唤醒后继节点与否 &lt;- 这是独占的情况下) 前继节点使用完lock, 进行释放, 因为自己被标记为 SIGNAL, 所以唤醒其后继节点 waitStatus 变化过程: 独占模式下: 0(初始) -&gt; signal(被后继节点标记为release需要唤醒后继节点) -&gt; 0 (等释放好lock, 会恢复到0) 独占模式 + 使用 Condition情况下: 0(初始) -&gt; signal(被后继节点标记为release需要唤醒后继节点) -&gt; 0 (等释放好lock, 会恢复到0)其上可能涉及 中断与超时, 只是多了一个 CANCELLED, 当节点变成 CANCELLED, 后就等着被清除。 共享模式下: 0(初始) -&gt; PROPAGATE(获取 lock 或release lock 时) (获取 lock 时会调用 setHeadAndPropagate 来进行 传递式的唤醒后继节点, 直到碰到 独占模式的节点) 共享模式 + 独占模式下: 0(初始) -&gt; signal(被后继节点标记为release需要唤醒后继节点) -&gt; 0 (等释放好lock, 会恢复到0) 其上的这些状态变化主要在: doReleaseShared , shouldParkAfterFailedAcquire 里面。 4. Condition QueueCondition Queue 是一个并发不安全的, 只用于独占模式的队列(PS: 为什么是并发不安全的呢? 主要是在操作 Condition 时, 线程必需获取 独占的 lock, 所以不需要考虑并发的安全问题);而当Node存在于 Condition Queue 里面, 则其只有 waitStatus, thread, nextWaiter 有值, 其他的都是null(其中的 waitStatus 只能是 CONDITION, 0(0 代表node进行转移到 Sync Queue里面, 或被中断/timeout)); 这里有个注意点, 就是当线程被中断或获取 lock 超时, 则一瞬间 node 会存在于 Condition Queue, Sync Queue 两个队列中. 节点 Node4, Node5, Node6, Node7 都是调用 Condition.awaitXX 方法加入 Condition Queue(PS: 加入后会将原来的 lock 释放)。 4.1 入队列方法 addConditionWaiter将当前线程封装成一个 Node 节点放入到 Condition Queue 里面大家可以注意到, 下面对 Condition Queue 的操作都没考虑到 并发(Sync Queue 的队列是支持并发操作的), 这是为什么呢? 因为在进行操作 Condition 是当前的线程已经获取了AQS的独占锁, 所以不需要考虑并发的情况。 12345678910111213141516171819202122232425262728private Node addConditionWaiter()&#123; Node t = lastWaiter; // Condition queue 的尾节点 // 尾节点已经Cancel, 直接进行清除, /** * 当Condition进行 awiat 超时或被中断时, Condition里面的节点是没有被删除掉的, 需要其 * 他await 在将线程加入 Condition Queue 时调用addConditionWaiter而进而删除, 或 await 操作差不多结束时, 调用 \"node.nextWaiter != null\" 进行判断而删除 (PS: 通过 signal 进行唤 * 醒时 node.nextWaiter 会被置空, 而中断和超时时不会) */ if(t != null &amp;&amp; t.waitStatus != Node.CONDITION)&#123; /** * 调用 unlinkCancelledWaiters 对 \"waitStatus != Node.CONDITION\" 的节点进行 * 删除(在Condition里面的Node的waitStatus 要么是CONDITION(正常), 要么就是 0 * (signal/timeout/interrupt)) */ unlinkCancelledWaiters(); t = lastWaiter; &#125; //将线程封装成 node 准备放入 Condition Queue 里面 Node node = new Node(Thread.currentThread(), Node.CONDITION); if(t == null)&#123; //Condition Queue 是空的 firstWaiter = node; &#125; else &#123; // 追加到 queue 尾部 t.nextWaiter = node; &#125; lastWaiter = node; return node;&#125; 4.2 删除Cancelled节点的方法 unlinkCancelledWaiters当Node在Condition Queue 中, 若状态不是 CONDITION, 则一定是被中断或超时。在调用 addConditionWaiter 将线程放入 Condition Queue 里面时或 awiat 方法获取结束时 进行清理 Condition queue 里面的因 timeout/interrupt 而还存在的节点。这个删除操作比较巧妙, 其中引入了 trail 节点， 可以理解为traverse整个 Condition Queue 时遇到的最后一个有效的节点。 123456789101112131415161718192021private void unlinkCancelledWaiters()&#123; Node t = firstWaiter; Node trail = null; while(t != null)&#123; Node next = t.nextWaiter; // 1. 先初始化 next 节点 if(t.waitStatus != Node.CONDITION)&#123; // 2. 节点不有效, 在Condition Queue 里面 Node.waitStatus 只有可能是 CONDITION 或是 0(timeout/interrupt引起的) t.nextWaiter = null; // 3. Node.nextWaiter 置空 if(trail == null)&#123; // 4. 一次都没有遇到有效的节点 firstWaiter = next; // 5. 将 next 赋值给 firstWaiter(此时 next 可能也是无效的, 这只是一个临时处理) &#125; else &#123; trail.nextWaiter = next; // 6. next 赋值给 trail.nextWaiter, 这一步其实就是删除节点 t &#125; if(next == null)&#123; // 7. next == null 说明 已经 traverse 完了 Condition Queue lastWaiter = trail; &#125; &#125;else&#123; trail = t; // 8. 将有效节点赋值给 trail &#125; t = next; &#125;&#125; 4.3 转移节点的方法 transferForSignaltransferForSignal只有在节点被正常唤醒才调用的正常转移的方法。 将Node 从Condition Queue 转移到 Sync Queue 里面在调用transferForSignal之前, 会 first.nextWaiter = null;而我们发现若节点是因为 timeout / interrupt 进行转移, 则不会进行这步操作; 两种情况的转移都会把 wautStatus 置为 0 123456789101112131415final boolean transferForSignal(Node node)&#123; /** * If cannot change waitStatus, the node has been cancelled */ if(!compareAndSetWaitStatus(node, Node.CONDITION, 0))&#123; // 1. 若 node 已经 cancelled 则失败 return false; &#125; Node p = enq(node); // 2. 加入 Sync Queue int ws = p.waitStatus; if(ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))&#123; // 3. 这里的 ws &gt; 0 指Sync Queue 中node 的前继节点cancelled 了, 所以, 唤醒一下 node ; compareAndSetWaitStatus(p, ws, Node.SIGNAL)失败, 则说明 前继节点已经变成 SIGNAL 或 cancelled, 所以也要 唤醒 LockSupport.unpark(node.thread); &#125; return true;&#125; 4.4 转移节点的方法 transferAfterCancelledWaittransferAfterCancelledWait 在节点获取lock时被中断或获取超时才调用的转移方法。将 Condition Queue 中因 timeout/interrupt 而唤醒的节点进行转移 1234567891011final boolean transferAfterCancelledWait(Node node)&#123; if(compareAndSetWaitStatus(node, Node.CONDITION, 0))&#123; // 1. 没有 node 没有 cancelled , 直接进行转移 (转移后, Sync Queue , Condition Queue 都会存在 node) enq(node); return true; &#125; while(!isOnSyncQueue(node))&#123; // 2.这时是其他的线程发送signal,将本线程转移到 Sync Queue 里面的工程中(转移的过程中 waitStatus = 0了, 所以上面的 CAS 操作失败) Thread.yield(); // 这里调用 isOnSyncQueue判断是否已经 入Sync Queue 了 &#125; return false;&#125; 5. Sync QueueAQS内部维护着一个FIFO的CLH队列，所以AQS并不支持基于优先级的同步策略。至于为何要选择CLH队列，主要在于CLH锁相对于MSC锁，他更加容易处理cancel和timeout，同时他具备进出队列快、无所、畅通无阻、检查是否有线程在等待也非常容易（head != tail,头尾指针不同）。当然相对于原始的CLH队列锁，ASQ采用的是一种变种的CLH队列锁： 原始CLH使用的locked自旋，而AQS的CLH则是在每个node里面使用一个状态字段来控制阻塞，而不是自旋。 为了可以处理timeout和cancel操作，每个node维护一个指向前驱的指针。如果一个node的前驱被cancel，这个node可以前向移动使用前驱的状态字段。 head结点使用的是傀儡结点。 这个图代表有个线程获取lock, 而 Node1, Node2, Node3 则在Sync Queue 里面进行等待获取lock(PS: 注意到 dummy Node 的SINGNAL 这是叫获取 lock 的线程在释放lock时通知后继节点的标示) 5.1 Sync Queue 节点入Queue方法这里有个地方需要注意, 就是初始化 head, tail 的节点, 不一定是 head.next, 因为期间可能被其他的线程进行抢占了。将当前的线程封装成 Node 加入到 Sync Queue 里面。 1234567891011121314151617181920212223242526272829303132333435363738394041424344private Node addWaiter(Node mode)&#123; Node node = new Node(Thread.currentThread(), mode); // 1. 封装 Node Node pred = tail; if(pred != null)&#123; // 2. pred != null -&gt; 队列中已经有节点, 直接 CAS 到尾节点 node.prev = pred; // 3. 先设置 Node.pre = pred (PS: 则当一个 node在Sync Queue里面时 node.prev 一定 != null(除 dummy node), 但是 node.prev != null 不能说明其在 Sync Queue 里面, 因为现在的CAS可能失败 ) if(compareAndSetTail(pred, node))&#123; // 4. CAS node 到 tail pred.next = node; // 5. CAS 成功, 将 pred.next = node (PS: 说明 node.next != null -&gt; 则 node 一定在 Sync Queue, 但若 node 在Sync Queue 里面不一定 node.next != null) return node; &#125; &#125; enq(node); // 6. 队列为空, 调用 enq 入队列 return node;&#125;/** * 这个插入会检测head tail 的初始化, 必要的话会初始化一个 dummy 节点, 这个和 ConcurrentLinkedQueue 一样的 * 将节点 node 加入队列 * 这里有个注意点 * 情况: * 1. 首先 queue是空的 * 2. 初始化一个 dummy 节点 * 3. 这时再在tail后面添加节点(这一步可能失败, 可能发生竞争被其他的线程抢占) * 这里为什么要加入一个 dummy 节点呢? * 这里的 Sync Queue 是CLH lock的一个变种, 线程节点 node 能否获取lock的判断通过其前继节点 * 而且这里在当前节点想获取lock时通常给前继节点 打上 signal 的标识(表示前继节点释放lock需要通知我来获取lock) * 若这里不清楚的同学, 请先看看 CLH lock的资料 (这是理解 AQS 的基础) */private Node enq(final Node node)&#123; for(;;)&#123; Node t = tail; if(t == null)&#123; // Must initialize // 1. 队列为空 初始化一个 dummy 节点 其实和 ConcurrentLinkedQueue 一样 if(compareAndSetHead(new Node()))&#123; // 2. 初始化 head 与 tail (这个CAS成功后, head 就有值了, 详情将 Unsafe 操作) tail = head; &#125; &#125;else&#123; node.prev = t; // 3. 先设置 Node.pre = pred (PS: 则当一个 node在Sync Queue里面时 node.prev 一定 != null, 但是 node.prev != null 不能说明其在 Sync Queue 里面, 因为现在的CAS可能失败 ) if(compareAndSetTail(t, node))&#123; // 4. CAS node 到 tail t.next = node; // 5. CAS 成功, 将 pred.next = node (PS: 说明 node.next != null -&gt; 则 node 一定在 Sync Queue, 但若 node 在Sync Queue 里面不一定 node.next != null) return t; &#125; &#125; &#125;&#125; 5.2 Sync Queue 节点出Queue方法这里的出Queue的方法其实有两个：新节点获取lock, 调用setHead抢占head, 并且剔除原head；节点因被中断或获取超时而进行 cancelled, 最后被剔除。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 设置 head 节点(在独占模式没有并发的可能, 当共享的模式有可能) */private void setHead(Node node)&#123; head = node; node.thread = null; // 清除线程引用 node.prev = null; // 清除原来 head 的引用 &lt;- 都是 help GC&#125;// 清除因中断/超时而放弃获取lock的线程节点(此时节点在 Sync Queue 里面)private void cancelAcquire(Node node) &#123; if (node == null) return; node.thread = null; // 1. 线程引用清空 Node pred = node.prev; while (pred.waitStatus &gt; 0) // 2. 若前继节点是 CANCELLED 的, 则也一并清除 node.prev = pred = pred.prev; Node predNext = pred.next; // 3. 这里的 predNext也是需要清除的(只不过在清除时的 CAS 操作需要 它) node.waitStatus = Node.CANCELLED; // 4. 标识节点需要清除 // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; // 5. 若需要清除额节点是尾节点, 则直接 CAS pred为尾节点 compareAndSetNext(pred, predNext, null); // 6. 删除节点predNext &#125; else &#123; int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || // 7. 后继节点需要唤醒(但这里的后继节点predNext已经 CANCELLED 了) (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; // 8. 将 pred 标识为 SIGNAL pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) // 8. next.waitStatus &lt;= 0 表示 next 是个一个想要获取lock的节点 compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); // 若 pred 是头节点, 则此刻可能有节点刚刚进入 queue ,所以进行一下唤醒 &#125; node.next = node; // help GC &#125;&#125; 6. 独占Lock6.1 独占方式获取lock主要流程 调用 tryAcquire 尝试性的获取锁(一般都是由子类实现), 成功的话直接返回 tryAcquire 调用获取失败, 将当前的线程封装成 Node 加入到 Sync Queue 里面(调用addWaiter), 等待获取 signal 信号 调用 acquireQueued 进行自旋的方式获取锁(有可能会 repeatedly blocking and unblocking) 根据acquireQueued的返回值判断在获取lock的过程中是否被中断, 若被中断, 则自己再中断一下(selfInterrupt), 若是响应中断的则直接抛出异常 6.2 独占方式获取lock主要分成3类 acquire 不响应中断的获取lock, 这里的不响应中断指的是线程被中断后会被唤醒, 并且继续获取lock,在方法返回时, 根据刚才的获取过程是否被中断来决定是否要自己中断一下(方法 selfInterrupt) doAcquireInterruptibly 响应中断的获取 lock, 这里的响应中断, 指在线程获取 lock 过程中若被中断, 则直接抛出异常 doAcquireNanos 响应中断及超时的获取 lock, 当线程被中断, 或获取超时, 则直接抛出异常, 获取失败 6.3 独占的获取lock 方法 acquireacquire(int arg)：以独占模式获取对象，忽略中断。 123456public final void acquire(int arg)&#123; if(!tryAcquire(arg)&amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) &#123; selfInterrupt(); &#125;&#125; 调用 tryAcquire 尝试性的获取锁(一般都是又子类实现), 成功的话直接返回 tryAcquire 调用获取失败, 将当前的线程封装成 Node 加入到 Sync Queue 里面(调用addWaiter), 等待获取 signal 信号 调用 acquireQueued 进行自旋的方式获取锁(有可能会 repeatedly blocking and unblocking) 根据acquireQueued的返回值判断在获取lock的过程中是否被中断, 若被中断, 则自己再中断一下(selfInterrupt)。 6.4 循环获取lock 方法 acquireQueued1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg)&#123; boolean failed = true; try &#123; boolean interrupted = false; for(;;)&#123; final Node p = node.predecessor(); // 1. 获取当前节点的前继节点 (当一个n在 Sync Queue 里面, 并且没有获取 lock 的 node 的前继节点不可能是 null) if(p == head &amp;&amp; tryAcquire(arg))&#123; // 2. 判断前继节点是否是head节点(前继节点是head, 存在两种情况 (1) 前继节点现在占用 lock (2)前继节点是个空节点, 已经释放 lock, node 现在有机会获取 lock); 则再次调用 tryAcquire尝试获取一下 setHead(node); // 3. 获取 lock 成功, 直接设置 新head(原来的head可能就直接被回收) p.next = null; // help GC // help gc failed = false; return interrupted; // 4. 返回在整个获取的过程中是否被中断过 ; 但这又有什么用呢? 若整个过程中被中断过, 则最后我在 自我中断一下 (selfInterrupt), 因为外面的函数可能需要知道整个过程是否被中断过 &#125; if(shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 5. 调用 shouldParkAfterFailedAcquire 判断是否需要中断(这里可能会一开始 返回 false, 但在此进去后直接返回 true(主要和前继节点的状态是否是 signal)) parkAndCheckInterrupt())&#123; // 6. 现在lock还是被其他线程占用 那就睡一会, 返回值判断是否这次线程的唤醒是被中断唤醒 interrupted = true; &#125; &#125; &#125;finally &#123; if(failed)&#123; // 7. 在整个获取中出错 cancelAcquire(node); // 8. 清除 node 节点(清除的过程是先给 node 打上 CANCELLED标志, 然后再删除) &#125; &#125; &#125; 主逻辑: 当前节点的前继节点是head节点时，先 tryAcquire获取一下锁, 成功的话设置新 head, 返回 第一步不成功, 检测是否需要sleep, 需要的话就sleep, 等待前继节点在释放lock时唤醒或通过中断来唤醒 整个过程可能需要blocking nonblocking 几次 6.5 支持中断获取lock 方法 doAcquireInterruptibly123456789101112131415161718192021222324private void doAcquireInterruptibly(int arg) throws InterruptedException&#123; final Node node = addWaiter(Node.EXCLUSIVE); // 1. 将当前的线程封装成 Node 加入到 Sync Queue 里面 boolean failed = true; try &#123; for(;;)&#123; final Node p = node.predecessor(); // 2. 获取当前节点的前继节点 (当一个n在 Sync Queue 里面, 并且没有获取 lock 的 node 的前继节点不可能是 null) if(p == head &amp;&amp; tryAcquire(arg))&#123; // 3. 判断前继节点是否是head节点(前继节点是head, 存在两种情况 (1) 前继节点现在占用 lock (2)前继节点是个空节点, 已经释放 lock, node 现在有机会获取 lock); 则再次调用 tryAcquire尝试获取一下 setHead(node); p.next = null; // help GC failed = false; return; &#125; if(shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 4. 调用 shouldParkAfterFailedAcquire 判断是否需要中断(这里可能会一开始 返回 false, 但在此进去后直接返回 true(主要和前继节点的状态是否是 signal)) parkAndCheckInterrupt())&#123; // 5. 现在lock还是被其他线程占用 那就睡一会, 返回值判断是否这次线程的唤醒是被中断唤醒 throw new InterruptedException(); // 6. 线程此时唤醒是通过线程中断, 则直接抛异常 &#125; &#125; &#125;finally &#123; if(failed)&#123; // 7. 在整个获取中出错(比如线程中断) cancelAcquire(node); // 8. 清除 node 节点(清除的过程是先给 node 打上 CANCELLED标志, 然后再删除) &#125; &#125;&#125; acquireInterruptibly(int arg)： 以独占模式获取对象，如果被中断则中止。 123456public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; 通过先检查中断的状态，然后至少调用一次tryAcquire，返回成功。否则，线程在排队，不停地阻塞与唤醒，调用tryAcquire直到成功或者被中断。 6.6 超时&amp;中断获取lock 方法tryAcquireNanos(int arg, long nanosTimeout):独占且支持超时模式获取： 带有超时时间，如果经过超时时间则会退出。 12345678910111213141516171819202122232425262728293031323334353637private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException&#123; if(nanosTimeout &lt;= 0L)&#123; return false; &#125; final long deadline = System.nanoTime() + nanosTimeout; // 0. 计算截至时间 final Node node = addWaiter(Node.EXCLUSIVE); // 1. 将当前的线程封装成 Node 加入到 Sync Queue 里面 boolean failed = true; try &#123; for(;;)&#123; final Node p = node.predecessor(); // 2. 获取当前节点的前继节点 (当一个n在 Sync Queue 里面, 并且没有获取 lock 的 node 的前继节点不可能是 null) if(p == head &amp;&amp; tryAcquire(arg))&#123; // 3. 判断前继节点是否是head节点(前继节点是head, 存在两种情况 (1) 前继节点现在占用 lock (2)前继节点是个空节点, 已经释放 lock, node 现在有机会获取 lock); 则再次调用 tryAcquire尝试获取一下 setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); // 4. 计算还剩余的时间 if(nanosTimeout &lt;= 0L)&#123; // 5. 时间超时, 直接返回 return false; &#125; if(shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 6. 调用 shouldParkAfterFailedAcquire 判断是否需要中断(这里可能会一开始 返回 false, 但在此进去后直接返回 true(主要和前继节点的状态是否是 signal)) nanosTimeout &gt; spinForTimeoutThreshold)&#123; // 7. 若没超时, 并且大于spinForTimeoutThreshold, 则线程 sleep(小于spinForTimeoutThreshold, 则直接自旋, 因为效率更高 调用 LockSupport 是需要开销的) LockSupport.parkNanos(this, nanosTimeout); &#125; if(Thread.interrupted())&#123; // 8. 线程此时唤醒是通过线程中断, 则直接抛异常 throw new InterruptedException(); &#125; &#125; &#125;finally &#123; if(failed)&#123; // 9. 在整个获取中出错(比如线程中断/超时) cancelAcquire(node); // 10. 清除 node 节点(清除的过程是先给 node 打上 CANCELLED标志, 然后再删除) &#125; &#125;&#125; 尝试以独占模式获取，如果中断和超时则放弃。实现时先检查中断的状态，然后至少调用一次tryAcquire。 12345public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg)|| doAcquireNanos(arg, nanosTimeout); &#125; 6.7 释放lock方法释放 lock 流程： 调用子类的 tryRelease 方法释放获取的资源 判断是否完全释放lock(这里有 lock 重复获取的情况) 判断是否有后继节点需要唤醒, 需要的话调用unparkSuccessor进行唤醒 12345678910111213141516171819202122232425262728293031323334public final boolean release(int arg)&#123; if(tryRelease(arg))&#123; // 1. 调用子类, 若完全释放好, 则返回true(这里有lock重复获取) Node h = head; if(h != null &amp;&amp; h.waitStatus != 0)&#123; // 2. h.waitStatus !=0 其实就是 h.waitStatus &lt; 0 后继节点需要唤醒 unparkSuccessor(h); // 3. 唤醒后继节点 &#125; return true; &#125; return false;&#125;/** * 唤醒 node 的后继节点 * 这里有个注意点: 唤醒时会将当前node的标识归位为 0 * 等于当前节点标识位 的流转过程: 0(刚加入queue) -&gt; signal (被后继节点要求在释放时需要唤醒) -&gt; 0 (进行唤醒后继节点) */private void unparkSuccessor(Node node) &#123; logger.info(\"unparkSuccessor node:\" + node + Thread.currentThread().getName()); int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 1. 清除前继节点的标识 Node s = node.next; logger.info(\"unparkSuccessor s:\" + node + Thread.currentThread().getName()); if (s == null || s.waitStatus &gt; 0) &#123; // 2. 这里若在 Sync Queue 里面存在想要获取 lock 的节点,则一定需要唤醒一下(跳过取消的节点) （PS: s == null发生在共享模式的竞争释放资源） s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) // 3. 找到 queue 里面最前面想要获取 Lock 的节点 s = t; &#125; logger.info(\"unparkSuccessor s:\"+s); if (s != null) LockSupport.unpark(s.thread);&#125; 7. 共享Lock7.1 共享方式获取lock流程 调用 tryAcquireShared 尝试性的获取锁(一般都是由子类实现), 成功的话直接返回 tryAcquireShared 调用获取失败, 将当前的线程封装成 Node 加入到 Sync Queue 里面(调用addWaiter), 等待获取 signal 信号 在 Sync Queue 里面进行自旋的方式获取锁(有可能会 repeatedly blocking and unblocking 当获取失败, 则判断是否可以 block(block的前提是前继节点被打上 SIGNAL 标示) 共享与独占获取lock的区别主要在于 在共享方式下获取 lock 成功会判断是否需要继续唤醒下面的继续获取共享lock的节点(及方法 doReleaseShared) 7.2 共享方式获取lock主要分成3类 acquireShared 不响应中断的获取lock, 这里的不响应中断指的是线程被中断后会被唤醒, 并且继续获取lock,在方法返回时, 根据刚才的获取过程是否被中断来决定是否要自己中断一下(方法 selfInterrupt) doAcquireSharedInterruptibly 响应中断的获取 lock, 这里的响应中断, 指在线程获取 lock 过程中若被中断, 则直接抛出异常 doAcquireSharedNanos 响应中断及超时的获取 lock, 当线程被中断, 或获取超时, 则直接抛出异常, 获取失败 7.3 获取共享lock 方法 acquireShared12345public final void acquireShared(int arg)&#123; if(tryAcquireShared(arg) &lt; 0)&#123; // 1. 调用子类, 获取共享 lock 返回 &lt; 0, 表示失败 doAcquireShared(arg); // 2. 调用 doAcquireShared 当前 线程加入 Sync Queue 里面, 等待获取 lock &#125;&#125; 7.4 获取共享lock 方法 doAcquireShared1234567891011121314151617181920212223242526272829303132private void doAcquireShared(int arg)&#123; final Node node = addWaiter(Node.SHARED); // 1. 将当前的线程封装成 Node 加入到 Sync Queue 里面 boolean failed = true; try &#123; boolean interrupted = false; for(;;)&#123; final Node p = node.predecessor(); // 2. 获取当前节点的前继节点 (当一个n在 Sync Queue 里面, 并且没有获取 lock 的 node 的前继节点不可能是 null) if(p == head)&#123; int r = tryAcquireShared(arg); // 3. 判断前继节点是否是head节点(前继节点是head, 存在两种情况 (1) 前继节点现在占用 lock (2)前继节点是个空节点, 已经释放 lock, node 现在有机会获取 lock); 则再次调用 tryAcquireShared 尝试获取一下 if(r &gt;= 0)&#123; setHeadAndPropagate(node, r); // 4. 获取 lock 成功, 设置新的 head, 并唤醒后继获取 readLock 的节点 p.next = null; // help GC if(interrupted)&#123; // 5. 在获取 lock 时, 被中断过, 则自己再自我中断一下(外面的函数可能需要这个参数) selfInterrupt(); &#125; failed = false; return; &#125; &#125; if(shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 6. 调用 shouldParkAfterFailedAcquire 判断是否需要中断(这里可能会一开始 返回 false, 但在此进去后直接返回 true(主要和前继节点的状态是否是 signal)) parkAndCheckInterrupt())&#123; // 7. 现在lock还是被其他线程占用 那就睡一会, 返回值判断是否这次线程的唤醒是被中断唤醒 interrupted = true; &#125; &#125; &#125;finally &#123; if(failed)&#123; // 8. 在整个获取中出错(比如线程中断/超时) cancelAcquire(node); // 9. 清除 node 节点(清除的过程是先给 node 打上 CANCELLED标志, 然后再删除) &#125; &#125;&#125; 7.5 获取共享lock 方法 doAcquireSharedInterruptibly12345678910111213141516171819202122232425262728private void doAcquireSharedInterruptibly(int arg) throws InterruptedException&#123; final Node node = addWaiter(Node.SHARED); // 1. 将当前的线程封装成 Node 加入到 Sync Queue 里面 boolean failed = true; try &#123; for(;;)&#123; final Node p = node.predecessor(); // 2. 获取当前节点的前继节点 (当一个n在 Sync Queue 里面, 并且没有获取 lock 的 node 的前继节点不可能是 null) if(p == head)&#123; int r = tryAcquireShared(arg); // 3. 判断前继节点是否是head节点(前继节点是head, 存在两种情况 (1) 前继节点现在占用 lock (2)前继节点是个空节点, 已经释放 lock, node 现在有机会获取 lock); 则再次调用 tryAcquireShared 尝试获取一下 if(r &gt;= 0)&#123; setHeadAndPropagate(node, r); // 4. 获取 lock 成功, 设置新的 head, 并唤醒后继获取 readLock 的节点 p.next = null; // help GC failed = false; return; &#125; &#125; if(shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 5. 调用 shouldParkAfterFailedAcquire 判断是否需要中断(这里可能会一开始 返回 false, 但在此进去后直接返回 true(主要和前继节点的状态是否是 signal)) parkAndCheckInterrupt())&#123; // 6. 现在lock还是被其他线程占用 那就睡一会, 返回值判断是否这次线程的唤醒是被中断唤醒 throw new InterruptedException(); // 7. 若此次唤醒是 通过线程中断, 则直接抛出异常 &#125; &#125; &#125;finally &#123; if(failed)&#123; // 8. 在整个获取中出错(比如线程中断/超时) cancelAcquire(node); // 9. 清除 node 节点(清除的过程是先给 node 打上 CANCELLED标志, 然后再删除) &#125; &#125;&#125; 7.6 获取共享lock 方法 doAcquireSharedNanos12345678910111213141516171819202122232425262728293031323334353637383940private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException&#123; if (nanosTimeout &lt;= 0L)&#123; return false; &#125; final long deadline = System.nanoTime() + nanosTimeout; // 0. 计算超时的时间 final Node node = addWaiter(Node.SHARED); // 1. 将当前的线程封装成 Node 加入到 Sync Queue 里面 boolean failed = true; try &#123; for(;;)&#123; final Node p = node.predecessor(); // 2. 获取当前节点的前继节点 (当一个n在 Sync Queue 里面, 并且没有获取 lock 的 node 的前继节点不可能是 null) if(p == head)&#123; int r = tryAcquireShared(arg); // 3. 判断前继节点是否是head节点(前继节点是head, 存在两种情况 (1) 前继节点现在占用 lock (2)前继节点是个空节点, 已经释放 lock, node 现在有机会获取 lock); 则再次调用 tryAcquireShared 尝试获取一下 if(r &gt;= 0)&#123; setHeadAndPropagate(node, r); // 4. 获取 lock 成功, 设置新的 head, 并唤醒后继获取 readLock 的节点 p.next = null; // help GC failed = false; return true; &#125; &#125; nanosTimeout = deadline - System.nanoTime(); // 5. 计算还剩余的 timeout , 若小于0 则直接return if(nanosTimeout &lt;= 0L)&#123; return false; &#125; if(shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 6. 调用 shouldParkAfterFailedAcquire 判断是否需要中断(这里可能会一开始 返回 false, 但在此进去后直接返回 true(主要和前继节点的状态是否是 signal)) nanosTimeout &gt; spinForTimeoutThreshold)&#123;// 7. 在timeout 小于 spinForTimeoutThreshold 时 spin 的效率, 比 LockSupport 更高 LockSupport.parkNanos(this, nanosTimeout); &#125; if(Thread.interrupted())&#123; // 7. 若此次唤醒是 通过线程中断, 则直接抛出异常 throw new InterruptedException(); &#125; &#125; &#125;finally &#123; if (failed)&#123; // 8. 在整个获取中出错(比如线程中断/超时) cancelAcquire(node); // 10. 清除 node 节点(清除的过程是先给 node 打上 CANCELLED标志, 然后再删除) &#125; &#125;&#125; 7.7 释放共享lock当 Sync Queue中存在连续多个获取 共享lock的节点时, 会出现并发的唤醒后继节点(因为共享模式下获取lock后会唤醒近邻的后继节点来获取lock)。首先调用子类的 tryReleaseShared来进行释放 lock，然后判断是否需要唤醒后继节点来获取 lock 1234567891011121314151617181920212223private void doReleaseShared()&#123; for(;;)&#123; Node h = head; // 1. 获取 head 节点, 准备 release if(h != null &amp;&amp; h != tail)&#123; // 2. Sync Queue 里面不为 空 int ws = h.waitStatus; if(ws == Node.SIGNAL)&#123; // 3. h节点后面可能是 独占的节点, 也可能是 共享的, 并且请求了唤醒(就是给前继节点打标记 SIGNAL) if(!compareAndSetWaitStatus(h, Node.SIGNAL, 0))&#123; // 4. h 恢复 waitStatus 值置0 (为啥这里要用 CAS 呢, 因为这里的调用可能是在 节点刚刚获取 lock, 而其他线程又对其进行中断, 所用cas就出现失败) continue; // loop to recheck cases &#125; unparkSuccessor(h); // 5. 唤醒后继节点 &#125; else if(ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))&#123; //6. h后面没有节点需要唤醒, 则标识为 PROPAGATE 表示需要继续传递唤醒(主要是区别 独占节点最终状态0 (独占的节点在没有后继节点, 并且release lock 时最终 waitStatus 保存为 0)) continue; // loop on failed CAS // 7. 同样这里可能存在竞争 &#125; &#125; if(h == head)&#123; // 8. head 节点没变化, 直接 return(从这里也看出, 一个共享模式的 节点在其唤醒后继节点时, 只唤醒一个, 但是它会在获取 lock 时唤醒, 释放 lock 时也进行, 所以或导致竞争的操作) break; // head 变化了, 说明其他节点获取 lock 了, 自己的任务完成, 直接退出 &#125; &#125;&#125; 8. 总结本文主要讲过了抽象的队列式的同步器AQS的主要方法和实现原理。分别介绍了Node、Condition Queue、 Sync Queue、独占获取释放lock、共享获取释放lock的具体源码实现。AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它。 参考 Java并发之AQS详解 AbstractQueuedSynchronizer 源码分析 (基于Java 8)","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://blueskykong.com/categories/并发编程/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/tags/java/"}]},{"title":"并发编程的锁机制：synchronized和lock","slug":"lock","date":"2017-05-13T16:00:00.000Z","updated":"2017-12-27T14:22:49.000Z","comments":true,"path":"2017/05/14/lock/","link":"","permalink":"http://blueskykong.com/2017/05/14/lock/","excerpt":"","text":"并发编程中，锁是经常需要用到的，今天我们一起来看下Java中的锁机制：synchronized和lock。 1. 锁的种类锁的种类挺多，包括：自旋锁、自旋锁的其他种类、阻塞锁、可重入锁、读写锁、互斥锁、悲观锁、乐观锁、公平锁、可重入锁等等，其余就不列出了。我们这边重点看如下几种：可重入锁、读写锁、可中断锁、公平锁。 1.1 可重入锁如果锁具备可重入性，则称作为可重入锁。synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举比如说，当一个线程执行到method1 的synchronized方法时，而在method1中会调用另外一个synchronized方法method2，此时该线程不必重新去申请锁，而是可以直接执行方法method2。 1.2 读写锁读写锁将对一个资源的访问分成了2个锁，如文件，一个读锁和一个写锁。正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。可以通过readLock()获取读锁，通过writeLock()获取写锁。 1.3 可中断锁可中断锁，即可以中断的锁。在Java中，synchronized就不是可中断锁，而Lock是可中断锁。如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。 Lock接口中的lockInterruptibly()方法就体现了Lock的可中断性。 1.4 公平锁公平锁即尽量以请求锁的顺序来获取锁。同时有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该锁，这种就是公平锁。 非公平锁即无法保证锁的获取是按照请求锁的顺序进行的，这样就可能导致某个或者一些线程永远获取不到锁。 synchronized是非公平锁，它无法保证等待的线程获取锁的顺序。对于ReentrantLock和ReentrantReadWriteLock，默认情况下是非公平锁，但是可以设置为公平锁。 2. synchronized和lock的用法2.1 synchronizedsynchronized是Java的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。简单总结如下四种用法。 2.1.1 代码块对某一代码块使用，synchronized后跟括号，括号里是变量，一次只有一个线程进入该代码块。 12345public int synMethod(int m)&#123; synchronized(m) &#123; //... &#125; &#125; 2.1.2 方法声明时方法声明时使用，放在范围操作符之后,返回类型声明之前。即一次只能有一个线程进入该方法，其他线程要想在此时调用该方法，只能排队等候。 123public synchronized void synMethod() &#123; //...&#125; 2.1.3 synchronized后面括号里是对象synchronized后面括号里是一对象，此时线程获得的是对象锁。 12345public void test() &#123; synchronized (this) &#123; //... &#125;&#125; 2.1.4 synchronized后面括号里是类synchronized后面括号里是类，如果线程进入，则线程在该类中所有操作不能进行，包括静态变量和静态方法，对于含有静态方法和静态变量的代码块的同步，通常使用这种方式。 2.2 LockLock接口主要相关的类和接口如下。 ReadWriteLock是读写锁接口，其实现类为ReetrantReadWriteLock。ReetrantLock实现了Lock接口。 2.2.1 LockLock中有如下方法： 1234567public interface Lock &#123; void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; lock：用来获取锁，如果锁被其他线程获取，处于等待状态。如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。 lockInterruptibly：通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。 tryLock：tryLock方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 tryLock（long，TimeUnit）：与tryLock类似，只不过是有等待时间，在等待时间内获取到锁返回true，超时返回false。 unlock：释放锁，一定要在finally块中释放 2.2.2 ReetrantLock实现了Lock接口，可重入锁，内部定义了公平锁与非公平锁。默认为非公平锁： 123public ReentrantLock() &#123; sync = new NonfairSync(); &#125; 可以手动设置为公平锁： 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; 2.2.3 ReadWriteLock1234public interface ReadWriteLock &#123; Lock readLock(); //获取读锁 Lock writeLock(); //获取写锁 &#125; 一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。ReentrantReadWirteLock实现了ReadWirteLock接口，并未实现Lock接口。不过要注意的是： 如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。 2.2.4 ReetrantReadWriteLockReetrantReadWriteLock同样支持公平性选择，支持重进入，锁降级。 123456789101112131415161718192021222324public class RWLock &#123; static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); static ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(); static Lock r = rwLock.readLock(); static Lock w = rwLock.writeLock(); //读 public static final Object get(String key)&#123; r.lock(); try &#123; return map.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; //写 public static final Object put(String key, Object value)&#123; w.lock(); try &#123; return map.put(key, value); &#125; finally &#123; w.unlock(); &#125; &#125;&#125; 只需在读操作时获取读锁，写操作时获取写锁。当写锁被获取时，后续的读写操作都会被阻塞，写锁释放后，所有操作继续执行。 3. 两种锁的比较3.1 synchronized和lock的区别 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 Lock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离） 性能上来说，在资源竞争不激烈的情形下，Lock性能稍微比synchronized差点（编译程序通常会尽可能的进行优化synchronized）。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。 3.2 性能比较下面对synchronized与Lock进行性能测试，分别开启10个线程，每个线程计数到1000000，统计两种锁同步所花费的时间。网上也能找到这样的例子。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class TestAtomicIntegerLock &#123; private static int synValue; public static void main(String[] args) &#123; int threadNum = 10; int maxValue = 1000000; testSync(threadNum, maxValue); testLocck(threadNum, maxValue); &#125; //test synchronized public static void testSync(int threadNum, int maxValue) &#123; Thread[] t = new Thread[threadNum]; Long begin = System.nanoTime(); for (int i = 0; i &lt; threadNum; i++) &#123; Lock locks = new ReentrantLock(); synValue = 0; t[i] = new Thread(() -&gt; &#123; for (int j = 0; j &lt; maxValue; j++) &#123; locks.lock(); try &#123; synValue++; &#125; finally &#123; locks.unlock(); &#125; &#125; &#125;); &#125; for (int i = 0; i &lt; threadNum; i++) &#123; t[i].start(); &#125; //main线程等待前面开启的所有线程结束 for (int i = 0; i &lt; threadNum; i++) &#123; try &#123; t[i].join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"使用lock所花费的时间为：\" + (System.nanoTime() - begin)); &#125; // test Lock public static void testLocck(int threadNum, int maxValue) &#123; int[] lock = new int[0]; Long begin = System.nanoTime(); Thread[] t = new Thread[threadNum]; for (int i = 0; i &lt; threadNum; i++) &#123; synValue = 0; t[i] = new Thread(() -&gt; &#123; for (int j = 0; j &lt; maxValue; j++) &#123; synchronized(lock) &#123; ++synValue; &#125; &#125; &#125;); &#125; for (int i = 0; i &lt; threadNum; i++) &#123; t[i].start(); &#125; //main线程等待前面开启的所有线程结束 for (int i = 0; i &lt; threadNum; i++) &#123; try &#123; t[i].join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"使用synchronized所花费的时间为：\" + (System.nanoTime() - begin)); &#125;&#125; 测试结果的差异还是比较明显的，Lock的性能明显高于synchronized。本次测试基于JDK1.8。 12使用lock所花费的时间为：436667997使用synchronized所花费的时间为：616882878 JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞的是实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。多线程环境下，synchronized的吞吐量下降的非常严重，而ReentrankLock则能基本保持在同一个比较稳定的水平上。 到了JDK1.6，发生了变化，对synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在JDK1.6上synchronize的性能并不比Lock差。官方也表示，他们也更支持synchronize，在未来的版本中还有优化余地，所以还是提倡在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步。 4. 总结本文主要对并发编程中的锁机制synchronized和lock，进行详解。synchronized是基于JVM实现的，内置锁，Java中的每一个对象都可以作为锁。对于同步方法，锁是当前实例对象。对于静态同步方法，锁是当前对象的Class对象。对于同步方法块，锁是Synchonized括号里配置的对象。Lock是基于在语言层面实现的锁，Lock锁可以被中断，支持定时锁。Lock可以提高多个线程进行读操作的效率。通过对比得知，Lock的效率是明显高于synchronized关键字的，一般对于数据结构设计或者框架的设计都倾向于使用Lock而非Synchronized。 参考 Lock和synchronized比较详解 Java中Lock和synchronized的比较和应用 Java并发编程（六）–Lock与Synchronized的比较","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://blueskykong.com/categories/并发编程/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/tags/java/"}]},{"title":"深入理解Spring IoC（控制反转）","slug":"ioc","date":"2017-04-21T16:00:00.000Z","updated":"2017-12-24T08:42:59.000Z","comments":true,"path":"2017/04/22/ioc/","link":"","permalink":"http://blueskykong.com/2017/04/22/ioc/","excerpt":"","text":"IoC概念IoC（Inversion of Control，控制倒转），是spring的核心，贯穿始终。所谓IoC，对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。所有的类都会在spring容器中登记，告诉spring你是个什么，你需要什么，然后spring会在系统运行到适当的时候，把你要的东西主动给你，同时也把你交给其他需要你的东西。所有的类的创建、销毁都由 spring来控制，也就是说控制对象生存周期的不再是引用它的对象，而是spring。对于某个具体的对象而言，以前是它控制其他对象，现在是所有对象都被spring控制，所以这叫控制反转。 IoC 的一个重点是在系统运行中（runtime），动态的向某个对象提供它所需要的其他对象。这一点是通过DI（Dependency Injection，依赖注入）来实现的。比如对象A需要操作数据库，以前我们总是要在A中自己编写代码来获得一个Connection对象，有了 spring我们就只需要告诉spring，A中需要一个Connection，至于这个Connection怎么构造，何时构造，A不需要知道。在系统运行时，spring会在适当的时候制造一个Connection，然后像打针一样，注射到A当中，这样就完成了对各个对象之间关系的控制。A需要依赖 Connection才能正常运行，而这个Connection是由spring注入到A中的，依赖注入的名字就这么来的。那么DI是如何实现的呢？ Java 1.3之后一个重要特征是反射（reflection），它允许程序在运行的时候动态的生成对象、执行对象的方法、改变对象的属性，spring就是通过反射来实现注入的。 上图可以看出，之前由客户端主动创建的行为都变为了由IoC容器进行创建。传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对 象的创建；IoC容器控制了对象；控制什么？主要控制了外部资源获取（不只是对象包括比如文件等）；传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。 Spring IoC结构Spring 启动时读取应用程序提供的Bean配置信息，并在Spring容器中生成一份相应的Bean配置注册表，然后根据这张注册表实例化Bean，装配好Bean之间的依赖关系，为上层应用提供准备就绪的运行环境。 Spring 通过一个配置文件描述 Bean 及 Bean 之间的依赖关系，利用 Java 语言的反射功能实例化 Bean 并建立 Bean 之间的依赖关系。 Spring 的 IoC 容器在完成这些底层工作的基础上，还提供了 Bean 实例缓存、生命周期管理、 Bean 实例代理、事件发布、资源装载等高级服务。 BeanDefinitionRegistry： Spring 配置文件中每一个节点元素在 Spring 容器里都通过一个 BeanDefinition 对象表示，它描述了 Bean 的配置信息。而 BeanDefinitionRegistry 接口提供了向容器手工注册 BeanDefinition 对象的方法。 BeanFactory 接口位于类结构树的顶端 ，它最主要的方法就是 getBean(String beanName)，该方法从容器中返回特定名称的 Bean，BeanFactory 的功能通过其他的接口得到不断扩展： ListableBeanFactory：该接口定义了访问容器中 Bean 基本信息的若干方法，如查看Bean 的个数、获取某一类型 Bean 的配置名、查看容器中是否包括某一 Bean 等方法； HierarchicalBeanFactory：父子级联 IoC 容器的接口，子容器可以通过接口方法访问父容器； 通过 HierarchicalBeanFactory 接口， Spring 的 IoC 容器可以建立父子层级关联的容器体系，子容器可以访问父容器中的 Bean，但父容器不能访问子容器的 Bean。Spring 使用父子容器实现了很多功能，比如在 Spring MVC 中，展现层 Bean 位于一个子容器中，而业务层和持久层的 Bean 位于父容器中。这样，展现层 Bean 就可以引用业务层和持久层的 Bean，而业务层和持久层的 Bean 则看不到展现层的 Bean。 ConfigurableBeanFactory：是一个重要的接口，增强了 IoC 容器的可定制性，它定义了设置类装载器、属性编辑器、容器初始化后置处理器等方法； AutowireCapableBeanFactory：定义了将容器中的 Bean 按某种规则（如按名字匹配、按类型匹配等）进行自动装配的方法； SingletonBeanRegistry：定义了允许在运行期间向容器注册单实例 Bean 的方法； IoC容器的初始化ApplicationContext 由 BeanFactory 派生而来，提供了更多面向实际应用的功能。在BeanFactory 中，很多功能需要以编程的方式实现，而在 ApplicationContext 中则可以通过配置的方式实现。 ApplicationContext 继承了 HierarchicalBeanFactory 和 ListableBeanFactory 接口，在此基础上，还通过多个其他的接口扩展了 BeanFactory 的功能： ClassPathXmlApplicationContext：默认从类路径加载配置文件 FileSystemXmlApplicationContext：默认从文件系统中装载配置文件 ApplicationEventPublisher：让容器拥有发布应用上下文事件的功能，包括容器启动事件、关闭事件等。实现了 ApplicationListener 事件监听接口的 Bean 可以接收到容器事件 ， 并对事件进行响应处理。在 ApplicationContext 抽象实现类AbstractApplicationContext 中，我们可以发现存在一个 ApplicationEventMulticaster，它负责保存所有监听器，以便在容器产生上下文事件时通知这些事件监听者。 MessageSource：为应用提供 i18n 国际化消息访问的功能； ResourcePatternResolver ： 所 有 ApplicationContext 实现类都实现了类似于PathMatchingResourcePatternResolver 的功能，可以通过带前缀的 Ant 风格的资源文件路径装载 Spring 的配置文件。 LifeCycle：该接口是 Spring 2.0 加入的，该接口提供了 start()和 stop()两个方法，主要用于控制异步处理过程。在具体使用时，该接口同时被 ApplicationContext 实现及具体 Bean 实现， ApplicationContext 会将 start/stop 的信息传递给容器中所有实现了该接口的 Bean，以达到管理和控制 JMX、任务调度等目的。 ConfigurableApplicationContext 扩展于 ApplicationContext，它新增加了两个主要的方法： refresh()和 close()，让 ApplicationContext 具有启动、刷新和关闭应用上下文的能力。在应用上下文关闭的情况下调用 refresh()即可启动应用上下文，在已经启动的状态下，调用 refresh()则清除缓存并重新装载配置信息，而调用close()则可关闭应用上下文。这些接口方法为容器的控制管理带来了便利，但作为开发者，我们并不需要过多关心这些方法。 Bean的生命周期1．当调用者通过 getBean(beanName)向容器请求某一个 Bean 时，如果容器注册了org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessor 接口，在实例化 Bean 之前，将调用接口的 postProcessBeforeInstantiation()方法； 2．根据配置情况调用 Bean 构造函数或工厂方法实例化 Bean； 3．如果容器注册了 InstantiationAwareBeanPostProcessor 接口，在实例化 Bean 之后，调用该接口的 postProcessAfterInstantiation()方法，可在这里对已经实例化的对象进行一些“梳妆打扮”； 4．如果 Bean 配置了属性信息，容器在这一步着手将配置值设置到 Bean 对应的属性中，不过在设置每个属性之前将先调用InstantiationAwareBeanPostProcessor 接口的postProcessPropertyValues()方法； 5．调用 Bean 的属性设置方法设置属性值； 6．如果 Bean 实现了 org.springframework.beans.factory.BeanNameAware 接口，将调用setBeanName()接口方法，将配置文件中该 Bean 对应的名称设置到 Bean 中； 7．如果 Bean 实现了 org.springframework.beans.factory.BeanFactoryAware 接口，将调用 setBeanFactory()接口方法，将 BeanFactory 容器实例设置到 Bean 中； 8．如果 BeanFactory 装配了 org.springframework.beans.factory.config.BeanPostProcessor后处理器，将调用 BeanPostProcessor 的 Object postProcessBeforeInitialization(Object bean, String beanName)接口方法对 Bean 进行加工操作。其中入参 bean 是当前正在处理的 Bean，而 beanName 是当前 Bean 的配置名，返回的对象为加工处理后的 Bean。用户可以使用该方法对某些 Bean 进行特殊的处理，甚至改变 Bean 的行为， BeanPostProcessor 在 Spring 框架中占有重要的地位，为容器提供对 Bean 进行后续加工处理的切入点， Spring 容器所提供的各种“神奇功能”（如 AOP，动态代理等）都通过 BeanPostProcessor 实施； 9．如果 Bean 实现了 InitializingBean 的接口，将调用接口的 afterPropertiesSet()方法； 10．如果在通过 init-method 属性定义了初始化方法，将执行这个方法； 11．BeanPostProcessor 后处理器定义了两个方法：其一是 postProcessBeforeInitialization() 在第 8 步调用；其二是 Object postProcessAfterInitialization(Object bean, String beanName)方法，这个方法在此时调用，容器再次获得对 Bean 进行加工处理的机会； 12．如果在中指定 Bean 的作用范围为 scope=“prototype”，将 Bean 返回给调用者，调用者负责 Bean 后续生命的管理， Spring 不再管理这个 Bean 的生命周期；如果作用范围设置为 scope=“singleton”，则将 Bean 放入到 Spring IoC 容器的缓存池中，并将 Bean引用返回给调用者， Spring 继续对这些 Bean 进行后续的生命管理； 13．对于 scope=“singleton”的 Bean，当容器关闭时，将触发 Spring 对 Bean 的后续生命周期的管理工作，首先如果 Bean 实现了 DisposableBean 接口，则将调用接口的afterPropertiesSet()方法，可以在此编写释放资源、记录日志等操作； 14．对于 scope=“singleton”的 Bean，如果通过的 destroy-method 属性指定了 Bean 的销毁方法， Spring 将执行 Bean 的这个方法，完成 Bean 资源的释放等操作。 可以将这些方法大致划分为三类： Bean 自身的方法：如调用 Bean 构造函数实例化 Bean，调用 Setter 设置 Bean 的属性值以及通过的 init-method 和 destroy-method 所指定的方法； Bean 级生命周期接口方法：如 BeanNameAware、 BeanFactoryAware、 InitializingBean 和 DisposableBean，这些接口方法由 Bean 类直接实现； 容器级生命周期接口方法：后处理器接口一般不由 Bean 本身实现，它们独立于 Bean，实现类以容器附加装置的形式注册到 Spring 容器中并通过接口反射为 Spring 容器预先识别。当Spring 容器创建任何 Bean 的时候，这些后处理器都会发生作用，所以这些后处理器的影响是全局性的。当然，用户可以通过合理地编写后处理器，让其仅对感兴趣Bean进行加工处理。 ApplicationContext 和 BeanFactory 另一个最大的不同之处在于：ApplicationContext会利用 Java 反射机制自动识别出配置文件中定义的 BeanPostProcessor、 InstantiationAwareBeanPostProcessor 和 BeanFactoryPostProcessor，并自动将它们注册到应用上下文中；而后者需要在代码中通过手工调用 addBeanPostProcessor()方法进行注册。这也是为什么在应用开发时，我们普遍使用 ApplicationContext 而很少使用 BeanFactory 的原因之一。 IOC容器工作机制容器启动过程web环境下Spring容器、SpringMVC容器启动过程： 对于一个web应用，其部署在web容器中，web容器提供其一个全局的上下文环境，这个上下文就是ServletContext，其为后面的spring IoC容器提供宿主环境； 在web.xml中会提供有contextLoaderListener（或ContextLoaderServlet）。在web容器启动时，会触发容器初始化事件，此时contextLoaderListener会监听到这个事件，其contextInitialized方法会被调用，在这个方法中，spring会初始化一个启动上下文，这个上下文被称为根上下文，即WebApplicationContext，这是一个接口类，确切的说，其实际的实现类是XmlWebApplicationContext。这个就是spring的IoC容器，其对应的Bean定义的配置由web.xml中的context-param标签指定。在这个IoC容器初始化完毕后，spring容器以WebApplicationContext.ROOTWEBAPPLICATIONCONTEXTATTRIBUTE为属性Key，将其存储到ServletContext中，便于获取； contextLoaderListener监听器初始化完毕后，开始初始化web.xml中配置的Servlet，这个servlet可以配置多个，以最常见的DispatcherServlet为例（Spring MVC），这个servlet实际上是一个标准的前端控制器，用以转发、匹配、处理每个servlet请求。DispatcherServlet上下文在初始化的时候会建立自己的IoC上下文容器，用以持有spring mvc相关的bean，这个servlet自己持有的上下文默认实现类也是XmlWebApplicationContext。在建立DispatcherServlet自己的IoC上下文时，会利用WebApplicationContext.ROOTWEBAPPLICATIONCONTEXTATTRIBUTE先从ServletContext中获取之前的根上下文(即WebApplicationContext)作为自己上下文的parent上下文（即第2步中初始化的XmlWebApplicationContext作为自己的父容器）。有了这个parent上下文之后，再初始化自己持有的上下文（这个DispatcherServlet初始化自己上下文的工作在其initStrategies方法中可以看到，大概的工作就是初始化处理器映射、视图解析等）。初始化完毕后，spring以与servlet的名字相关(此处不是简单的以servlet名为Key，而是通过一些转换)的属性为属性Key，也将其存到ServletContext中，以便后续使用。这样每个servlet就持有自己的上下文，即拥有自己独立的bean空间，同时各个servlet共享相同的bean，即根上下文定义的那些bean。 Bean加载过程Spring的高明之处在于，它使用众多接口描绘出了所有装置的蓝图，构建好Spring的骨架，继而通过继承体系层层推演，不断丰富，最终让Spring成为有血有肉的完整的框架。所以查看Spring框架的源码时，有两条清晰可见的脉络： 1）接口层描述了容器的重要组件及组件间的协作关系； 2）继承体系逐步实现组件的各项功能。 接口层清晰地勾勒出Spring框架的高层功能，框架脉络呼之欲出。有了接口层抽象的描述后，不但Spring自己可以提供具体的实现，任何第三方组织也可以提供不同实现， 可以说Spring完善的接口层使框架的扩展性得到了很好的保证。纵向继承体系的逐步扩展，分步骤地实现框架的功能，这种实现方案保证了框架功能不会堆积在某些类的身上，造成过重的代码逻辑负载，框架的复杂度被完美地分解开了。 Spring组件按其所承担的角色可以划分为两类： 1）物料组件：Resource、BeanDefinition、PropertyEditor以及最终的Bean等，它们是加工流程中被加工、被消费的组件，就像流水线上被加工的物料； BeanDefinition：Spring通过BeanDefinition将配置文件中的配置信息转换为容器的内部表示，并将这些BeanDefinition注册到BeanDefinitionRegistry中。Spring容器的后续操作直接从BeanDefinitionRegistry中读取配置信息。 2）加工设备组件：ResourceLoader、BeanDefinitionReader、BeanFactoryPostProcessor、InstantiationStrategy以及BeanWrapper等组件像是流水线上不同环节的加工设备，对物料组件进行加工处理。 InstantiationStrategy：负责实例化Bean操作，相当于Java语言中new的功能，并不会参与Bean属性的配置工作。属性填充工作留待BeanWrapper完成 BeanWrapper：继承了PropertyAccessor和PropertyEditorRegistry接口，BeanWrapperImpl内部封装了两类组件：被封装的目标Bean和一套用于设置Bean属性的属性编辑器；具有三重身份：Bean包裹器、属性访问器、属性编辑器注册表。 PropertyAccessor：定义了各种访问Bean属性的方法。PropertyEditorRegistry：属性编辑器的注册表 完整Bean的作业流程 １、ResourceLoader从存储介质中加载Spring配置信息，并使用Resource表示这个配置文件的资源； ２、BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中每一个解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中； ３、容器扫描BeanDefinitionRegistry中的BeanDefinition，使用Java的反射机制自动识别出Bean工厂后处理后器（实现BeanFactoryPostProcessor接口）的Bean，然后调用这些Bean工厂后处理器对BeanDefinitionRegistry中的BeanDefinition进行加工处理。主要完成以下两项工作： 1）对使用到占位符的元素标签进行解析，得到最终的配置值，这意味对一些半成品式的BeanDefinition对象进行加工处理并得到成品的BeanDefinition对象； 2）对BeanDefinitionRegistry中的BeanDefinition进行扫描，通过Java反射机制找出所有属性编辑器的Bean（实现java.beans.PropertyEditor接口的Bean），并自动将它们注册到Spring容器的属性编辑器注册表中（PropertyEditorRegistry）； 4．Spring容器从BeanDefinitionRegistry中取出加工后的BeanDefinition，并调用InstantiationStrategy着手进行Bean实例化的工作； 5．在实例化Bean时，Spring容器使用BeanWrapper对Bean进行封装，BeanWrapper提供了很多以Java反射机制操作Bean的方法，它将结合该Bean的BeanDefinition以及容器中属性编辑器，完成Bean属性的设置工作； 6．利用容器中注册的Bean后处理器（实现BeanPostProcessor接口的Bean）对已经完成属性设置工作的Bean进行后续加工，直接装配出一个准备就绪的Bean。 总结Spring IOC容器主要有继承体系底层的BeanFactory、高层的ApplicationContext和WebApplicationContext。Bean有自己的生命周期。容器启动原理：Spring应用的IOC容器通过tomcat的Servlet或Listener监听启动加载；Spring MVC的容器由DispatchServlet作为入口加载；Spring容器是Spring MVC容器的父容器。容器加载Bean原理：BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中每一个解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中；容器扫描BeanDefinitionRegistry中的BeanDefinition；调用InstantiationStrategy进行Bean实例化的工作；使用BeanWrapper完成Bean属性的设置工作；单例Bean缓存池：Spring 在 DefaultSingletonBeanRegistry 类中提供了一个用于缓存单实例 Bean 的缓存器，它是一个用 HashMap 实现的缓存器，单实例的 Bean 以 beanName 为键保存在这个HashMap 中。 本文主要转载自Spring IOC原理总结。 参考Spring IOC原理总结","categories":[{"name":"java","slug":"java","permalink":"http://blueskykong.com/categories/java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blueskykong.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://blueskykong.com/tags/Spring/"}]},{"title":"设计模式之中介者模式","slug":"designMediate","date":"2017-04-02T16:00:00.000Z","updated":"2018-02-24T16:11:19.000Z","comments":true,"path":"2017/04/03/designMediate/","link":"","permalink":"http://blueskykong.com/2017/04/03/designMediate/","excerpt":"","text":"中介者模式属于行为型模式。 中介者模式的定义定义：用一个中介者对象来封装一系列的对象交互。中介者使得各对象不需要显式地相互引用，从而使其松散耦合，而且可以独立地改变它们之间的交互。 在软件开发中，通过提供一个统一的接口让系统不同部分进行通信。一般，如果系统有很多子模块需要直接沟通，都要创建一个中央控制点让其各模块通过中央控制点进行交互。中介者模式可以让这些子模块不需要直接沟通，从而达到进行解耦的目的。在现实生活中，有很多中介者模式的使用，例如二手车平台、婚姻中介和房产中介，通过平台方介入进行协调供需之间的关系。 中介者模式的结构中介者模式有如下角色： Mediator中介者定义一个接口用于与各同事（Colleague）对象通信。 ConcreteMediator具体中介者通过协调各同事对象实现协作行为，了解并维护它的各个同事。 Colleague抽象同事类。 Colleagueclass具体同事类。每个具体同事类都只需要知道自己的行为即可，但是他们都需要认识中介者 中介者模式的实现定义抽象Mediator： 123public abstract class Mediator &#123; public abstract void notice(String content,Colleague coll);&#125; 定义抽象同事Colleague： 123456789public abstract class Colleague &#123; protected String name; protected Mediator mediator; public Colleague(String name, Mediator mediator) &#123; this.name = name; this.mediator = mediator; &#125;&#125; 具体同事类继承自Colleague，此刻就可以与中介者mediator进行通信了。 123456789101112public class ColleagueA extends Colleague &#123; public ColleagueA(String name, Mediator mediator) &#123; super(name, mediator); &#125; public void getNotice(String message)&#123; System.out.println(\"同事A\"+name+\"获得信息\"+message); &#125; //同事A与中介者通信 public void contact(String message)&#123; mediator.notice(message, this); &#125;&#125; 12345678910111213public class ColleagueB extends Colleague &#123; public ColleagueB(String name, Mediator mediator) &#123; super(name, mediator); &#125; public void getNotice(String message)&#123; System.out.println(\"同事B\"+name+\"获得信息\"+message); &#125; //同事B与中介者通信 public void contact(String message)&#123; mediator.notice(message, this); &#125;&#125; 定义具体中介者ConcreteMediator,具体中介者通过协调各同事对象实现协作行为，了解并维护它的各个同事。 1234567891011121314@Datapublic class ConcreteMediator extends Mediator &#123; ColleagueA collA; ColleagueB collB; @Override public void notice(String content, Colleague coll) &#123; if (coll == collA) &#123; collB.getNotice(content); &#125; else &#123; collA.getNotice(content); &#125; &#125;&#125; 定义中介者与具体同事类，中介者知晓每一个具体的Colleague类。 123456789101112public class Client &#123; // 中介者，ColleagueA、ColleagueB public static void main(String[] args) &#123; ConcreteMediator mediator = new ConcreteMediator(); ColleagueA colleagueA = new ColleagueA(\"A\", mediator); ColleagueB colleagueB = new ColleagueB(\"B\", mediator); mediator.setCollA(colleagueA); mediator.setCollB(colleagueB); colleagueA.contact(\"我是A，我要联系B！\"); colleagueB.contact(\"我是B，收到A消息！\"); &#125;&#125; 运行结果很简单，读者自己试一下吧。 总结中介者模式简化了对象之间的关系，将系统的各个对象之间的相互关系进行封装，将各个同事类解耦，使得系统变为松耦合。并且提供系统的灵活性，使得各个同事对象独立而易于复用。 其缺点也很明显： 中介者模式中，中介者角色承担了较多的责任，所以一旦这个中介者对象出现了问题，整个系统将会受到重大的影响。 新增加一个同事类时，不得不去修改抽象中介者类和具体中介者类，此时可以使用观察者模式和状态模式来解决这个问题。 中介者模式适用于当对象之间的交互变多时，为了防止一个类会涉及修改其他类的行为，可以使用中介者模式，将系统从网状结构变为以中介者为中心的星型结构。 vs 外观模式外观模式主要是以封装和隔离为主要任务，中介者则是协调同事类之间的关系，因此，中介者具有部分业务的逻辑控制。他们之间的主要区别为： 外观模式的子系统如果脱离外观模式还是可以运行的，而中介者模式增加了业务逻辑，同事类不能脱离中介者而独自存在。 外观模式将子系统的逻辑隐藏，用户不知道子系统的存在，而中介者模式中，用户知道同事类的存在。 参考 设计模式（十四）中介者模式 Java设计模式系列之中介者模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之命令模式","slug":"designTerminal","date":"2017-03-30T16:00:00.000Z","updated":"2018-02-11T01:45:21.000Z","comments":true,"path":"2017/03/31/designTerminal/","link":"","permalink":"http://blueskykong.com/2017/03/31/designTerminal/","excerpt":"","text":"命令模式是一种行为模式。 命令模式的定义命令模式是一个高内聚的模式，将一个请求封装成一个对象，从而让你使用不同的请求把客户端参数化，对请求排队或者记录日志，可以提供命令的撤销和恢复功能。命令模式的核心在于引入了命令类，通过命令类来降低发送者和接收者的耦合度，请求发送者只需指定一个命令对象，再通过命令对象来调用请求接收者的处理方法。 命令模式可以将请求发送者和接收者完全解耦，发送者与接收者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。 命令模式的结构命令模式包含如下角色： Receiver接收者角色命令接收者模式，命令传递到这里执行对应的操作。 Command命令角色需要执行的命令都在这里声明 Invoker调用者角色接收到命令，并执行命令，也就是命令的发动者和调用者 命令模式的实现抽象Command类。 123public abstract class Command &#123; public abstract void execute(); &#125; 调用者Invoker类。 123456789101112131415161718public class Invoker &#123; private Command command; //构造注入 public Invoker(Command command) &#123; this.command = command; &#125; //设值注入 public void setCommand(Command command) &#123; this.command = command; &#125; //业务方法，用于调用命令类的execute()方法 public void call() &#123; command.execute(); &#125; &#125; 具体Command类，设置对应的接收者。 123456789101112public class ConcreteCommand extends Command &#123; private Receiver receiver; //维持一个对请求接收者对象的引用 public ConcreteCommand(Receiver receiver) &#123; super(); this.receiver = receiver; &#125; public void execute() &#123; receiver.action(); //调用请求接收者的业务处理方法action() &#125; &#125; 抽象接收者。 123public abstract class Receiver &#123; public abstract void action();&#125; 第一个接收者。 12345678public class ConcreteReceiver extends Receiver&#123; @Override public void action() &#123; System.out.println(\"ConcreteReceiver receives the command!\"); &#125;&#125; 第二个接收者。 12345678public class ConcreteReceiver2 extends Receiver&#123; @Override public void action() &#123; System.out.println(\"ConcreteReceiver2 receives the command!\"); &#125;&#125; 测试类，创建了连个接收者，分别发送指令。 1234567891011121314151617public class Client &#123; public static void main(String[] args) &#123; Receiver receiver1 = new ConcreteReceiver(); Command command1 = new ConcreteCommand(receiver1); Invoker invoker = new Invoker(); invoker.setCommand(command1); invoker.call(); Receiver receiver2 = new ConcreteReceiver2(); Command command2 = new ConcreteCommand(receiver2); invoker.setCommand(command2); invoker.call(); &#125;&#125; 总结命令模式的本质是对请求进行封装，一个请求对应于一个命令，将发出命令的责任和执行命令的责任分割开。每一个命令都是一个操作：请求的一方发出请求要求执行一个操作；接收的一方收到请求，并执行相应的操作。命令模式允许请求的一方和接收的一方独立开来，使得请求的一方不必知道接收请求的一方的接口，更不必知道请求如何被接收、操作是否被执行、何时被执行，以及是怎么被执行的。命令模式的关键在于引入了抽象命令类，请求发送者针对抽象命令类编程，只有实现了抽象命令类的具体命令才与请求接收者相关联。 命令模式的优点是： 类间解藕调用者角色与接受者角色之间没有任何依赖关系，调用者实现功能时只需要调用Command抽象类的execute方法就可以，不需要知道到底是哪个接收者执行。 可扩展性Command子类可以非常容易的扩展，而调用者Invoker和高层次的模块Client不产生严重的代码藕合 其缺点是造成了类膨胀，如果有多个子命令对应多个Command子类，比较繁琐。 参考 java设计模式之命令模式 设计模式之命令模式—Command Pattern","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之迭代子模式","slug":"designIterator","date":"2017-03-27T16:00:00.000Z","updated":"2018-02-08T07:50:19.000Z","comments":true,"path":"2017/03/28/designIterator/","link":"","permalink":"http://blueskykong.com/2017/03/28/designIterator/","excerpt":"","text":"迭代子模式又叫游标(Cursor)模式，是对象的行为模式。 迭代子模式的定义迭代子模式可以顺序地访问一个聚集中的元素而不必暴露聚集的内部表象。我们常见的集合有很多种类，其顶层数据存储和组织方式的不同导致了我们在对数据进行遍历的时候存在一些差异，迭代器模式就是通过实现某种统一的方式来实现对不同的集合的遍历，同时又不暴露出其底层的数据存储和组织方式。 例如，如果没有使用Iterator，遍历一个数组的方法是使用索引： 123for(int i=0; i&lt;array.size(); i++) &#123; get(i)&#125; 而访问一个链表（LinkedList）又必须使用while循环： 123while((e=e.next())!=null) &#123; e.data()&#125; 以上两种方法客户端都必须事先知道集合的内部结构，访问代码和集合本身是紧耦合，无法将访问逻辑从集合类和客户端代码中分离出来，每一种集合对应一种遍历方法，客户端代码无法复用。 更恐怖的是，如果以后需要把ArrayList更换为LinkedList，则原来的客户端代码必须全部重写。 为解决以上问题，Iterator模式总是用同一种逻辑来遍历集合： 12for(Iterator it = yourCollection.iterater(); it.hasNext(); ) &#123; ... &#125; 客户端自身不维护遍历集合的”指针”，所有的内部状态（如当前元素位置，是否有下一个元素）都由Iterator来维护，而这个Iterator由集合类通过工厂方法生成，因此，它知道如何遍历整个集合。客户端从不直接和集合类打交道，它总是控制Iterator，向它发送”向前”，”向后”，”取当前元素”的命令，就可以间接遍历整个集合。 迭代子模式的结构迭代模式中有如下的角色： 迭代器角色（Iterator）: 负责定义访问和遍历元素的接口。 具体迭代器角色（Concrete Iterator）：实现迭代器接口，并要记录遍历中的当前位置。 容器角色(Container): 负责提供创建具体迭代器角色的接口。 具体容器角色（Concrete Container）：实现创建具体迭代器角色的接口， 这个具体迭代器角色与该容器的结构相关。 迭代子模式的实现迭代器接口实现，定义了获取第一个节点的方法，前一个节点和后一个节点，以及判断是否有下一个节点。 123456789public interface Iterator &#123; public Object first(); public Object previous(); public Object next(); public boolean hasNext();&#125; 具体实现迭代器，实现上述接口定义的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142public class MyIterator implements Iterator&#123; private List&lt;Object&gt; list; private int index = 0; public MyIterator(List&lt;Object&gt; list) &#123; this.list = list; &#125; @Override public Object previous() &#123; if((this.index - 1) &lt; 0)&#123; return null; &#125;else&#123; return this.list.get(--index); &#125; &#125; @Override public Object next() &#123; if((this.index + 1) &gt;= this.list.size())&#123; return null; &#125;else&#123; return this.list.get(++index); &#125; &#125; @Override public boolean hasNext() &#123; if(this.index &lt; (this.list.size() - 1))&#123; return true; &#125; return false; &#125; @Override public Object first() &#123; if(this.list.size() &lt;= 0)&#123; return null; &#125;else&#123; return this.list.get(0); &#125; &#125;&#125; 容器定义，定义了两个抽象方法，用来设置具体的迭代器实现以及注入容器中的元素。 123456public abstract class Container &#123; public abstract Iterator iterator(); public abstract void put(Object obj);&#125; 具体的容器类基于List，实现抽象方法。 123456789101112131415public class MyContainer extends Container&#123; private List&lt;Object&gt; list; public MyContainer() &#123; this.list = new ArrayList&lt;Object&gt;(); &#125; @Override public void put(Object obj)&#123; this.list.add(obj); &#125; @Override public Iterator iterator() &#123; return new MyIterator(list); &#125;&#125; 客户端测试类。设置元素，并使用迭代器进行遍历。 123456789101112131415161718public class ClientTest &#123; public static void main(String[] args) &#123; //创建一个自定义容器，直接使用ArrayList的实现 Container strContainer = new MyContainer(); strContainer.put(\"001\"); strContainer.put(\"002\"); Iterator myIterator = strContainer.iterator(); //使用迭代器遍历 System.out.println(myIterator.first()); while (myIterator.hasNext()) &#123; System.out.println(myIterator.next()); &#125; &#125;&#125; 总结Iterator模式是用于遍历集合类的标准访问方法。它可以把访问逻辑从不同类型的集合类中抽象出来，从而避免向客户端暴露集合的内部结构。 适用场景： 访问一个聚合对象的内容而无须暴露它的内部表示。 需要为聚合对象提供多种遍历方式。 为遍历不同的聚合结构提供一个统一的接口。 优点： 它支持以不同的方式遍历一个聚合对象。 迭代器简化了聚合类。在同一个聚合上可以有多个遍历。 在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。 系统需要访问一个聚合对象的内容而无需暴露它的内部表示。 缺点： 由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。 迭代器模式在遍历的同时更改迭代器所在的集合结构会导致出现异常。所以使用foreach语句只能在对集合进行遍历，不能在遍历的同时更改集合中的元素。 参考 java设计模式—-迭代子模式 Head First设计模式之迭代器模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之责任链模式","slug":"designchain","date":"2017-03-24T16:00:00.000Z","updated":"2018-02-05T14:22:00.000Z","comments":true,"path":"2017/03/25/designchain/","link":"","permalink":"http://blueskykong.com/2017/03/25/designchain/","excerpt":"","text":"责任链模式是一种对象的行为模式。 责任链模式定义责任链模式：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 在责任链模式里，很多的对象由每一个对象对其下家的引用而联接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下动态地重新组织链和分配责任。比如servlet中的filter，有多层，当然，这个在Spring Security使用的更加淋漓尽致。 在责任链模式中发出请求的客户端并不知道这当中的哪个对象最终处理这个请求，这样系统的更改可以在不影响客户端的情况下动态的重新组织和分配责任。 责任链模式的结构 责任链模式中，主要的角色有Handler和ConcreteHandler： Handler定义一个处理请求的接口； ConcreteHandler具体处理类，处理它所负责的请求，可访问它的后继者。如果可以处理该请求，就处理，否则就将该请求转发给它的后继者。 责任链模式的实现抽象类Handler，具体的实现都要继承该抽象类。定义了继任者，以及处理请求的方法。 1234567@Datapublic abstract class Handler &#123; protected Handler successor;//继任者 //处理请求 public void handleRequest(int num) &#123;&#125;&#125; 第一个继任者，num小于10则处理，否则继续传递。 12345678910public class ConcreteHandler1 extends Handler &#123; public void handleRequest(int num) &#123; if (num &gt;= 0 &amp;&amp; num &lt; 10) &#123; System.out.println(this.getClass() + \" 处理请求 \" + num); &#125; else if (successor != null) &#123; successor.handleRequest(num); &#125; &#125;&#125; 第二个继任者，处理10到20的num。 12345678910public class ConcreteHandler2 extends Handler &#123; public void handleRequest(int num) &#123; if (num &gt;= 10 &amp;&amp; num &lt; 20) &#123; System.out.println(this.getClass() + \" 处理请求 \" + num); &#125; else if (successor != null) &#123; successor.handleRequest(num); &#125; &#125;&#125; 第三个继任者，处理20到30的num。 12345678910public class ConcreteHandler3 extends Handler &#123; public void handleRequest(int num) &#123; if (num &gt;= 20 &amp;&amp; num &lt; 30) &#123; System.out.println(this.getClass() + \" 处理请求 \" + num); &#125; else if (successor != null) &#123; successor.handleRequest(num); &#125; &#125;&#125; 客户端示例代码。调用链为：1-&gt;2-&gt;3。 1234567891011121314public class TestDemo &#123; public static void main(String[] args) &#123; Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); Handler handler3 = new ConcreteHandler3(); //设置责任链的前驱和后继 handler1.setSuccessor(handler2); handler2.setSuccessor(handler3); handler1.handleRequest(15); &#125;&#125; 总结本文主要介绍了行为模式的责任链模式。在看到一些文章处理很多if...else...语句时，也会用责任链模式处理，将条件判断分散到各个实现类中，并且这些处理类的优先处理顺序可以随意的设定，并且如果想要添加新的 handler 类也是十分简单的，这符合开放闭合原则。不过需要注意避免责任链中出现循环引用。优缺点总结如下： 优点： 降低耦合度。它将请求的发送者和接收者解耦。 简化了对象。使得对象不需要知道链的结构。增加新的请求处理类很方便。 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 不足之处： 不能保证请求一定被接收。 系统性能将受到一定影响，可能会造成循环调用。可能不容易观察运行时的特征，有碍于除错。 参考 话设计模式—责任链模式 设计模式之责任链模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之策略模式","slug":"designstrategy","date":"2017-03-21T16:00:00.000Z","updated":"2018-01-16T12:24:56.000Z","comments":true,"path":"2017/03/22/designstrategy/","link":"","permalink":"http://blueskykong.com/2017/03/22/designstrategy/","excerpt":"","text":"策略模式的定义策略模式属于行为型模式。 策略模式是对算法的封装，把一系列的算法分别封装到对应的类中，并且这些类实现相同的接口，相互之间可以替换。在策略模式中，调用算法的主体则是封装到了封装类Context中，抽象策略Strategy一般是一个接口，目的只是为了定义规范，里面一般不包含逻辑。其实，这只是通用实现，而在实际编程中，因为各个具体策略实现类之间难免存在一些相同的逻辑，为了避免重复的代码，我们常常使用抽象类来担任Strategy的角色，在里面封装公共的代码。 策略模式的适用场景：如通知服务有三种通知方式：应用服务内部通知、短信和邮件三种方式。根据需要，可能使用三种方式中的任意一种。此种场景可以使用策略模式，客户端根据需求进行相应的选择。 策略模式的结构 环境类：对策略进行二次封装，目的是避免高层模块对策略的直接调用。 抽象策略：通常情况下为一个接口，当各个实现类中存在着重复的逻辑时，则使用抽象类来封装这部分公共的代码，此时，策略模式看上去更像是模版方法模式。 具体策略：具体策略角色通常由一组封装了算法的类来担任，这些类之间可以根据需要自由替换。 策略模式的优点： 支持“开闭原则”，用户可以在不修改原有系统的基础上选择算法或行为，也可以灵活地增加新的算法或行为，提供了管理相关的算法族的办法。 可以避免使用多重条件语句。多重条件语句不易维护，它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起，统统列在一个多重条件语句里面，比使用继承的办法还要原始和落后。 策略模式的缺点： 必须对客户端（调用者）暴露所有的策略类，因为使用哪种策略是由客户端来决定的，因此，客户端应该知道有什么策略，并且了解各种策略之间的区别，否则，后果很严重。比如，客户端要使用一个容器，有链表实现的，也有数组实现的，客户端是不是也要明白链表和数组有什么区别？就这一点来说是有悖于迪米特法则的。 由于策略模式把每个具体的策略实现都单独封装成为类，如果备选的策略很多的话，那么对象的数目就会很可观。 策略模式的实践通知接口，抽象策略类实现： 1234public interface Notify &#123; // 策略方法 public void notice();&#125; 环境Context的实现： 123456789101112public class Context &#123; //持有一个具体策略的对象 private Notify notify; // 构造函数，传入一个具体策略对象 public Context(Notify notify)&#123; this. notify = notify; &#125; // 策略方法 public void contextInterface()&#123; notify.notice(); &#125;&#125; 邮件通知策略类的实现： 123456public class MailNotify implements Notify &#123; @Override public void notice() &#123; //相关的业务 &#125;&#125; 短信通知策略类的实现： 123456public class SMSNotify implements Notify &#123; @Override public void notice() &#123; //相关的业务 &#125;&#125; 客户端进行调用短信通知策略： 12345678910public class Client &#123; public static void main(String[] args) &#123; //选择并创建需要使用的策略对象 Notify strategy = new SMSNotify(); //创建环境 Context context = new Context(strategy); //通过环境Context进行调用 context. contextInterface(); &#125;&#125; 总结策略模式的重点不是如何实现算法，而是如何组织、调用这些算法，从而让程序结构更灵活，具有更好的维护性和扩展性。运行期间，策略模式在每一个时刻只能使用一个具体的策略实现对象，虽然可以动态地在不同的策略实现中切换，但是同时只能使用一个。经常见到的是，所有的具体策略类都有一些公有的行为。这时候，就应当把这些公有的行为放到共同的抽象策略角色Strategy类里面。当然这时候抽象策略角色必须要用Java抽象类实现，而不能使用接口。 适用场景： 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 一个系统需要动态地在几种算法中选择一种。 如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 vs工厂模式工厂模式是创建型模式 ，它关注对象创建，提供创建对象的接口. 让对象的创建与具体的使用客户无关。策略模式是对象行为型模式 ，它关注行为和算法的封装 。它定义一系列的算法,把每一个算法封装起来, 并且使它们可相互替换。使得算法可独立于使用它的客户而变化。 vs模版方法模式另一种模式也是关注对算法的封装——模版方法模式，对照类图可以看到，策略模式与模版方法模式的区别仅仅是多了一个单独的封装类Context，它与模版方法模式的区别在于：在模版方法模式中，调用算法的主体在抽象的父类中，而在策略模式中，调用算法的主体则是封装到了封装类Context中，抽象策略Strategy一般是一个接口，目的只是为了定义规范，里面一般不包含逻辑。其实，这只是通用实现，而在实际编程中，因为各个具体策略实现类之间难免存在一些相同的逻辑，为了避免重复的代码，我们常常使用抽象类来担任Strategy的角色，在里面封装公共的代码，因此，在很多应用的场景中，在策略模式中一般会看到模版方法模式的影子。 参考 23种设计模式（12）：策略模式 设计模式 ( 十八 ) 策略模式Strategy（对象行为型）","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之观察者模式","slug":"designobeserver","date":"2017-03-14T16:00:00.000Z","updated":"2018-02-07T05:22:08.000Z","comments":true,"path":"2017/03/15/designobeserver/","link":"","permalink":"http://blueskykong.com/2017/03/15/designobeserver/","excerpt":"","text":"观察者模式属于行为模式。 观察者模式的定义观察者模式又称为发布/订阅模式，是一种对象的行为型模式。它定义了对象之间的一对多的依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象都得到通知并被自动更新。观察者模式的优点在于实现了表示层和数据层的分离，并定义了稳定的更新消息传递机制，类别清晰，抽象了更新接口，使得相同的数据层可以有各种不同的表示层。使用场景： 对一个对象的修改涉及对其它对象的修改，而且不知道有多少对象需要进行相应修改。 对象应该能够在不用假设对象标识的前提下通知其它对象。 观察者模式的结构在观察者模式中，包括以下四个角色： 主题（Subject）：主题是一个接口，该接口规定了具体主题需要实现的方法，比如，添加、删除观察者以及通知观察者更新数据的方法。 观察者（Observer）：观察者是一个接口，该接口规定了具体观察者用来更新数据的方法。 具体主题（ConcreteSubject）：具体主题是实现主题接口类的一个实例，该实例包含有可以经常发生变化的数据。具体主题需使用一个集合，比如ArrayList，存放观察者的引用，以便数据变化时通知具体观察者。 具体观察者（ConcreteObserver）：具体观察者是实现观察者接口类的一个实例。具体观察者包含有可以存放具体主题引用的主题接口变量，以便具体观察者让具体主题将自己的引用添加到具体主题的集合中，使自己成为它的观察者，或让这个具体主题将自己从具体主题的集合中删除，使自己不再是它的观察者。 观察者模式的实现定义一个抽象被观察者接口，抽象主题，可以增加和删除观察者角色。 12345public interface Observerable &#123; public void registerObserver(Observer o); public void removeObserver(Observer o); public void notifyObserver(); &#125; 定义一个抽象观察者接口，订阅消息的更新： 123public interface Observer &#123; public void update(String message);&#125; 具体的主题，实现了Observerable接口，对Observerable接口的三个方法进行了具体实现，同时有一个List集合，用以保存注册的观察者，等需要通知观察者时，遍历该集合即可。 1234567891011121314151617181920212223242526272829303132333435363738public class WechatServer implements Observerable &#123; //注意到这个List集合的泛型参数为Observer接口，设计原则：面向接口编程而不是面向实现编程 private List&lt;Observer&gt; list; private String message; public WechatServer() &#123; list = new ArrayList&lt;Observer&gt;(); &#125; @Override public void registerObserver(Observer o) &#123; list.add(o); &#125; @Override public void removeObserver(Observer o) &#123; if(!list.isEmpty()) list.remove(o); &#125; //遍历 @Override public void notifyObserver() &#123; for(int i = 0; i &lt; list.size(); i++) &#123; Observer oserver = list.get(i); oserver.update(message); &#125; &#125; public void setInfomation(String s) &#123; this.message = s; System.out.println(\"更新消息： \" + s); //消息更新，通知所有观察者 notifyObserver(); &#125;&#125; 定义具体观察者，微信公众号的订阅用户User： 12345678910111213141516171819public class User implements Observer &#123; private String name; private String message; public User(String name) &#123; this.name = name; &#125; @Override public void update(String message) &#123; this.message = message; read(); &#125; public void read() &#123; System.out.println(name + \" 收到推送消息： \" + message); &#125; &#125; 测试类： 1234567891011public class Test &#123; public static void main(String[] args) &#123; WechatServer server = new WechatServer(); Observer user1 = new User(\"user1\"); server.registerObserver(user1); server.setInfomation(\"test\"); &#125;&#125; 我们注册了user1，并发布了一条消息test，user1能够正常收到该消息通知。 总结观察者模式将观察者和主题（被观察者）彻底解耦，主题只知道观察者实现了某一接口，即Observer接口。并不需要观察者的具体类是谁、做了些什么或者其他任何细节。任何时候我们都可以增加新的观察者。因为主题唯一依赖的东西是一个实现了Observer接口的对象列表。 具体主题和具体观察者是松耦合关系。由于主题接口仅仅依赖于观察者接口，因此具体主题只是知道它的观察者是实现观察者接口的某个类的实例，但不需要知道具体是哪个类。同样，由于观察者仅仅依赖于主题接口，因此具体观察者只是知道它依赖的主题是实现主题接口的某个类的实例，但不需要知道具体是哪个类。 观察者模式满足“开-闭原则”。主题接口仅仅依赖于观察者接口。这样，就可以让创建具体主题的类也仅仅是依赖于观察者接口，因此，如果增加新的实现观察者接口的类，不必修改创建具体主题的类的代码。同样，创建具体观察者的类仅仅依赖于主题接口，如果增加新的实现主题接口的类，也不必修改创建具体观察者类的代码。 vs 发布/订阅模式在翻阅资料的时候，有人把观察者（Observer）模式等同于发布（Publish）/订阅（Subscribe）模式，也有人认为这两种模式还是存在差异。发布/订阅模式中，订阅者把自己想订阅的事件注册到调度中心，当该事件触发时候，发布者发布该事件到调度中心（顺带上下文），由调度中心统一调度订阅者注册到调度中心的处理代码。 虽然两种模式都存在订阅者和发布者（具体观察者可认为是订阅者、具体目标可认为是发布者），但是观察者模式是由具体目标调度的，而发布/订阅模式是统一由调度中心调的，所以观察者模式的订阅者与发布者之间是存在依赖的，而发布/订阅模式则不会。 参考 JAVA设计模式之观察者模式 设计模式（三）：观察者模式与发布/订阅模式区别","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之模板方法模式","slug":"templatedesign","date":"2017-03-09T16:00:00.000Z","updated":"2018-01-21T03:08:24.000Z","comments":true,"path":"2017/03/10/templatedesign/","link":"","permalink":"http://blueskykong.com/2017/03/10/templatedesign/","excerpt":"","text":"模板方法模式的定义 模板方法模式是类的行为模式。准备一个抽象类，将部分逻辑以具体方法以及具体构造函数的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。这就是模板方法模式的用意。 上面对模板方法模式的定义其实已经很清晰了。完成一件事情，有固定的数个步骤，但是每个步骤根据对象的不同，而实现细节不同；就可以在父类中定义一个完成该事情的总方法，按照完成事件需要的步骤去调用其每个步骤的实现方法。而每个步骤的具体实现，由子类完成。 模板方法模式的适用场景：还是使用通知服务的例子。有三种通知方式：应用服务内部通知、短信和邮件三种方式。发送通知需要如下步骤：准备发送通知的内容、发送具体通知。这两步是算法的骨架，然而根据需要，可能使用三种方式中的任意一种，涉及具体细节。 模板方法模式的结构这里涉及到两个角色： 抽象模板(Abstract Template)角色。实现了模板方法，定义了算法的骨架。 定义了一个或多个抽象操作，以便让子类实现。这些抽象操作叫做基本操作，它们是一个顶级逻辑的组成步骤。 定义并实现了一个模板方法。这个模板方法一般是一个具体方法，它给出了一个顶级逻辑的骨架，而逻辑的组成步骤在相应的抽象操作中，推迟到子类实现。顶级逻辑也有可能调用一些具体方法。 具体模板(Concrete Template)角色，实现抽象类中的抽象方法，完成完整的算法。 实现父类所定义的一个或多个抽象方法，它们是一个顶级逻辑的组成步骤。 每一个抽象模板角色都可以有任意多个具体模板角色与之对应，而每一个具体模板角色都可以给出这些抽象方法（也就是顶级逻辑的组成步骤）的不同实现，从而使得顶级逻辑的实现各不相同。 模板方法模式的优点： 具体细节步骤实现定义在子类中，子类定义详细处理算法是不会改变算法整体结构。 子类实现算法的某些细节，有助于算法的扩展。 存在一种反向的控制结构，通过一个父类调用其子类的操作，通过子类对父类进行扩展增加新的行为，符合“开闭原则”。 模板方法模式的不足： 每个不同的实现都需要定义一个子类，会导致类的个数增加，系统更加庞大。 模板方法模式的实现抽象模板角色类实现： 1234567891011121314public abstract class AbstractNotify &#123; //模板方法 public final void send() &#123; String text = assembleContent(); notice(text); &#125; //基本方法，已经实现 private String assembleContent() &#123; return \"content\"; &#125; // 通知方法的声明（由子类实现） public abstract void notice(String text);&#125; 邮件通知具体模板实现： 123456public class MailNotify extends AbstractNotify &#123; @Override public void notice(String text) &#123; //相关的业务 &#125;&#125; 短信通知具体模板实现： 123456public class SMSNotify extends AbstractNotify &#123; @Override public void notice(String text) &#123; //相关的业务 &#125;&#125; 客户端进行调用短信通知策略： 12345678public class Client &#123; public static void main(String[] args) &#123; //选择并创建需要使用的具体模板 AbstractNotify notify = new SMSNotify(); //SMS发送 notify.send(); &#125;&#125; 总结上面的实现中使用了JAVA的继承机制，在抽象类中定义一个模板方法，该方法引用了若干个抽象方法（由子类实现）或具体方法（子类可以覆盖重写）。模板方法模式是一种类的行为型模式，在它的结构图中只有类之间的继承关系，没有对象关联关系。模板方法模式是基于继承的代码复用基本技术，模板方法模式的结构和用法也是面向对象设计的核心之一。在模板方法模式中，可以将相同的代码放在父类中，而将不同的方法实现放在不同的子类中。在模板方法模式中，我们需要准备一个抽象类，将部分逻辑以具体方法以及具体构造函数的形式实现，然后声明一些抽象方法来让子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现，这就是模板方法模式的用意。模板方法模式体现了面向对象的诸多重要思想，是一种使用频率较高的模式。 上面的实现其实少了一个钩子方法，它在抽象类中不做事，或者是默认的事情，子类可以选择覆盖它。最后，为了防止子类改变模板方法中的算法骨架，一般将模板方法声明为final vs策略方法模式策略模式和模板方法都是用于封装算法，前者是利用组合和委托模型，而后者则是继承。从具体实现来看，策略模式与模版方法模式的区别仅仅是多了一个单独的封装类Context，它与模版方法模式的区别在于：在模版方法模式中，调用算法的主体在抽象的父类中，而在策略模式中，调用算法的主体则是封装到了封装类Context中，抽象策略Strategy一般是一个接口，目的只是为了定义规范，里面一般不包含逻辑。其实，这只是通用实现，而在实际编程中，因为各个具体策略实现类之间难免存在一些相同的逻辑，为了避免重复的代码，我们常常使用抽象类来担任Strategy的角色，在里面封装公共的代码，因此，在很多应用的场景中，在策略模式中一般会看到模版方法模式的影子。 参考 设计模式之 - 模板模式（Template Pattern） 《JAVA与模式》之模板方法模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之外观模式","slug":"designfacade","date":"2017-03-02T16:00:00.000Z","updated":"2017-12-18T14:44:49.000Z","comments":true,"path":"2017/03/03/designfacade/","link":"","permalink":"http://blueskykong.com/2017/03/03/designfacade/","excerpt":"","text":"1. 概述外观模式通过外观的包装，使复杂的系统对外只能看到外观对象，而不会看到具体的细节对象，为子系统中的一组接口提供了一个统一的访问接口，这个接口使得子系统更容易被访问或者使用。 这样无疑会降低应用程序的复杂度，并且提高了程序的可维护性。 2. 组成为子系统中的一组接口提供一个一致的界面， Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。引入外观角色之后，用户只需要直接与外观角色交互，用户与子系统之间的复杂关系由外观角色来实现，从而降低了系统的耦合度。 其组成如下： 外观角色（Facade）：是核心，他被客户client角色调用，知道各个子系统的功能。同时根据客户角色已有的需求预订了几种功能组合。 子系统角色（Subsystem classes）：实现子系统的功能，并处理由Facade对象指派的任务。对子系统而言，facade和client角色是未知的，没有Facade的任何相关信息；即没有指向Facade的实例。 客户角色（client）：调用facade角色获得完成相应的功能。3. 示例 3.1 子系统1234567891011121314151617181920212223242526//子系统A public class SubSystemOne &#123; public void MethodeOne() &#123; System.out.println(\"Sub System A method.\"); &#125; &#125; /// 子系统B public class SubSystemTwo &#123; public void MethodTwo() &#123; System.out.println(\"Sub System B method.\"); &#125; &#125; // 子系统C public class SubSystemThree &#123; public void MethodThree() &#123; System.out.println(\"Sub System C method.\"); &#125; &#125; 一共有三个子系统，每个子系统都有自己的方法。 3.2 外观类12345678910111213141516171819202122232425262728// 外观类public class Facade&#123; private SubSystemOne one; private SubSystemTwo two; private SubSystemThree three; public Facade() &#123; one = new SubSystemOne(); two = new SubSystemTwo(); three = new SubSystemThree(); &#125; public void MethodA() &#123; System.out.println(\"\\nMethod group A----\"); one.MethodeOne(); two.MethodTwo(); &#125; public void MethodB() &#123; System.out.println(\"\\nMethod group B----\"); two.MethodTwo(); three.MethodThree(); &#125;&#125; 外观类是提供给客户端调用直接进行调用，外观类对子系统提供的方法进行组合，形成两个组，分别表现为不同的行为（调用不同的方法）。 3.3 客户端12345678910public class FacadeTest&#123; public static void main(string[] args) &#123; // 调用外观类 Facade facade = new Facade(); facade.MethodA(); facade.MethodB(); &#125;&#125; 由于Facade的作用，客户端可以根本不知道子系统类的存在。 4. 场景和优缺点4.1 使用场景 当你要为一个复杂子系统提供一个简单接口时。子系统往往因为不断演化而变得越来越复杂。大多数模式使用时都会产生更多更小的类。 这使得子系统更具可重用性，也更容易对子系统进行定制，但这也给那些不需要定制子系统的用户带来一些使用上的困难。facade可以提供一个简单的缺省视图， 这一视图对大多数用户来说已经足够，而那些需要更多的可定制性的用户可以越过facade层。 客户程序与抽象类的实现部分之间存在着很大的依赖性。引入 facade将这个子系统与客户以及其他的子系统分离，可以提高子系统的独立性 和可移植性。 当你需要构建一个层次结构的子系统时，使用 facade模式定义子系统中每层的入口点。如果子系统之间是相互依赖的，你可以让它们仅通过facade进行通讯，从而简化了它们之间的依赖关系。 4.2 优点 Facade模式降低了客户端对子系统使用的复杂性。 外观模式松散了客户端与子系统的耦合关系，让子系统内部的模块能更容易扩展和维护。 通过合理使用Facade，可以帮助我们更好的划分访问的层次。 4.3 缺点 不能很好地限制客户使用子系统类，如果对客户访问子系统类做太多的限制则减少了可变性和灵活性。 在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。 5. 总结本文主要讲了设计模式的外观模式，从概述到组成，以一个实例进行讲解各个组成角色，最后概括了使用场景和外观模式的优缺点。外观模式的思路，有点让人联想其适配器模式，适配器模式是将一个接口通过适配来间接转换为另一个接口。而外观模式，其主要是提供一个整洁的一致的接口给客户端。 外观模式要求一个子系统的外部与其内部的通信通过一个统一的外观对象进行，外观类将客户端与子系统的内部复杂性分隔开，使得客户端只需要与外观对象打交道，而不需要与子系统内部的很多对象打交道。从很大程度上提高了客户端使用的便捷性，使得客户端无须关心子系统的工作细节，通过外观角色即可调用相关功能。 另外，不要试图通过外观类为子系统增加新行为，不要通过继承一个外观类在子系统中加入新的行为，这种做法是错误的。外观模式的用意是为子系统提供一个集中化和简化的沟通渠道，而不是向子系统加入新的行为，新的行为的增加应该通过修改原有子系统类或增加新的子系统类来实现，不能通过外观类来实现。 参考设计模式–外观模式Facade","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之建造者模式","slug":"designbuilder","date":"2017-02-25T16:00:00.000Z","updated":"2017-11-30T14:52:21.000Z","comments":true,"path":"2017/02/26/designbuilder/","link":"","permalink":"http://blueskykong.com/2017/02/26/designbuilder/","excerpt":"","text":"1. 名词解释 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 比如一台电脑包括主机、显示器、键盘等外设，这些部件组成了完整的一台电脑。如何将这些部件组装成一台完整的电脑并返回给用户，这是建造者模式需要解决的问题。建造者模式（builder）又称为生成器模式，从名词就可以看出，它是一种较为复杂、使用频率也相对较低的创建型模式。建造者模式为客户端返回的不是一个简单的产品，而是一个由多个部件组成的复杂产品。 2. 建造者模式UML图 上图中包含了建造者模式的四个主要角色： Builder（抽象建造者）：它为创建一个产品Product对象的各个部件指定抽象方法，在该接口中一般声明两类方法，一类方法是buildPartX()，它们用于创建复杂对象的各个部件；另一类方法是getResult()，它们用于返回复杂对象。Builder既可以是抽象类，也可以是接口。 ConcreteBuilder（具体建造者）：它实现了Builder抽象方法，实现各个部件的具体构造和装配方法，定义并明确它所创建的复杂对象，也可以提供一个方法返回创建好的复杂产品对象。依赖于Product。 Product（产品角色）：它是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品的内部表示并定义它的装配过程。 Director（指挥者）：指挥者又称为导演类，它负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造。客户端一般只需要与指挥者进行交互，在客户端确定具体建造者的类型，并实例化具体建造者对象（也可以通过配置文件和反射机制），然后通过指挥者类的构造函数或者Setter方法将该对象传入指挥者类中。 3. 建造者模式实现下面代码基于Java实现的一个建造者模式。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@dataclass Product &#123; private String name; private String type; public void showProduct()&#123; System.out.println(\"名称：\"+name); System.out.println(\"型号：\"+type); &#125; &#125; //抽象类abstract class Builder &#123; public abstract void buildPart(String arg1, String arg2); public abstract Product getProduct(); &#125; //具体建造者class ConcreteBuilder extends Builder &#123; private Product product = new Product(); public Product getResult() &#123; return product; &#125; public void buildPart(String arg1, String arg2) &#123; product.setName(arg1); product.setType(arg2); &#125; &#125; // 指挥者 public class Director &#123; private Builder builder; public Director(Builder builder) &#123; this.builder=builder; &#125; public void setBuilder(Builder builder) &#123; this.builder=builer; &#125; public Product construct()&#123; builder.buildPart(\"lenvono\",\"Y470\"); return builder.getResult(); &#125; &#125; //客户端调用public class Client &#123; public static void main(String[] args)&#123; Builder builder = new ConcreteBuilder(); Director director = new Director(builder); Product product = director.construct(); product1.showProduct(); &#125; &#125; 四个角色都包含在上面的实现中，客户端进行调用，对于客户端而言，只需关心具体的建造者即可。在指挥者类中可以注入一个抽象建造者类型的对象，其核心在于提供了一个建造方法construct()，在该方法中调用了builder对象的构造部件的方法，最后返回一个产品对象。 4. 与工厂模式区别建造者模式的优点是封装性好，且易于扩展。上面提到，对于客户端而言，只需关心具体的建造者即可。使用建造者模式可以优先的封装变化，product和builder比较稳定，主要的业务逻辑封装在控制类中对整体可取得比较好的稳定性。如需扩展，只需要加一个新的建造者，对之前代码没有影响。 与工厂模式相比，建造者模式一般用来创建更为复杂的对象，因为对象的创建过程更为复杂，因此将对象的创建过程独立出来组成一个新的类——指挥者类。也就是说，工厂模式是将对象的全部创建过程封装在工厂类中，由工厂类向客户端提供最终的产品；而建造者模式中，建造者类一般只提供产品类中各个组件的建造，而将具体建造过程交付给指挥者类。由指挥者类负责将各个组件按照特定的规则组建为产品，然后将组建好的产品交付给客户端。 5. 总结本文讲解了设计模式中的建造者模式，大的分类属于创建型模式。首先介绍了建造者模式的概念；然后给出了建造者模式的类图，并对其中涉及到的四个角色进行了解释；又给出了基于Java实现的代码；最后简单说了下其优点，与工厂模式的区别。建造者模式主要适用于创建一些复杂的对象，这些对象的内部组成构件间的建造顺序是稳定的，但是对象的内部组成构件面临着复杂的变化。 参考 《java与模式》阎宏 23种设计模式（4）：建造者模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之代理模式","slug":"designproxy","date":"2017-02-21T16:00:00.000Z","updated":"2018-02-23T09:46:07.000Z","comments":true,"path":"2017/02/22/designproxy/","link":"","permalink":"http://blueskykong.com/2017/02/22/designproxy/","excerpt":"","text":"代理模式属于结构性模式。 代理模式的定义代理模式为其他对象提供一种代理以控制对这个对象的访问。从定义可以知道代理模式控制客户端对一个对象的访问，它跟现实中的中介代理类似，只是作为代表做一些受理工作，真正执行的并不是它自己。 代理模式的结构 代理模式中的角色： 抽象主题 Subject：声明了目标对象和代理对象的共同接口，任何可以使用目标对象的地方都可以使用代理对象。 具体主题 RealSubject：也称为委托角色或者被代理角色。定义了代理对象所代表的目标对象。 代理主题 Proxy：代理类。代理对象内部含有目标对象的引用，从而可以操作目标对象；代理对象提供一个与目标对象相同的接口，以便替代目标对象。代理对象通常在客户端调用传递给目标对象之前或之后，执行某个操作，而不是单纯地将调用传递给目标对象。 代理模式的分类代理模式又分为静态代理和动态代理。 静态代理静态代理是由开发创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。 主题接口的定义： 1234public interface Subject&#123; void hello();&#125; 具体主题类的定义： 12345678public class RealSubject implements Subject&#123; @Override public void hello() &#123; System.out.println(\"RealSubject\"); &#125;&#125; 代理主题的实现： 12345678910111213public class Proxy implements Subject&#123; private Subject subject = null; @Override public void hello() &#123; if(subject == null) subject = new RealSubject(); System.out.print(\"Hello, I'm A Proxy, I'm invoking...\"); this.subject.hello(); &#125;&#125; 调用时只需要实例化代理对象即可Subject subject = new Proxy();。代理对象将客户端的调用指派给目标对象，在调用目标对象的方法之前和之后都可以执行特定的操作。 动态代理Java动态代理有两种实现：jdk动态代理和cglib动态代理。 JDK动态代理jdk动态代理是由java内部的反射机制来实现的。 定义接口与实现类 1234567public interface OrderService &#123; public void save(UUID orderId, String name); public void update(UUID orderId, String name); public String getByName(String name);&#125; 上面代码定义了一个被拦截对象接口，即横切关注点。下面代码实现被拦截对象接口。 1234567891011121314151617181920212223242526272829public class OrderServiceImpl implements OrderService &#123; private String user = null; public OrderServiceImpl() &#123; &#125; public OrderServiceImpl(String user) &#123; this.setUser(user); &#125; //... @Override public void save(UUID orderId, String name) &#123; System.out.println(\"call save()方法,save:\" + name); &#125; @Override public void update(UUID orderId, String name) &#123; System.out.println(\"call update()方法\"); &#125; @Override public String getByName(String name) &#123; System.out.println(\"call getByName()方法\"); return \"aoho\"; &#125;&#125; JDK动态代理类 123456789101112131415161718192021222324252627public class JDKProxy implements InvocationHandler &#123; //需要代理的目标对象 private Object targetObject; public Object createProxyInstance(Object targetObject) &#123; this.targetObject = targetObject; return Proxy.newProxyInstance(this.targetObject.getClass().getClassLoader(), this.targetObject.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //被代理对象 OrderServiceImpl bean = (OrderServiceImpl) this.targetObject; Object result = null; //切面逻辑（advise），此处是在目标类代码执行之前 System.out.println(\"---before invoke----\"); if (bean.getUser() != null) &#123; result = method.invoke(targetObject, args); &#125; System.out.println(\"---after invoke----\"); return result; &#125; //...&#125; 上述代码实现了动态代理类JDKProxy，实现InvocationHandler接口，并且实现接口中的invoke方法。当客户端调用代理对象的业务方法时，代理对象执行invoke方法，invoke方法把调用委派给targetObject，相当于调用目标对象的方法，在invoke方法委派前判断权限，实现方法的拦截。 测试 12345678910public class AOPTest &#123; public static void main(String[] args) &#123; JDKProxy factory = new JDKProxy(); //Proxy为InvocationHandler实现类动态创建一个符合某一接口的代理实例 OrderService orderService = (OrderService) factory.createProxyInstance(new OrderServiceImpl(\"aoho\")); //由动态生成的代理对象来orderService 代理执行程序 orderService.save(UUID.randomUUID(), \"aoho\"); &#125;&#125; 结果如下： 123---before invoke----call save()方法,save:aoho---after invoke---- CGLIB动态代理cglib动态代理底层则是借助asm来实现的。 要代理的类CGLIB既可以对接口的类生成代理，也可以针对类生成代理。示例中，实现对类的代理。 12345678910111213141516171819202122232425public class OrderManager &#123; private String user = null; public OrderManager() &#123; &#125; public OrderManager(String user) &#123; this.setUser(user); &#125; //... public void save(UUID orderId, String name) &#123; System.out.println(\"call save()方法,save:\" + name); &#125; public void update(UUID orderId, String name) &#123; System.out.println(\"call update()方法\"); &#125; public String getByName(String name) &#123; System.out.println(\"call getByName()方法\"); return \"aoho\"; &#125;&#125; 该类的实现和上面的接口实现一样，为了保持统一。 CGLIB动态代理类 123456789101112131415161718192021222324252627public class CGLibProxy implements MethodInterceptor &#123; // CGLib需要代理的目标对象 private Object targetObject; public Object createProxyObject(Object obj) &#123; this.targetObject = obj; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(obj.getClass()); //回调方法的参数为代理类对象CglibProxy，最后增强目标类调用的是代理类对象CglibProxy中的intercept方法 enhancer.setCallback(this); //增强后的目标类 Object proxyObj = enhancer.create(); // 返回代理对象 return proxyObj; &#125; @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object obj = null; //切面逻辑（advise），此处是在目标类代码执行之前 System.out.println(\"---before intercept----\"); obj = method.invoke(targetObject, args); System.out.println(\"---after intercept----\"); return obj; &#125;&#125; 上述实现了创建子类的方法与代理的方法。getProxy(SuperClass.class)方法通过入参即父类的字节码，扩展父类的class来创建代理对象。intercept()方法拦截所有目标类方法的调用，obj表示目标类的实例，method为目标类方法的反射对象，args为方法的动态入参，methodProxy为代理类实例。method.invoke(targetObject, args)通过代理类调用父类中的方法。 测试 12345public class AOPTest &#123; public static void main(String[] args) &#123; OrderManager order = (OrderManager) new CGLibProxy().createProxyObject(new OrderManager(\"aoho\")); order.save(UUID.randomUUID(), \"aoho\"); &#125; 结果如下： 123---before intercept----call save()方法,save:aoho---after intercept---- 总结本文主要介绍了创建型的模式：代理模式。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。代理模式又分为静态代理和动态代理，不同之处在于代理类的生成时间。动态代理又分为jdk动态代理和cglib动态代理实现。两种方法各有优劣。总的来说，反射机制在生成类的过程中比较高效，而asm在生成类之后的相关执行过程中比较高效（可以通过将asm生成的类进行缓存，这样解决asm生成类过程低效问题）。 vs 装饰者模式装饰者模式与代理模式很类似，二者最主要的区别是：代理模式中，代理类对被代理的对象有控制权，决定其执行或者不执行。而装饰模式中，装饰类对代理对象没有控制权，只能为其增加一层装饰，以加强被装饰对象的功能，仅此而已。装饰者模式主要是用来增加类的职责和行为的，将类的核心职责和装饰功能区分开，可以很方便对装饰功能进行添加和去除。 vs 中介者模式中介者模式用一个中介者对象来封装一系列对象的交互。中介者使得各对象不需要显式地相互引用，从而解耦合，独立改变他们之间的交互。主要区别如下： 代理模式是一对一，一个代理只能代表一个对象。中介者模式则是多对多，中介者的功能多样，客户也可以多个。 只能代理一方。如果PB是A的代理，那么C可以通过PB访问A，但是A不能通过PB访问B。对于中介者模式而言，A可以通过中介访问B，B也可以通过中介访问A。 vs 外观模式和上面类似，代理对象代表一个单一对象，而外观对象代表一个子系统，代理的客户对象无法直接访问对象，由代理提供单独的目标对象的访问，而通常外观对象提供对子系统各元件功能的简化的共同层次的调用接口。代理是一种原来对象的代表，其他需要与这个对象打交道的操作都是和这个代表交涉的。 参考 设计模式：代理模式 Java设计模式之代理模式 中介者模式、代理模式和外观模式的Pk","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"设计模式之单例模式","slug":"designsingleton","date":"2017-02-18T16:00:00.000Z","updated":"2017-11-05T13:41:48.000Z","comments":true,"path":"2017/02/19/designsingleton/","link":"","permalink":"http://blueskykong.com/2017/02/19/designsingleton/","excerpt":"","text":"上一篇写了23种设计模式总览，本文主要介绍创建模式中的单例模式，日常工作中也会有经常用到。 1. 定义首先，什么是单例模式？单例模式有以下特点： 从字面就可以理解，单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 单例模式确保某个类只有一个实例，而且自行实例化并向整个系统提供这个实例。适用场合一般是需要频繁地进行创建和销毁的对象。如应用程序中的数据库连接池、线程池等。系统内存中该类只存在一个对象，节省了系统资源，对于一些需要频繁创建销毁的对象，使用单例模式可以提高系统性能。由于单例模式在内存中只有一个实例，减少了内存开销。 单例模式的写法有好几种，这里主要介绍三种：懒汉式单例、饿汉式单例、登记式单例。 2. 实现方法下面以java实现为例，展示几种单例模式的具体实现。 2.1 懒汉式单例12345678910111213//懒汉式单例类.在第一次调用的时候实例化自己 public class Singleton &#123; private Singleton() &#123;&#125; private static Singleton single=null; //静态工厂方法 public static Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single; &#125; //... &#125; 上述Singleton代码通过将构造方法限定为private避免了类在外部被实例化，在同一个虚拟机范围内，Singleton的唯一实例只能通过getInstance()方法访问。（事实上，通过Java反射机制是能够实例化构造方法为private的类的，那基本上会使所有的Java单例实现失效。此问题在此处不做讨论，姑且掩耳盗铃地认为反射机制不存在。） 但是以上实现没有考虑线程安全问题。所谓线程安全是指：如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。或者说：一个类或者程序所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。显然以上实现并不满足线程安全的要求，在并发环境下很可能出现多个Singleton实例。 上述的实现的方式，如果现在存在着线程A和B，线程A执行到了If(singleton == null);，线程B执行到了Singleton = new Singleton();线程B虽然实例化了一个Singleton，但是对于线程A来说判断singleton还是木有初始化的，所以线程A还会对singleton进行初始化。 （1）在getInstance方法上加同步 123456public static synchronized Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single; &#125; 当线程B访问这个函数的时候，其他的任何要访问该函数的代码不能执行，直到线程B执行完该函数（这是利用锁实现的）。 (2) 双重检查锁定DCL synchronized似乎已经解决了多线程下的问题，但多个线程访问同一个函数的时候，那么只能有一个线程能够访问这个函数，效率很低。 12345678910public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; 这种方式将在方法上的声明转移到了内部的代码块中，只有当singleton=null时，才需要锁机制，但是如果线程A和B同时执行到了Synchronized(singleton.class)，虽然也是只有一个线程能够执行，假如线程B先执行，线程B获得锁，线程B执行完之后，线程A获得锁，此时检查singleton是否为空再执行，所以不会出现两个singleton实例的情况。 (3) 静态内部类 关于内部类： 内部类都是在第一次使用时才会被加载。外部类不调用 getInstance（）时候 内部类是不会加载的，所以达到了懒汉的效果。然后调用的时候 内部类被加载，加载的时候就会初始化实例；这个加载的过程是不会有多线程的问题的！类加载的时候有一种机制叫做，缓存机制；第一次加载成功之后会被缓存起来；而且一般一个类不会加载多次。 123456789public class Singleton &#123; private static class LazyHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return LazyHolder.INSTANCE; &#125; &#125; DCL优点是资源利用率高，第一次执行getInstance时单例对象才被实例化，效率高。缺点是第一次加载时反应稍慢一些，在高并发环境下也有一定的缺陷。静态内部类实现，第一次加载Singleton类时并不会初始化sInstance，只有第一次调用getInstance方法时虚拟机加载SingletonHolder 并初始化sInstance ，这样不仅能确保线程安全也能保证Singleton类的唯一性，所以推荐使用静态内部类单例模式。 但是在反序列化时会重新创建对象，将一个单例实例对象写到磁盘再读回来，从而获得了一个实例。反序列化操作提供了readResolve方法，这个方法可以让开发人员控制对象的反序列化。在上述的几个方法示例中如果要杜绝单例对象被反序列化是重新生成对象，就必须加入如下方法： 123private Object readResolve() throws ObjectStreamException&#123; return singleton;&#125; 2.2 饿汉式单例12345678public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123; &#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快。 这种方式基于类加载机制避免了多线程的同步问题，但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到懒加载的效果。 2.3 登记式单例123456789101112131415 //登记式单例类，利用容器实现 //类似Spring里面的方法，将类名注册，下次从里面直接获取。 public class SingletonManager &#123; private static Map&lt;String, Object&gt; objMap = new HashMap&lt;String,Object&gt;(); private Singleton() &#123; &#125; public static void registerService(String key, Objectinstance) &#123; if (!objMap.containsKey(key) ) &#123; objMap.put(key, instance) ; &#125; &#125; public static ObjectgetService(String key) &#123; return objMap.get(key) ; &#125;&#125; SingletonManager将多种的单例类统一管理，在使用时根据key获取对象对应类型的对象。这种方式使得我们可以管理多种类型的单例，并且在使用时可以通过统一的接口进行获取操作，降低了用户的使用成本，也对用户隐藏了具体实现，降低了耦合度。这种不常用，内部实现还是用的饿汉式单例，因为其中的static方法块，它的单例在类被装载的时候就被实例化了。 3. 总结本文主要讲了单例模式的三种方式，分别是懒汉单例、饿汉单例和登记式单例。 主要的使用场景： 需要频繁的进行创建和销毁的对象； 创建对象时耗时过多或耗费资源过多，但又经常用到的对象； 工具类对象； 频繁访问数据库或文件的对象。 饿汉单例，类一旦加载，就把单例初始化完成，保证getInstance的时候，单例是已经存在的了。饿汉式天生就是线程安全的，可以直接用于多线程而不会出现问题。 饿汉式在类创建的同时就实例化一个静态对象出来，占据一定的内存，但是在第一次调用时速度也会更快，因为其资源已经初始化完成。 懒汉单例，只有当调用getInstance的时候，才会去初始化这个单例。是线程不安全的，在饿汉单例实现的基础上，有三种方法对多线程安全进行了处理。懒汉式会延迟加载，在第一次使用该单例的时候才会实例化对象出来，第一次调用时要做初始化，如果要做的工作比较多，性能上会有些延迟，之后就和饿汉式一样了。 参考 JAVA设计模式之单例模式 高并发下线程安全的单例模式（最全最经典）","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]},{"title":"23种设计模式总览","slug":"designPattern1","date":"2017-01-11T16:00:00.000Z","updated":"2017-10-17T07:48:30.000Z","comments":true,"path":"2017/01/12/designPattern1/","link":"","permalink":"http://blueskykong.com/2017/01/12/designPattern1/","excerpt":"","text":"1. 设计模式分类 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 其他两类：并发型模式和线程池模式。 这边引用下网上的设计模式图。 2. 设计模式的六大原则2.1 总原则总原则为开闭原则。对扩展开放，对修改封闭。在程序需要进行拓展的时候，不用去修改原有的代码，而是扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类等，后面的具体设计中我们会提到这点。 2.2 单一职责原则不要存在多于一个导致类变更的原因，也就是说每个类应该实现单一的职责，否则就应该把类拆分。 2.3 里氏替换原则里氏替换原则（Liskov Substitution Principle），任何基类可以出现的地方，子类一定可以出现。里氏替换原则是继承复用的基石，只有当衍生类可以替换基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。里氏替换原则中，子类对父类的方法尽量不要重写和重载。因为父类代表了定义好的结构，通过这个规范的接口与外界交互，子类不应该随便破坏它。 2.4 依赖倒转原则依赖倒转原则（Dependence Inversion Principle），面向接口编程，依赖于抽象而不依赖于具体。写代码时用到具体类时，不与具体类交互，而与具体类的上层接口交互。 2.5 接口隔离原则接口隔离原则（Interface Segregation Principle），每个接口中不存在子类用不到却必须实现的方法，如果不然，就要将接口拆分。使用多个隔离的接口，比使用单个接口（多个接口方法集合到一个的接口）要好。 2.6 迪米特法则迪米特法则，最少知道原则（Demeter Principle），一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public方法提供给外部。这样当被依赖的类变化时，才能最小的影响该类。最少知道原则的另一个表达方式是：只与直接的朋友通信。类之间只要有耦合关系，就叫朋友关系。耦合分为依赖、关联、聚合、组合等。我们称出现为成员变量、方法参数、方法返回值中的类为直接朋友。局部变量、临时变量则不是直接的朋友。我们要求陌生的类不要作为局部变量出现在类中。 2.7 合成复用原则合成复用原则（Composite Reuse Principle），尽量首先使用合成/聚合的方式，而不是使用继承。 3 总结本文主要写了设计模式的总览，对23种设计模式进行分类，包括创建型模式、结构型模式、行为型模式以及两种其他模式。其次介绍了设计模式的六大原则。后面文章将扩展介绍每一种设计模式。 参考1.23种设计模式全解析","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blueskykong.com/tags/设计模式/"}]}]}